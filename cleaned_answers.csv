Question ID,Answers
80,"I wound up using this. It is a kind of a hack, but it actually works pretty well. The only thing is you have to be very careful with your semicolons. : D
var strSql:String = stream.readUTFBytes(stream.bytesAvailable);      
var i:Number = 0;
var strSqlSplit:Array = strSql.split("";"");
for (i = 0; i < strSqlSplit.length; i++){
    NonQuery(strSqlSplit[i].toString());
}

"
90,"My easy click-by-click instructions (specific to TortoiseSVN) are in Stack Overflow question What is the simplest way to do branching and merging using TortoiseSVN?.
"
120,"The Jeff Prosise version from MSDN magazine works pretty well, but it has a few flaws:
AddNode freaks out with links to external sites on your menu (www.google.com, etc.)
Here's my fix in BuildSiteMap():
SiteMapNode node = GetSiteMapNodeFromReader(reader);
string url = node.Url;
if (url.Contains("":""))
{
    string garbage = Guid.NewGuid().ToString();  // SiteMapNode needs unique URLs
    node.Url = ""~/dummy_"" + garbage + "".aspx"";
    AddNode(node, _root);
    node.Url = url;
}
else
{
    AddNode(node, _root);
}

SQLDependency caching is cool, but if you don't want to make a trip to the DB everytime your menu loads (to check to see if the dependency has changed) and your menus don't change very often, then why not use HttpRuntime.Cache instead?
public override SiteMapNode RootNode
{
    get
    {
        SiteMapNode temp = (SiteMapNode)HttpRuntime.Cache[""SomeKeyName""];
        if (temp == null)
        {
            temp = BuildSiteMap();
            HttpRuntime.Cache.Insert(""SomeKeyName"", temp, null, DateTime.Now.AddHours(1), Cache.NoSlidingExpiration);
        }
        return temp;
    }
}

"
180,"My first thought on this is ""how generate N vectors in a space that maximize distance from each other."" You can see that the RGB (or any other scale you use that forms a basis in color space) are just vectors. Take a look at Random Point Picking. Hope this is a good start for you! Once you have a set of vectors that are maximized a part, you can save them in a hash table or something for later, and just perform random rotations on them to get all the colors you desire that are maximally apart from each other!
Edit: Thinking about this problem more, it would be better to map the colors in a linear manor, possibly (0,0,0) --> (255,255,255) lexicographically, and then distribute them evenly. I really don't know how well this will work, but it should since, lets say:
n = 10
we know we have 16777216 colors (256^3). We can use buckles algorithm 515 to find the lexicographically indexed color.. You'll probably have to edit the algorithm to avoid overflow and probably add some minor speed improvements.
"
260,"Oleg Shilo's C# Script solution (at The Code Project) really is a great introduction to providing script abilities in your application.
A different approach would be to consider a language that is specifically built for scripting, such as IronRuby, IronPython, or Lua.
IronPython and IronRuby are both available today.
For a guide to embedding IronPython read
How to embed IronPython script support in your existing app in 10 easy steps.
Lua is a scripting language commonly used in games. There is a Lua compiler for .NET, available from CodePlex -- http://www.codeplex.com/Nua
That codebase is a great read if you want to learn about building a compiler in .NET.
A different angle altogether is to try PowerShell. There are numerous examples of embedding PowerShell into an application -- here's a thorough project on the topic: 
Powershell Tunnel
"
330,"I would be a bit reluctant to use nested classes here.  What if you created an abstract base class for a ""multimedia driver"" to handle the back-end stuff (workhorse), and a separate class for the front-end work?  The front-end class could take a pointer/reference to an implemented driver class (for the appropriate media type and situation) and perform the abstract operations on the workhorse structure.
My philosophy would be to go ahead and make both structures accessible to the client in a polished way, just under the assumption they would be used in tandem.
I would reference something like a QTextDocument in Qt.  You provide a direct interface to the bare metal data handling, but pass the authority along to an object like a QTextEdit to do the manipulation.
"
470,"No, what you're doing is fine. Don't let those people confuse you.
If you've written the web services with .net then the reference proxies generated by .net are going to be quite suitable. The situation you describe (where you are both producer and consumer) is the ideal situation.
If you need to connect to a web services that is unknown at compile time, then you would want a more dynamic approach, where you deduce the 'shape' of the web service. 
But start by using the auto generated proxy class, and don't worry about it until you hit a limitation. And when you do -- come back to stack overflow ;-)"
580,"I've taken to hand-coding all of my DDL (creates/alter/delete) statements, adding them to my .sln as text files, and using normal versioning (using subversion, but any revision control should work). This way, I not only get the benefit of versioning, but updating live from dev/stage is the same process for code and database - tags, branches and so on work all the same.
Otherwise, I agree redgate is expensive if you don't have a company buying it for you. If you can get a company to buy it for you though, it really is worth it!"
650,"With the ""Built in"" stuff, you can't, as using 1.0.* or 1.0.0.* will replace the revision and build numbers with a coded date/timestamp, which is usually also a good way. 
For more info, see the Assembly Linker Documentation in the /v tag.
As for automatically incrementing numbers, use the AssemblyInfo Task:
AssemblyInfo Task
This can be configured to automatically increment the build number.
There are 2 Gotchas:

Each of the 4 numbers in the Version string is limited to 65535. This is a Windows Limitation and unlikely to get fixed.

Why are build numbers limited to 65535?

Using with with Subversion requires a small change:

Using MSBuild to generate assembly version info at build time (including SubVersion fix)


Retrieving the Version number is then quite easy:
Version v = Assembly.GetExecutingAssembly().GetName().Version;
string About = string.Format(CultureInfo.InvariantCulture, @""YourApp Version {0}.{1}.{2} (r{3})"", v.Major, v.Minor, v.Build, v.Revision);


And, to clarify: In .net or at least in C#, the build is actually the THIRD number, not the fourth one as some people (for example Delphi Developers who are used to Major.Minor.Release.Build) might expect.
In .net, it's Major.Minor.Build.Revision.
"
810,"I'm guessing that because you want to set it for all users, that you're on some kind of shared computer, which is probably running under a domain?
HERE BE DRAGONS
Let's say Joe and Jane regularly log onto the computer, then they will each have 'registries'.
You'll then install your app, and the installer will employ giant hacks and disgusting things to set items under HKCU for them.
THEN, bob will come along and log on (he, and 500 other people have accounts in the domain and so can do this). He's never used this computer before, so he has no registry. The first time he logs in, windows creates him one, but he won't have your setting. 
Your app then falls over or behaves incorrectly, and bob complains loudly about those crappy products from raynixon incorporated.
The correct answer is to just have some default settings in your app, which can write them to the registry if it doesn't find them. It's general good practice that your app should never depend on the registry, and should create things as needed, for any registry entry, not just HKCU, anyway"
930,"@Goyuix -- that's excellent for something written from memory.
tested it here -- found the connection wasn't opened. Otherwise very nice.
using System.Data.OleDb;
...

using (OleDbConnection conn = new OleDbConnection())
{
    conn.ConnectionString = ""Provider=sqloledb;Data Source=yourServername\\yourInstance;Initial Catalog=databaseName;Integrated Security=SSPI;"";

    using (OleDbCommand cmd = new OleDbCommand())
    {
        conn.Open();
        cmd.Connection = conn;
        cmd.CommandText = ""Select * from yourTable"";

        using (OleDbDataReader dr = cmd.ExecuteReader())
        {
            while (dr.Read())
            {
                Console.WriteLine(dr[""columnName""]);
            }
        }
    }
}

"
1010,"Rex, I suspect a good place to start looking is solutions that compress the ViewState -- they're grabbing ViewState on the server before it's sent down to the client and gzipping it. That's exactly where you want to be.

Scott Hanselman on ViewState Compression (2005)
ViewState Compression with System.IO.Compression (2007)
"
1040,"Killing other processes is not a healthy thing to do. If your scenario involves something like uninstallation, you could use the MoveFileEx API function to mark the file for deletion upon next reboot.
If it appears that you really need to delete a file in use by another process, I'd recommend re-considering the actual problem before considering any solutions.
"
1070,"The exact definitions of ""vsize,"" ""rss,"" ""rprvt,"" ""rshrd,"" and other obscure-looking abbreviations vary from OS to OS.  The manual pages for the ""top"" and ""ps"" commands will have some sort of description, but all such descriptions are simplified greatly (or are based on long-extinct kernel implementations).  ""Process size"" as a concept is fiendishly difficult to pin down in the general case.  Answers in specific instances depend heavily on the actual memory management implementation in the OS, and are rarely as satisfying as the tidy ""process size"" concept that exists in the minds of most users (and most developers).
For example, none of those numbers (nor, likely, any combination of them) can be used to tell you exactly how many such processes can run at once in a given amount of free memory.  But really, your best bet is to come at it from that end: why do you want this number, and what will you use it for?  Given that information, I think you'll get more useful answers."
1160,"CruiseControl.Net 1.4.4 has now an Assembly Version Labeller, which generates version numbers compatible with .Net assembly properties.
In my project I have it configured as:
<labeller type=""assemblyVersionLabeller"" incrementOnFailure=""true"" major=""1"" minor=""2""/>

(Caveat: assemblyVersionLabeller won't start generating svn revision based labels until an actual commit-triggered build occurs.)
and then consume this from my MSBuild projects with MSBuildCommunityTasks.AssemblyInfo :
<Import Project=""$(MSBuildExtensionsPath)\MSBuildCommunityTasks\MSBuild.Community.Tasks.Targets""/>
<Target Name=""BeforeBuild"">
  <AssemblyInfo Condition=""'$(CCNetLabel)' != ''"" CodeLanguage=""CS"" OutputFile=""Properties\AssemblyInfo.cs"" 
  AssemblyTitle=""MyTitle"" AssemblyCompany=""MyCompany"" AssemblyProduct=""MyProduct""
  AssemblyCopyright=""Copyright Â©  2009"" ComVisible=""false"" Guid=""some-random-guid""
  AssemblyVersion=""$(CCNetLabel)"" AssemblyFileVersion=""$(CCNetLabel)""/>
</Target>

For sake of completness, it's just as easy for projects using NAnt instead of MSBuild:
<target name=""setversion"" description=""Sets the version number to CruiseControl.Net label."">
    <script language=""C#"">
        <references>
            <include name=""System.dll"" />
        </references>
        <imports>
            <import namespace=""System.Text.RegularExpressions"" />
        </imports>
        <code><![CDATA[
             [TaskName(""setversion-task"")]
             public class SetVersionTask : Task
             {
              protected override void ExecuteTask()
              {
               StreamReader reader = new StreamReader(Project.Properties[""filename""]);
               string contents = reader.ReadToEnd();
               reader.Close();
               string replacement = ""[assembly: AssemblyVersion(\"""" + Project.Properties[""CCNetLabel""] + ""\"")]"";
               string newText = Regex.Replace(contents, @""\[assembly: AssemblyVersion\("""".*""""\)\]"", replacement);
               StreamWriter writer = new StreamWriter(Project.Properties[""filename""], false);
               writer.Write(newText);
               writer.Close();
              }
             }
             ]]>
        </code>
    </script>
    <foreach item=""File"" property=""filename"">
        <in>
            <items basedir="".."">
                <include name=""**\AssemblyInfo.cs""></include>
            </items>
        </in>
        <do>
            <setversion-task />
        </do>
    </foreach>
</target>

"
1180,"The way we do this is to have a 'catch all' for our domain name registered in DNS so that anything.ourdomain.com will point to our server.
With Apache you can set up a similar catch-all for your vhosts.  The ServerName must be a single static name but the ServerAlias directive can contain a pattern.
Servername www.ourdomain.com
ServerAlias *.ourdomain.com

Now all of the domains will trigger the vhost for our project.  The final part is to decode the domain name actually used so that you can work out the username in your code, something like (PHP):
list( $username ) = explode( ""."", $_SERVER[ ""HTTP_HOST"" ] );

or a RewriteRule as already suggested that silently maps user.ourdomain.com/foo/bar to www.ourdomain.com/foo/bar?user=user or whatever you prefer.
"
1300,"If you are quite happy with MSBuild, then I would stick with MSBuild.  This may be one of those cases where the tool you learn first is the one you will prefer.  I started with NAnt and can't quite get used to MSBuild.  I'm sure they will both be around for quite some time.
There are some fundamental differences between the two, probably best highlighted by this conversation between some NAnt fans and a Microsoftie.
Interestingly, Jeremy Miller asked the exact opposite question on his blog last year.  "
1390,"Not sure how credible this source is, but:

The Windows Server 2008 Core edition can:

Run the file server role.
Run the Hyper-V virtualization server role.
Run the Directory Services role.
Run the DHCP server role.
Run the IIS Web server role.
Run the DNS server role.
Run Active Directory Lightweight Directory Services.
Run the print server role.

The Windows Server 2008 Core edition cannot:

Run a SQL Server.
Run an Exchange Server.
Run Internet Explorer.
Run Windows Explorer.
Host a remote desktop session.
Run MMC snap-in consoles locally.


"
1600,"It is possible to skip the step of creating the empty database. You can create the new database as part of the restore process.
This is actually the easiest and best way I know of to clone a database. You can eliminate errors by scripting the backup and restore process rather than running it through the SQL Server Management Studio
There are two other options you could explore:

Detach the database, copy the .mdf file and re-attach.
Use SQL Server Integration Services (SSIS) to copy all the objects over

I suggest sticking with backup and restore and automating if necessary."
1610,"You can not do this programatically (in a safe way that is) without creating a new table. 
What Enterprise Manager does when you commit a reordering is to create a new table, move the data and then delete the old table and rename the new table to the existing name. 
If you want your columns in a particular order/grouping without altering their physical order, you can create a view which can be whatever you desire."
1760,"There are so many it's crazy.  Crazy good, I guess.

For the conservative types (me), NUnit is still available and still more than capable.
For the Microsoft-types, MSTest is adequate, but slow and clunky compared to Nunit.  It also lacks code coverage without paying the big bucks for the pricey versions of Visual Studio.
There's also MbUnit.  It's like NUnit, but has nifty features like RowTest (run the same test with different parameters) and Rollback (put the database back like you found it after a test) 
And finally, xUnit.net is the trendy option with some attitude.
Oh, and TestDriven.NET will give you IDE integration for both Nunit and MBunit.

I'm sure they're all just fine.  I'd steer away from MSTest though, unless you just enjoy the convenience of having everything in one IDE out of the box.
Scott Hanselman has a podcast on this very topic.
"
1790,"Subversion 1.5 introduced write through proxy support for webdav servers over the existing SvnSync support that was added in 1.4. This allows you to have local mirrors for retrieving files and history, but commits are committed directly to the master repository. If setup correctly the local mirrors receive the changes immediately.
See the Svn Book for more details.
"
1970,"I have only really used PL/pgSQL, but that was because I needed a few stored procedures relatively fast and didn't want to add extra modules to the server.
Longer term, I would probably use PL/Perl or PL/Python, as I use perl for quick scripting and have been looking at python for a while now.
One thing I have found is that there is a lack of good documentation for that on the PostgreSQL site. The manuals were thorough as a reference, but did not work well as a tutorial to help show people how it should be done.
That, combined with a very good debugging environment, meant that my first experience of writing procedures involved looking at weird syntax errors for a long time.
If someone knows of a good site with tutorials etc for PostgreSQL programming, I would love to get a link to it.
"
2120,"I have found the solution else where:
SELECT SUBSTRING(master.dbo.fn_varbintohexstr(HashBytes('MD5', 'HelloWorld')), 3, 32) "
2250,"It really depends on the sort of data you're bringing back.  Since a DataSet is (in effect) just a collection of DataTable objects, you can return multiple distinct sets of data into a single, and therefore more manageable, object.  
Performance-wise, you're more likely to get inefficiency from unoptimized queries than from the ""wrong"" choice of .NET construct.  At least, that's been my experience.
"
2300,"Something like this?
dim cars(2),x
cars(0)=""Volvo""
cars(1)=""Saab""
cars(2)=""BMW""

For Each x in cars
  response.write(x & ""<br />"")
Next

See www.w3schools.com.
If you want to associate keys and values use a dictionary object instead:
Dim objDictionary
Set objDictionary = CreateObject(""Scripting.Dictionary"")
objDictionary.Add ""Name"", ""Scott""
objDictionary.Add ""Age"", ""20""
if objDictionary.Exists(""Name"") then
    ' Do something
else
    ' Do something else 
end if

"
2530,"Firefox 30 ignores autocomplete=""off"" for passwords, opting to prompt the user instead whether the password should be stored on the client. Note the following commentary from May 5, 2014:


The password manager always prompts if it wants to save a password. Passwords are not saved without permission from the user.
We are the third browser to implement this change, after IE and Chrome.


According to Mozilla developer documentation the form element attribute autocomplete prevents form data from being cached in older browsers.
<input type=""text"" name=""foo"" autocomplete=""off"" />

"
2540,"The Glib library used on the Gnome project may also be some use. Moreover it is pretty well tested.
IBM developer works has a good tutorial on its use: Manage C data using the GLib collections
"
2550,"Flash is certainly the most ubiquitous and portable solution.  98% of browsers have Flash installed.  Other alternatives are Quicktime, Windows Media Player, or even Silverlight (Microsoft's Flash competitor, which can be used to embed several video formats).
I would recommend using Flash (and it's FLV video file format) for embedding your video unless you have very specific requirements as far as video quality or DRM."
2630,"there's an out-twitter script i use for posting to twitter. it's nice, as it means you can send something to twitter without the risk of being distracted by a browser.
i added an alias for it, ""twit"".
so now you can type, for example:
PS C:\>""trying out stack overflow"" | twit
and if successfully lodged, it will return an integer that identifies your post."
2750,"Well, one of the reaons why classes usually contain private members with public getters/setters is exactly because they can verify data.
If you have a Number than can be between 1 and 100, i would definitely put something in the setter that validates that and then maybe throw an exception that is being caught by the code. The reason is simple: If you don't do it in the setter, you have to remember that 1 to 100 limitation every time you set it, which leads to duplicated code or when you forget it, it leads to an invalid state.
As for performance, i'm with Knuth here:

""We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil.""
"
2770,"You need to handle the System.Windows.Forms.Application.ThreadException event for Windows Forms. This article really helped me: http://bytes.com/forum/thread236199.html.
"
2780,"It's called alpha blending.
In psuedocode, assuming the background color (blend) always has 255 alpha. Also assumes alpha is 0-255.
alpha=argb.alpha()r = (alpha/255)*argb.r() + (1 - alpha/255)*blend.r()g = (alpha/255)*argb.g() + (1 - alpha/255)*blend.g()b = (alpha/255)*argb.b() + (1 - alpha/255)*blend.b()
note: you probably need to be a bit (more) careful about floating-point/int math and rounding issues, depending on language. Cast intermediates accordingly
Edited to add:
If you don't have a background color with an alpha of 255, the algebra gets alot more complicated. I've done it before and it's a fun exercise left to the reader (if you really need to know, ask another question :). 
In other words, what color C blends into some background the same as blending A, then blending B. This is sort of like calculating A+B (which isn't the same as B+A)."
2840,"You can use the Row_Number() function.
Its used as follows:
SELECT Row_Number() OVER(ORDER BY UserName) As RowID, UserFirstName, UserLastName
FROM Users

From which it will yield a result set with a RowID field which you can use to page between.
SELECT * 
FROM 
    ( SELECT Row_Number() OVER(ORDER BY UserName) As RowID, UserFirstName, UserLastName
      FROM Users 
    ) As RowResults
WHERE RowID Between 5 AND 10

etc
"
2900,"
And if it matters at all, apache@localhost is not the name of the user account that I use to get into the database. I don't have any user accounts with the name apache in them at all for that matter.

If it is saying 'apache@localhost' the username is not getting passed correctly to the MySQL connection. 'apache' is normally the user that runs the httpd process (at least on Redhat-based systems) and if no username is passed during the connection MySQL uses whomever is calling for the connection.
If you do the connection right in your script, not in a called file, do you get the same error?"
2970,"I know this is a little late in the game, but the URL mentioned for the JavaScript is mentioned in a list of sites known to have been part of the ASPRox bot resurgence that started up in June (at least that's when we were getting flagged with it). Some details about it are mentioned below:
http://www.bloombit.com/Articles/2008/05/ASCII-Encoded-Binary-String-Automated-SQL-Injection.aspx 
The nasty thing about this is that effectively every varchar type field in the database is ""infected"" to spit out a reference to this URL, in which the the browser gets an tiny iframe that turns it into a bot. A basic SQL fix for this can be found here:
http://aspadvice.com/blogs/programming_shorts/archive/2008/06/27/Asprox-Recovery.aspx
The scary thing though is that the virus looks to the system tables for values to infect and a lot of shared hosting plans also share the database space for their clients. So most likely it wasn't even your dad's site that was infected, but somebody else's site within his hosting cluster that wrote some poor code and opened the door to SQL Injection attack.
If he hasn't done so yet, I'd send an URGENT e-mail to their host and give them a link to that SQL code to fix the entire system. You can fix your own affected database tables, but most likely the bots that are doing the infection are going to pass right through that hole again and infect the whole lot.
Hopefully this gives you some more info to work with.
EDIT: One more quick thought, if he's using one of the hosts online design tools for building his website, all of that content is probably sitting in a column and was infected that way."
3150,"This page may help, it reviews quite a few C++ unit test frameworks:

CppUnit  
Boost.Test
CppUnitLite 
NanoCppUnit
Unit++
CxxTest

Check out CPPUnitLite or CPPUnitLite2. 
CPPUnitLite was created by Michael Feathers, who originally ported Java's JUnit to C++ as CPPUnit (CPPUnit tries mimic the development model of JUnit - but C++ lacks Java's features [e.g. reflection] to make it easy to use). 
CPPUnitLite attempts to make a true C++-style testing framework, not a Java one ported to C++. (I'm paraphrasing from Feather's Working Effectively with Legacy Code book). CPPUnitLite2 seems to be another rewrite, with more features and bug fixes.
I also just stumbled across UnitTest++ which includes stuff from CPPUnitLite2 and some other framework.
Microsoft has released WinUnit. 
Also checkout Catch or Doctest
"
3180,"I use it, especially since the hosted Version of FugBugz is free for up to 2 people. I found it a lot nicer than paper as I'm working on multiple projects, and my paper tends to get rather messy once you start making annotations or if you want to re-organize and shuffle tasks around, mark them as complete only to see that they are not complete after all...
Plus, the Visual Studio integration is really neat, something paper just cannot compete with. Also, if you lay the project to rest for 6 months and come back, all your tasks and notes are still there, whereas with paper you may need to search all the old documents and notes again, if you did not discard it.
But that is just the point of view from someone who is not really good at staying organized :-) If you are a really tidy and organized person, paper may work better for you than it does for me.
Bonus suggestion: Run Fogbugz on a second PC (or a small Laptop like the eeePC) so that you always have it at your fingertips. The main problem with Task tracking programs - be it FogBugz, Outlook, Excel or just notepad - is that they take up screen space, and my two monitors are usually full with Visual Studio, e-Mail, Web Browsers, some Notepads etc.
"
3230,"
Choose Project -> Properties
Select Configuration -> General
In the box for how you should link MFC, choose to statically link it.
Choose Linker -> Input.  Under Additional Dependencies, add any libraries you need your app to statically link in.

For more info, see this article: http://www.geekadmin.com/?p=34
"
3260,"There are lots and lots of classic peak detection methods, any of which might work.  You'll have to see what, in particular, bounds the quality of your data.  Here are basic descriptions:

Between any two points in your data, (x(0),y(0)) and (x(n),y(n)), add up y(i+1)-y(i) for 0 <= i < n and call this T (""travel"") and set R (""rise"") to y(n)- y(0) + k for suitably small k.  T/R > 1 indicates a peak.  This works OK if large travel due to noise is unlikely or if noise distributes symmetrically around a base curve shape.  For your application, accept the earliest peak with a score above a given threshold, or analyze the curve of travel per rise values for more interesting properties.
Use matched filters to score similarity to a standard peak shape (essentially, use a normalized dot-product against some shape to get a cosine-metric of similarity)
Deconvolve against a standard peak shape and check for high values (though I often find 2 to be less sensitive to noise for simple instrumentation output).
Smooth the data and check for triplets of equally spaced points where, if x0 < x1 < x2, y1 > 0.5*(y0+y2), or check Euclidean distances like this:  D((x0,y0),(x1,y1)) + D((x1,y1),(x2,y2)) > D((x0,y0),(x2,y2)), which relies on the triangle inequality.  Using simple ratios will again provide you a scoring mechanism.
Fit a very simple 2-gaussian mixture model to your data (for example, Numerical Recipes has a nice ready-made chunk of code).  Take the earlier peak.  This will deal correctly with overlapping peaks.
Find the best match in the data to a simple Gaussian, Cauchy, Poisson, or what-have-you curve.  Evaluate this curve over a broad range and subtract it from a copy of the data after noting it's peak location.  Repeat.  Take the earliest peak whose model parameters (standard deviation probably, but some applications might care about kurtosis or other features) meet some criterion.  Watch out for artifacts left behind when peaks are subtracted from the data.
Best match might be determined by the kind of match scoring suggested in #2 above.

I've done what you're doing before:  finding peaks in DNA sequence data, finding peaks in derivatives estimated from measured curves, and finding peaks in histograms.
I encourage you to attend carefully to proper baselining.  Wiener filtering or other filtering or simple histogram analysis is often an easy way to baseline in the presence of noise.
Finally, if your data is typically noisy and you're getting data off the card as unreferenced single-ended output (or even referenced, just not differential), and if you're averaging lots of observations into each data point, try sorting those observations and throwing away the first and last quartile and averaging what remains.  There are a host of such outlier elimination tactics that can be really useful.
"
3400,"Workaround only for leading wildcard:

store the text reversed in a different field (or in materialised view)
create a full text index on this column
find the reversed text with an *
SELECT * 
FROM TABLENAME 
WHERE CONTAINS(TextColumnREV, '""mrethcraes*""');


Of course there are many drawbacks, just for quick workaround...
Not to mention CONTAINSTABLE...
"
3470,"You should take a look at the UNPIVOT clause.
Update1: GateKiller, strangely enough I read an article (about something unrelated) about it this morning and I'm trying to jog my memory where I saw it again, had some decent looking examples too. It'll come back to me I'm sure.
Update2: Found it: http://weblogs.sqlteam.com/jeffs/archive/2008/04/23/unpivot.aspx"
3510,"http://www.easymaths.com/What_on_earth_is_Bodmas.htm:

What do you think the answer to 2 + 3 x 5 is?
Is it (2 + 3) x 5 = 5 x 5 = 25 ?
or 2 + (3 x 5) = 2 + 15 = 17 ?
BODMAS can come to the rescue and give us rules to follow so that we always get the right answer:
(B)rackets (O)rder (D)ivision (M)ultiplication (A)ddition (S)ubtraction
According to BODMAS, multiplication should always be done before addition, therefore 17 is actually the correct answer according to BODMAS and will also be the answer which your calculator will give if you type in 2 + 3 x 5 .

Why it is useful in programming? No idea, but i assume it's because you can get rid of some brackets? I am a quite defensive programmer, so my lines can look like this:
result = (((i + 4) - (a + b)) * MAGIC_NUMBER) - ANOTHER_MAGIC_NUMBER;

with BODMAS you can make this a bit clearer:
result = (i + 4 - (a + b)) * MAGIC_NUMBER - ANOTHER_MAGIC_NUMBER;

I think i'd still use the first variant - more brackets, but that way i do not have to learn yet another rule and i run into less risk of forgetting it and causing those weird hard to debug errors?
Just guessing at that part though.
Mike Stone EDIT: Fixed math as Gaius points out
"
3530,"from timocracy.com:
require 'rake'
require 'rake/rdoctask'
require 'rake/testtask'
require 'tasks/rails'

def capture_stdout
  s = StringIO.new
  oldstdout = $stdout
  $stdout = s
  yield
  s.string
ensure
  $stdout = oldstdout
end

Rake.application.rake_require '../../lib/tasks/metric_fetcher'
results = capture_stdout {Rake.application['metric_fetcher'].invoke}
"
3790,"You didn't mention for what OS, but the WMI Redistributable Components version 1.0 definitely exists.
For Windows Server 2003, the WMI SDK and redistributables are part of the Server SDK
I believe that the same is true for the Server 2008 SDK"
4080,"For static analysis tools I often use CPD, PMD, FindBugs, and Checkstyle.
CPD is the PMD ""Copy/Paste Detector"" tool. I was using PMD for a little while before I noticed the ""Finding Duplicated Code"" link on the PMD web page.
I'd like to point out that these tools can sometimes be extended beyond their ""out-of-the-box"" set of rules. And not just because they're open source so that you can rewrite them. Some of these tools come with applications or ""hooks"" that allow them to be extended. For example, PMD comes with the ""designer"" tool that allows you to create new rules. Also, Checkstyle has the DescendantToken check that has properties that allow for substantial customization.
I integrate these tools with an Ant-based build. You can follow the link to see my commented configuration.
In addition to the simple integration into the build, I find it helpful to configure the tools to be somewhat ""integrated"" in a couple of other ways. Namely, report generation and warning suppression uniformity. I'd like to add these aspects to this discussion (which should probably have the ""static-analysis"" tag also): how are folks configuring these tools to create a ""unified"" solution? (I've asked this question separately here)
First, for warning reports, I transform the output so that each warning has the simple format:
/absolute-path/filename:line-number:column-number: warning(tool-name): message
This is often called the ""Emacs format,"" but even if you aren't using Emacs, it's a reasonable format for homogenizing reports. For example:
/project/src/com/example/Foo.java:425:9: warning(Checkstyle):Missing a Javadoc comment.
My warning format transformations are done by my Ant script with Ant filterchains.
The second ""integration"" that I do is for warning suppression. By default, each tool supports comments or an annotation (or both) that you can place in your code to silence a warning that you want to ignore. But these various warning suppression requests do not have a consistent look which seems somewhat silly. When you're suppressing a warning, you're suppressing a warning, so why not always write ""SuppressWarning?""
For example, PMD's default configuration suppresses warning generation on lines of code with the string ""NOPMD"" in a comment. Also, PMD supports Java's @SuppressWarnings annotation. I configure PMD to use comments containing ""SuppressWarning(PMD."" instead of NOPMD so that PMD suppressions look alike. I fill in the particular rule that is violated when using the comment style suppression:
// SuppressWarnings(PMD.PreserveStackTrace) justification: (false positive) exceptions are chained
Only the ""SuppressWarnings(PMD."" part is significant for a comment, but it is consistent with PMD's support for the @SuppressWarning annotation which does recognize individual rule violations by name:
@SuppressWarnings(""PMD.CompareObjectsWithEquals"") // justification: identity comparision intended
Similarly, Checkstyle suppresses warning generation between pairs of comments (no annotation support is provided). By default, comments to turn Checkstyle off and on contain the strings CHECKSTYLE:OFF and CHECKSTYLE:ON, respectively. Changing this configuration (with Checkstyle's ""SuppressionCommentFilter"") to use the strings ""BEGIN SuppressWarnings(CheckStyle."" and ""END SuppressWarnings(CheckStyle."" makes the controls look more like PMD:

// BEGIN SuppressWarnings(Checkstyle.HiddenField) justification: ""Effective Java,"" 2nd ed., Bloch, Item 2
// END SuppressWarnings(Checkstyle.HiddenField)

With Checkstyle comments, the particular check violation (HiddenField) is significant because each check has its own ""BEGIN/END"" comment pair.
FindBugs also supports warning generation suppression with a @SuppressWarnings annotation, so no further configuration is required to achieve some level of uniformity with other tools. Unfortunately, Findbugs has to support a custom @SuppressWarnings annotation because the built-in Java @SuppressWarnings annotation has a SOURCE retention policy which is not strong enough to retain the annotation in the class file where FindBugs needs it. I fully qualify FindBugs warnings suppressions to avoid clashing with Java's @SuppressWarnings annotation:
@edu.umd.cs.findbugs.annotations.SuppressWarnings(""UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR"")
These techniques makes things look reasonably consistent across tools. Note that having each warning suppression contain the string ""SuppressWarnings"" makes it easy to run a simple search to find all instances for all tools over an entire code base.
"
4110,"I am a big fan of Embarcadero's ER/Studio.  It is very powerful and produces excellent on-screen as well as printed results.  They have a free trial as well, so you should be able to get in and give it a shot without too much strife.
Good luck!
"
4170,"There are three key components (assuming ur using SQL server):

SQLConnection
SqlCommand
SqlDataReader

(if you're using something else, replace Sql with ""Something"", like MySqlConnection, OracleCommand)
Everything else is just built on top of that.
Example 1:
using (SqlConnection connection = new SqlConnection(""CONNECTION STRING""))
using (SqlCommand command = new SqlCommand())
{
  command.commandText = ""SELECT Name FROM Users WHERE Status = @OnlineStatus"";
  command.Connection = connection;
  command.Parameters.Add(""@OnlineStatus"", SqlDbType.Int).Value = 1; //replace with enum
  connection.Open();

  using (SqlDataReader dr = command.ExecuteReader))
  {
      List<string> onlineUsers = new List<string>();

      while (dr.Read())
      {
         onlineUsers.Add(dr.GetString(0));
      }
  }
}

Example 2:
using (SqlConnection connection = new SqlConnection(""CONNECTION STRING""))
using (SqlCommand command = new SqlCommand())
{
  command.commandText = ""DELETE FROM Users where Email = @Email"";
  command.Connection = connection;
  command.Parameters.Add(""@Email"", SqlDbType.VarChar, 100).Value = ""user@host.com"";
  connection.Open();
  command.ExecuteNonQuery();
}

"
4230,"DataGrid was an ASP.NET 1.1 control, still supported. GridView arrived in 2.0, made certain tasks simpler added different databinding features:
This link has a comparison of DataGrid and GridView features -
https://msdn.microsoft.com/en-us/library/05yye6k9(v=vs.100).aspx
"
4320,"It's acceptable as long as you understand the consequences. The main reason you'd have a BLL is to re-use that logic elsewhere throughout your application.
If you have all that validation logic in the presentation code, you're really making it difficult to re-use elsewhere within your application."
4430,"In PHP 5 you can use SoapClient on the WSDL to call the web service functions. For example:
$client = new SoapClient(""some.wsdl"");

and $client is now an object which has class methods as defined in some.wsdl. So if there was a method called getTime in the WSDL then you would just call:
$result = $client->getTime();

And the result of that would (obviously) be in the $result variable. You can use the __getFunctions method to return a list of all the available methods.
"
4610,"You can't dynamically add methods to existing objects or classes in .NET, except by changing the source for that class.
You can, however, in C# 3.0, use extension methods, which look like new methods, but are compile-time magic.
To do this for your code:
public static class StringExtensions{    public static String trim(this String s)    {        return s.Trim();    }}
To use it:
String s = ""  Test  "";s = s.trim();
This looks like a new method, but will compile the exact same way as this code:
String s = ""  Test  "";s = StringExtensions.trim(s);
What exactly are you trying to accomplish? Perhaps there are better ways of doing what you want?"
4630,"I'm not sure if this would be handled exactly the same way for webstart, but we ran into this situation in a desktop application when dealing with a set of native libraries (dlls in our case).
Loading libA before libB should work, unless one of those libraries has a dependency that is unaccounted for and not in the path. My understanding is that once it gets to a system loadLibrary call (i.e. Java has found the library in its java.library.path and is now telling the OS to load it) - it is completely dependent on the operating system to find any dependent libraries, because at that point it is the operating system that is loading the library for the process, and the OS only knows how to look in the system path. That seems hard to set in the case of a Webstart app, but there is a way around this that does not involve static compiling. You may be able to shuffle where your libraries are - I am unsure 
If you use a custom classloader, you can override loadLibrary and findLibrary so that it can locate your libraries from within a jar in your classpath, and if you also make it aware of your native library dependencies (i.e. libB depends on libA depends on libX, then when loading libB you can catch yourself and ensure you load libA first, and in checking that notice and load libX first. Then the OS doesn't try to find a library that isn't in your path. It's klunky and a bit painful, but ensuring Java finds them and loads them all in the correct order can work."
4670,"I use msys-git on windows every single day. Works fast and flawlessly.
Although the newer build has some problems with git-svn, this build (Git-1.5.5-preview20080413.exe) has a working git-svn."
4850,"Within your overridden ProcessCmdKey how are you determining which key has been pressed?
The value of keyData (the second parameter) will change dependant on the key pressed and any modifier keys, so, for example, pressing the left arrow will return code 37, shift-left will return 65573, ctrl-left 131109 and alt-left 262181.
You can extract the modifiers and the key pressed by ANDing with appropriate enum values:protected override bool ProcessCmdKey(ref Message msg, Keys keyData)
{
    bool shiftPressed = (keyData & Keys.Shift) != 0;
    Keys unmodifiedKey = (keyData & Keys.KeyCode);

    // rest of code goes here
}
"
4870,"The reason why #1 is slower is that [\d;]+ is a greedy quantifier. Using +? or *? is going to do lazy quantifing. See MSDN - Quantifiers for more info.
You may want to try:
""(\e\[(\d{1,2};)*?[mz]?)?""
That may be faster for you."
4880,"I've seen plenty of people type their email address wrong and I've also looked through user databases full of invalid email address.
The way I see it you've got two options.  Use a second box to confirm the input, or send an authentication/activation email.
Both are annoyances so you get to choose which you think will annoy your users less.
Most would argue that having to find an email and click on a link is more annoying, but it avoids the copy/paste a bad address issue, and it allows you to do things like delete or roll back users if they don't activate after say 48 hours."
4930,"Well the link for Compiler Error CS0433 makes it pretty clear that the core issue is not with multiple versions of the assembly being referenced - but with namespace + typename conflicts.
When you load up / reference a type - the compiler can't resolve which DLL to load that type from. If Sharepoint is going to load both your DLLs versions (as you say it needs to) - this error will always come.
Simplest fix would be to change the namespaces in the new DLL, since it does have your custom tweaks, and you control the code - mark it clearly as well.
"
5170,"I've started using LinqPad. In addition to being more lightweight than SSMS, you can also practice writing LINQ queries- way more fun than boring old TSQL!"
5260,"You should probably write some automated tests for each condition you can think of, and then just start brainstorming more, writing the tests as you think of them.  This way, you can see for sure it will work, and will continue to work if you make further changes.  Look up Test Driven Development if you like the results."
5460,"I've done quite a few projects using Community Server. If you're okay with the out-of-the-box functionality, or you don't mind sticking to the version you start with, I think you'll be very happy.
The times I've run into headaches using CS is when the client wants functionality CS does not provide, but also insists on keeping the ability to upgrade to the latest version whenever Telligent releases an update. You can mostly support that by making all of your changes either in a separate project or by only modifying aspx/ascx files (no codebehinds). Some kind of merge is going to be required though no matter how well you plan it out."
5600,"When dealing with indexes, you have to determine what your table is going to be used for.  If you are primarily inserting 1000 rows a second and not doing any querying, then a clustered index is a hit to performance.  If you are doing 1000 queries a second, then not having an index will lead to very bad performance.  The best thing to do when trying to tune queries/indexes is to use the Query Plan Analyzer and SQL Profiler in SQL Server.  This will show you where you are running into costly table scans or other performance blockers.
As for the GUID vs ID argument, you can find people online that swear by both.  I have always been taught to use GUIDs unless I have a really good reason not to.  Jeff has a good post that talks about the reasons for using GUIDs: http://www.codinghorror.com/blog/archives/000817.html.
As with most anything development related, if you are looking to improve performance there is not one, single right answer.  It really depends on what you are trying to accomplish and how you are implementing the solution.  The only true answer is to test, test, and test again against performance metrics to ensure that you are meeting your goals.
[Edit]
@Matt, after doing some more research on the GUID/ID debate I came across this post.  Like I mentioned before, there is not a true right or wrong answer.  It depends on your specific implementation needs.  But these are some pretty valid reasons to use GUIDs as the primary key:

For example, there is an issue known as a ""hotspot"", where certain pages of data in a table are under relatively high currency contention. Basically, what happens is most of the traffic on a table (and hence page-level locks) occurs on a small area of the table, towards the end. New records will always go to this hotspot, because IDENTITY is a sequential number generator. These inserts are troublesome because they require Exlusive page lock on the page they are added to (the hotspot). This effectively serializes all inserts to a table thanks to the page locking mechanism. NewID() on the other hand does not suffer from hotspots. Values generated using the NewID() function are only sequential for short bursts of inserts (where the function is being called very quickly, such as during a multi-row insert), which causes the inserted rows to spread randomly throughout the table's data pages instead of all at the end - thus eliminating a hotspot from inserts.
Also, because the inserts are randomly distributed, the chance of page splits is greatly reduced. While a page split here and there isnt too bad, the effects do add up quickly. With IDENTITY, page Fill Factor is pretty useless as a tuning mechanism and might as well be set to 100% - rows will never be inserted in any page but the last one. With NewID(), you can actually make use of Fill Factor as a performance-enabling tool. You can set Fill Factor to a level that approximates estimated volume growth between index rebuilds, and then schedule the rebuilds during off-peak hours using dbcc reindex. This effectively delays the performance hits of page splits until off-peak times.
If you even think you might need to enable replication for the table in question - then you might as well make the PK a uniqueidentifier and flag the guid field as ROWGUIDCOL. Replication will require a uniquely valued guid field with this attribute, and it will add one if none exists. If a suitable field exists, then it will just use the one thats there.
Yet another huge benefit for using GUIDs for PKs is the fact that the value is indeed guaranteed unique - not just among all values generated by this server, but all values generated by all computers - whether it be your db server, web server, app server, or client machine. Pretty much every modern language has the capability of generating a valid guid now - in .NET you can use System.Guid.NewGuid. This is VERY handy when dealing with cached master-detail datasets in particular. You dont have to employ crazy temporary keying schemes just to relate your records together before they are committed. You just fetch a perfectly valid new Guid from the operating system for each new record's permanent key value at the time the record is created. 
http://forums.asp.net/t/264350.aspx
"
5690,What type is selectedYear? A DateTime? If so then you might need to convert to a string.
5880,"I guess a fairly big downside is that the extra volume of code that you have to write, manage and maintain for a small project may just be overkill.
It's all down to what's appropriate for the size of the project, the expected life of the final project and the budget!  Sometimes, whilst doing things 'properly' is appealing, doing something a little more 'lightweight' can be the right commercial decision!
"
6080,"EMAIL ADDRESS
Rational

Users don't change emails very often
Removes the step of asking for username and email address, which you'll need anyway
Users don't often forget their email address (see number one)
Email will be unique unless the user already registered for the site, in which case forward them to a forgot your password screen
Almost everyone is using email as the primary login for access to a website, this means the rate of adoption shouldn't be affected by the fact that you're asking for an email address


Update
After registration, be sure to ask the user to create some kind of username, don't litter a public site with their email address! Also, another benefit of using an email address as a login: you won't need any other information (like password / password confirm), just send them a temp password through the mail, or forgo passwords altogether and send them a one-use URL to their email address every time they'd like to login (see: mugshot.org)"
6110,"I've had to do this before. The only real way to do it is to manually match up the various locations. Use your database's console interface and grouping select statements. First, add your ""Company Name"" field. Then:
SELECT count(*) AS repcount, ""Location Name"" FROM mytable WHERE ""Company Name"" IS NULL GROUP BY ""Location Name"" ORDER BY repcount DESC LIMIT 5;
Figure out what company the location at the top of the list belongs to and then update your company name field with an UPDATE ... WHERE ""Location Name"" = ""The Location"" statement.
P.S. - You should really break your company names and location names out into separate tables and refer to them by their primary keys.
Update: - Wow - no duplicates? How many records do you have?"
6130,"The file in the .svn directory that keeps track of what you have checked out, when, what revision, and from where, has gotten corrupted somehow, for that particular file.
This is no more dangerous or critical than the normal odd file problem, and can be because of various problems, like a subversion program dying mid-change, power-disruption, etc.
Unless it happens more I wouldn't make much out of it.
It can be fixed by doing what you did, make a copy of your work-files, check out a fresh copy, and add the modified files back in.
Note that this might cause problems if you have a busy project where you would normally have to merge in changes.
For instance, you and a collegue both check out a fresh copy, and start working on the same file. At some point, your collegue checks in his modifications. When you attempt to do the same, you get the checksum problem you have. If you now make copies of your changed files, do a fresh checkout, then subversion will lose track of how your changes should be merged back in.
If you didn't get the problem in this case, when you got around to checkin in your modifications, you would need to update your working copy first, and possibly handle a conflict with your file.
However, if you do a fresh checkout, complete with your collegues changes, it now looks like you removed his changes and substituted with your own. No conflicts, and no indications from subversion that something is amiss."
6210,"From a high level, yes.  :D  The main thing is some place to store the templates.  A database is a great option unless you're not already using one, then file systems work fine.
WSIWIG editors (such as fckeditor) work well and give you some good options regarding the features that you allow.
Some sort of token replacement system is also a good idea if you need it.  For example, if someone puts %FIRSTNAME% in the email template, the code that generates the email can do some simple pattern matching to replace known tokens with other known values that may be dynamic based on user or other circumstances."
6340,"You defined the primary key twice. Try:
CREATE TABLE SHIPPING_GRID(  
    id INT NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'Unique ID for each row',  
    shipping_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the shipping vendor (vendors_type must be 3)',  
    start_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the vendor being shipped from',  
    end_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to the VENDOR.no for the vendor being shipped to',  
    shipment_duration INT(1) DEFAULT 1 COMMENT 'Duration in whole days shipment will take',  
    price FLOAT(5,5) NOT NULL COMMENT 'Price in US dollars per shipment lbs (down to 5 decimal places)',  
    is_flat_rate TINYINT(1) DEFAULT 0 COMMENT '1 if is flat rate regardless of weight, 0 if price is by lbs',  
    INDEX (shipping_vendor_no),  
    INDEX (start_vendor_no),  
    INDEX (end_vendor_no),  
    FOREIGN KEY (shipping_vendor_no) REFERENCES VENDOR (no),  
    FOREIGN KEY (start_vendor_no) REFERENCES VENDOR (no),  
    FOREIGN KEY (end_vendor_no) REFERENCES VENDOR (no)  
) TYPE = INNODB;

The VENDOR primary key must be INT(6), and both tables must be of type InnoDB.
"
6430,"foreach(var row in DataGrid1.Rows)
{
  DoStuff(row);
}
//Or ---------------------------------------------   
foreach(DataGridRow row in DataGrid1.Rows)
{
  DoStuff(row);
}
//Or ---------------------------------------------
for(int i = 0; i< DataGrid1.Rows.Count - 1; i++)
{
  DoStuff(DataGrid1.Rows[i]);
}

"
6440,"That's one of the sad reasons i'm still targeting .net 2.0 whenever possible :/
But people don't neccessarily need the full 200 MB Package. There is a 3 MB Bootstrapper which will only download the required components:
.net 3.5 SP1 Bootstrapper
However, the worst case scenario is still a pretty hefty download. Also, see this article for a more detailed explanation on the size and an alternative workaround to the size problem.
Addition: Since answering this question, Scott Hanselman created SmallestDotNet.com, which will determine the smallest required download. Doesn't change the worst case scenario, but is still useful to know.
"
6530,App_Data folder on the root of the project. It isn't served to web requests; so other people can't snoop for it.
6890,"How much order do you need to impose on the threads? If you just need all of the work started in the loop to finish before the code continues, but you don't care about the order the work within the loop finishes, then calling Join is the answer. To add more detail to Kevin Kenny's answer, you should call Join outside the loop. This means you will need a collection to hold references to the threads you started:
// Start all of the threads.
List<Thread> startedThreads = new List<Thread>();
foreach (...) {
  Thread thread = new Thread(new ThreadStart(MyMethod));
  thread.Start();
  startedThreads.Add(thread);
}

// Wait for all of the threads to finish.
foreach (Thread thread in startedThreads) {
  thread.Join();
}

In contrast, if you called Join inside the loop, the result would basically be the same as not using threads at all. Each iteration of the loop body would create and start a thread but then immediately Join it and wait for it to finish.
If the individual threads produce some result (write a message in a log, for example) then the messages may still appear out of order because there's no coordination between the threads. It is possible to get the threads to output their results in order by coordinating them with a Monitor.
"
7180,"Silverlight springs to mind as an obvious choice if you want to do animation using .NET on the web. It may not cover all platforms but will work in IE and FireFox and on the Mac.
"
7190,"Take a look at Hudson. It's highly customizable, and, IMHO, easier than CruiseControl.
"
7260,"If you have SSH installed, you should be able to run..
ssh-keygen

Then go through the steps, you'll have two files, id_rsa and id_rsa.pub (the first is your private key, the second is your public key - the one you copy to remote machines)
Then, connect to the remote machine you want to login to, to the file ~/.ssh/authorized_keys add the contents of your that id_rsa.pub file.
Oh, and chmod 600 all the id_rsa* files (both locally and remote), so no other users can read them:
chmod 600 ~/.ssh/id_rsa*

Similarly, ensure the remote ~/.ssh/authorized_keys file is chmod 600 also:
chmod 600 ~/.ssh/authorized_keys

Then, when you do ssh remote.machine, it should ask you for the key's password, not the remote machine.

To make it nicer to use, you can use ssh-agent to hold the decrypted keys in memory - this means you don't have to type your keypair's password every single time. To launch the agent, you run (including the back-tick quotes, which eval the output of the ssh-agent command)
`ssh-agent`

On some distros, ssh-agent is started automatically. If you run echo $SSH_AUTH_SOCK and it shows a path (probably in /tmp/) it's already setup, so you can skip the previous command.
Then to add your key, you do
ssh-add ~/.ssh/id_rsa

and enter your passphrase. It's stored until you remove it (using the ssh-add -D command, which removes all keys from the agent)
"
7440,"I'm a huge fan of Selenium. Saying 'unit-testing your web ui' isn't exactly accurate as some of the comments have mentioned. However, I do find Selenium to be incredibly useful for performing those sort of acceptance and sanity tests on the UI.
A good way to get started is using Selenium IDE as part of your development. Ie, just have the IDE open as you're developing and write your test as you go to cut down on your dev time. (Instead of having to manually go through the UI to get to the point where you can test whatever you're working on, just hit a button and Selenium IDE will take care of that for you. It's a terrific time-saver!)
Most of my major use case scenarios have Selenium RC tests to back them up. You can't really think of them as unit-tests along the lines of an xUnit framework, but they are tests targetted to very specific functionality. They're quick to write (especially if you implement common methods for things like logging in or setting up your test cases), quick to run, and provide a very tight feedback loop. In those senses Selenium RC tests are very similar to unit-tests.
I think, like anything else, if you put the effort into properly learning a test tool (eg, Selenium), your effort will pay off in spades. You mention that your company already uses Selenium to do UI testing. This is great. Work with it. If you find Selenium hard to use, or confusing, stick with it. The learning curve really isn't all that steep once you learn the API a little bit.
If I'm working on a web app, its rare for me to write a significant amount of code without Selenium RC tests to back it up. That's how effective I find Selenium. :) (Hopefully that'll answer your question..)
"
7470,"My eventual (and hopefully temporary) solution to this problem was a Python CGI script.  My script follows for anyone who might find it useful (despite the fact that this is a total hack).  
#!/usr/bin/python
""""""A CGI script to produce an RSS feed of top-level Gallery2 albums.""""""

#import cgi
#import cgitb; cgitb.enable()
from time import gmtime, strftime
import MySQLdb

ALBUM_QUERY = '''
    select g_id, g_title, g_originationTimestamp
    from g_Item
    where g_canContainChildren = 1 
    order by g_originationTimestamp desc
    limit 0, 20
    '''

RSS_TEMPLATE = '''Content-Type: text/xml

<?xml version=""1.0""?>
<rss version=""2.0"">
  <channel>
    <title>TITLE</title>
    <link><http://example.com/gallery2/main.php></link>
    <description>DESCRIPTION</description>
    <ttl>1440</ttl>
%s
  </channel>
</rss>
'''

ITEM_TEMPLATE = '''
    <item>
      <title>%s</title>
      <link><http://example.com/gallery2/main.php?g2_itemId=%s></link>
      <description>%s</description>
      <pubDate>%s</pubDate>
    </item>
'''

def to_item(row):
    item_id = row[0]
    title = row[1]
    date = strftime(""%a, %d %b %Y %H:%M:%S GMT"", gmtime(row[2]))
    return ITEM_TEMPLATE % (title, item_id, title, date)

conn = MySQLdb.connect(host = ""HOST"",
                       user = ""USER"",
                       passwd = ""PASSWORD"",
                       db = ""DATABASE"")
curs = conn.cursor()
curs.execute(ALBUM_QUERY)
print RSS_TEMPLATE % ''.join([ to_item(row) for row in curs.fetchall() ])
curs.close()

"
7540,"It's probably the awesome firefox3 fsync ""bug"", which is a giant pile of fail.
In summary

Firefox3 saves its bookmarks and history in an SQLite database
Every time you load a page it writes to this database several times
SQLite cares deeply that you don't lose your bookmarks, so each time it writes, instructs the kernel to flush it's database file to disk and ensure that it's fully written
Many variants of linux, when told to flush like that, flush EVERY FILE. This may take up to a minute or more if you have background tasks doing any kind of disk intensive stuff.
The kernel makes firefox wait while this flush happens, which locks up the UI.

"
7720,"To follow up on pauxu's answer, I'm using launch4j and NSIS on a project of mine and thought it would be helpful to show just how I'm using them.  Here's what I'm doing for Windows.  BTW, I'm creating .app and .dmg for Mac, but haven't figured out what to do for Linux yet.
Project Copies of launch4j and NSIS
In my project I have a ""vendor"" directory and underneath it I have a directory for ""launch4j"" and ""nsis"".  Within each is a copy of the install for each application.  I find it easier to have a copy local to the project rather than forcing others to install both products and set up some kind of environment variable to point to each.
Script Files
I also have a ""scripts"" directory in my project that holds various configuration/script files for my project.  First there is the launch4j.xml file:
<launch4jConfig>
  <dontWrapJar>true</dontWrapJar>
  <headerType>gui</headerType>
  <jar>rpgam.jar</jar>
  <outfile>rpgam.exe</outfile>
  <errTitle></errTitle>
  <cmdLine></cmdLine>
  <chdir>.</chdir>
  <priority>normal</priority>
  <downloadUrl>http://www.rpgaudiomixer.com/</downloadUrl>
  <supportUrl></supportUrl>
  <customProcName>false</customProcName>
  <stayAlive>false</stayAlive>
  <manifest></manifest>
  <icon></icon>
  <jre>
    <path></path>
    <minVersion>1.5.0</minVersion>
    <maxVersion></maxVersion>
    <jdkPreference>preferJre</jdkPreference>
  </jre>
  <splash>
    <file>..\images\splash.bmp</file>
    <waitForWindow>true</waitForWindow>
    <timeout>60</timeout>
    <timeoutErr>true</timeoutErr>
  </splash>
</launch4jConfig>

And then there's the NSIS script rpgam-setup.nsis.  It can take a VERSION argument to help name the file.
; The name of the installer
Name ""RPG Audio Mixer""

!ifndef VERSION
    !define VERSION A.B.C
!endif

; The file to write
outfile ""..\dist\installers\windows\rpgam-${VERSION}.exe""

; The default installation directory
InstallDir ""$PROGRAMFILES\RPG Audio Mixer""

; Registry key to check for directory (so if you install again, it will 
; overwrite the old one automatically)
InstallDirRegKey HKLM ""Software\RPG_Audio_Mixer"" ""Install_Dir""

# create a default section.
section ""RPG Audio Mixer""

    SectionIn RO

    ; Set output path to the installation directory.
    SetOutPath $INSTDIR
    File /r ""..\dist\layout\windows\""

    ; Write the installation path into the registry
    WriteRegStr HKLM SOFTWARE\RPG_Audio_Mixer ""Install_Dir"" ""$INSTDIR""

    ; Write the uninstall keys for Windows
    WriteRegStr HKLM ""Software\Microsoft\Windows\CurrentVersion\Uninstall\RPGAudioMixer"" ""DisplayName"" ""RPG Audio Mixer""
    WriteRegStr HKLM ""Software\Microsoft\Windows\CurrentVersion\Uninstall\RPGAudioMixer"" ""UninstallString"" '""$INSTDIR\uninstall.exe""'
    WriteRegDWORD HKLM ""Software\Microsoft\Windows\CurrentVersion\Uninstall\RPGAudioMixer"" ""NoModify"" 1
    WriteRegDWORD HKLM ""Software\Microsoft\Windows\CurrentVersion\Uninstall\RPGAudioMixer"" ""NoRepair"" 1
    WriteUninstaller ""uninstall.exe""

    ; read the value from the registry into the $0 register
    ;readRegStr $0 HKLM ""SOFTWARE\JavaSoft\Java Runtime Environment"" CurrentVersion

    ; print the results in a popup message box
    ;messageBox MB_OK ""version: $0""

sectionEnd

Section ""Start Menu Shortcuts""
  CreateDirectory ""$SMPROGRAMS\RPG Audio Mixer""
  CreateShortCut ""$SMPROGRAMS\RPG Audio Mixer\Uninstall.lnk"" ""$INSTDIR\uninstall.exe"" """" ""$INSTDIR\uninstall.exe"" 0
  CreateShortCut ""$SMPROGRAMS\RPG AUdio Mixer\RPG Audio Mixer.lnk"" ""$INSTDIR\rpgam.exe"" """" ""$INSTDIR\rpgam.exe"" 0
SectionEnd

Section ""Uninstall""

    ; Remove registry keys
    DeleteRegKey HKLM ""Software\Microsoft\Windows\CurrentVersion\Uninstall\RPGAudioMixer""
    DeleteRegKey HKLM SOFTWARE\RPG_Audio_Mixer

    ; Remove files and uninstaller
    Delete $INSTDIR\rpgam.exe
    Delete $INSTDIR\uninstall.exe

    ; Remove shortcuts, if any
    Delete ""$SMPROGRAMS\RPG Audio Mixer\*.*""

    ; Remove directories used
    RMDir ""$SMPROGRAMS\RPG Audio Mixer""
    RMDir ""$INSTDIR""

SectionEnd

Ant Integration
I have some targets in my Ant buildfile (build.xml) to handle the above.  First I tel Ant to import launch4j's Ant tasks:
<property name=""launch4j.dir"" location=""vendor/launch4j"" />
<taskdef name=""launch4j"" 
    classname=""net.sf.launch4j.ant.Launch4jTask""
    classpath=""${launch4j.dir}/launch4j.jar:${launch4j.dir}/lib/xstream.jar"" />

I then have a simple target for creating the wrapper executable:
<target name=""executable-windows"" depends=""jar"" description=""Create Windows executable (EXE)"">
    <launch4j configFile=""scripts/launch4j.xml"" outfile=""${exeFile}"" />
</target>

And another target for making the installer:
<target name=""installer-windows"" depends=""executable-windows"" description=""Create the installer for Windows (EXE)"">
    <!-- Lay out files needed for building the installer -->
    <mkdir dir=""${windowsLayoutDirectory}"" />
    <copy file=""${jarFile}"" todir=""${windowsLayoutDirectory}"" />
    <copy todir=""${windowsLayoutDirectory}/lib"">
        <fileset dir=""${libraryDirectory}"" />
        <fileset dir=""${windowsLibraryDirectory}"" />
    </copy>
    <copy todir=""${windowsLayoutDirectory}/icons"">
         <fileset dir=""${iconsDirectory}"" />
    </copy>
    <copy todir=""${windowsLayoutDirectory}"" file=""${exeFile}"" />

    <mkdir dir=""${windowsInstallerDirectory}"" />

    <!-- Build the installer using NSIS -->
    <exec executable=""vendor/nsis/makensis.exe"">
        <arg value=""/DVERSION=${version}"" />
        <arg value=""scripts/rpgam-setup.nsi"" />
    </exec>
</target>

The top portion of that just copies the necessary files for the installer to a temporary location and the second half executes the script that uses all of it to make the installer.
"
7880,"You need to use an ifstream if you just want to read (use an ofstream to write, or an fstream for both).
To open a file in text mode, do the following:
ifstream in(""filename.ext"", ios_base::in); // the in flag is optional

To open a file in binary mode, you just need to add the ""binary"" flag.
ifstream in2(""filename2.ext"", ios_base::in | ios_base::binary ); 

Use the ifstream.read() function to read a block of characters (in binary or text mode).  Use the getline() function (it's global) to read an entire line.
"
7940,"a) Must look the same
b) As standards-compliant as possible, but not so anal that it blocks finishing work
In a situation where you have perpetual access to the code, I don't think standards-compliance is all that important, since you can always make changes to the code if something breaks. If you don't have perpetual access (ie, you sign off on the code and it becomes someone else's responsibility), it's probably best to be as standards-compliant as possible to minimize maintenance headaches later... even if you never have to deal with the code again, your reputation persists and can be transmitted to other potential clients, and many teams like to blame the previous developer(s) for problems that come up.
"
7990,"Trust me, you will spend more money trying to search/develop a solution for this as compared to buying a third party component. Do not reinvent the wheel and go for the paid solution.
Printing is a complex problem and I would love to see the day when better framework support is added for this.
"
8050,"LINQ stands for Language Integrated Query and is a set of extensions for .NET that allow you to query data the same way from code and isn't tied to a specific data source.  You can use the same LINQ code for SQL Server, XML, objects, DataSets, and Entities.
Here is a good intro from Scott Guthrie
This is a nice set of 101 LINQ Samples
"
8140,"I've used event-based APIs for plugins in the past. You can insert hooks for plugins by dispatching events and providing access to the application state.
For example, if you were writing a blogging application, you might want to raise an event just before a new post is saved to the database, and provide the post HTML to the plugin to alter as needed.
"
8790,"I've got something similar set up: I have a main Ant build.xml which calls a separate build.xml that takes care of building my tests. This is how I do it:
<target name=""build-tests"">
    <subant target=""build"">
      <fileset dir=""${test.home}"" includes=""build.xml""/>
    </subant>
</target>

The trick is to use subant instead of antcall. You don't have to import the other build file.
"
8800,"There is an actual Data Type called KeyValuePair, use like this
KeyValuePair<string, string> myKeyValuePair = new KeyValuePair<string,string>(""defaultkey"", ""defaultvalue"");

"
8830,"Copy any applicable preferences files in ~/Library/Preferences from a machine that you have checked ""Don't show again"" on.
"
8880,"Answered my own question:
Use the NetServerEnum function, passing in the SV_TYPE_DOMAIN_ENUM constant for the ""servertype"" argument.
In Delphi, the code looks like this:
<snip>
type
  NET_API_STATUS = DWORD;
  PSERVER_INFO_100 = ^SERVER_INFO_100;
  SERVER_INFO_100 = packed record
    sv100_platform_id : DWORD;
    sv100_name        : PWideChar;
end;

function NetServerEnum(  //get a list of pcs on the network (same as DOS cmd ""net view"")
  const servername    : PWideChar;
  const level         : DWORD;
  const bufptr        : Pointer;
  const prefmaxlen    : DWORD;
  const entriesread   : PDWORD;
  const totalentries  : PDWORD;
  const servertype    : DWORD;
  const domain        : PWideChar;
  const resume_handle : PDWORD
) : NET_API_STATUS; stdcall; external 'netapi32.dll';

function NetApiBufferFree(  //memory mgmt routine
  const Buffer : Pointer
) : NET_API_STATUS; stdcall; external 'netapi32.dll';

const
  MAX_PREFERRED_LENGTH = DWORD(-1);
  NERR_Success = 0;
  SV_TYPE_ALL  = $FFFFFFFF;
  SV_TYPE_DOMAIN_ENUM = $80000000;


function TNetwork.ComputersInDomain: TStringList;
var
  pBuffer        : PSERVER_INFO_100;
  pWork          : PSERVER_INFO_100;
  dwEntriesRead  : DWORD;
  dwTotalEntries : DWORD;
  i              : integer;
  dwResult       : NET_API_STATUS;
begin
  Result := TStringList.Create;
  Result.Clear;

  dwResult := NetServerEnum(nil,100,@pBuffer,MAX_PREFERRED_LENGTH,
                            @dwEntriesRead,@dwTotalEntries,SV_TYPE_DOMAIN_ENUM,
                            PWideChar(FDomainName),nil);

  if dwResult = NERR_SUCCESS then begin
    try
      pWork := pBuffer;
      for i := 1 to dwEntriesRead do begin
        Result.Add(pWork.sv100_name);
        inc(pWork);
      end;  //for i
    finally
      NetApiBufferFree(pBuffer);
    end;  //try-finally
  end  //if no error
  else begin
    raise Exception.Create('Error while retrieving computer list from domain ' +
                           FDomainName + #13#10 +
                           SysErrorMessage(dwResult));
  end;
end;
<snip>

"
8940,"I believe you can set the desired solution up by rerunning the vmware configuration script.  And doing a custom network setup, so that both NIC's are mapped to your vmware instance.  I would recommend making eth0 the 2nd NIC since it will be easier for Linux to use by default.  Then make eth1 the 1st NIC.
"
8950,"Unfortunately, the ""full"" Sharepoint Experience is limited to running Internet Explorer 6/7 and Office 2007.
On the Mac, I recommend using Firefox (Camino?) which seems to work a bit better than Safari.
Edit: When you say ""Similar experience"", what exactly are you missing? I don't have any Mac here, but I was under the impression that Office 2008 will have a working integration with Sharepoint as well.
"
8970,"You should check out the QTKit Capture documentation.
On Leopard, you can get at all of it over the RubyCocoa bridge:
require 'osx/cocoa'
OSX.require_framework(""/System/Library/Frameworks/QTKit.framework"")

OSX::QTCaptureDevice.inputDevices.each do |device|
    puts device.localizedDisplayName
end

"
9240,"If I understand the question correctly, you've created a domain model and you would like to write an object-relational mapper to map between records in your database and your domain objects. However, you're concerned about polluting your domain model with the 'plumbing' code that would be necessary to read and write to your object's fields.
Taking a step back, you essentially have two choices of where to put your data mapping code - within the domain class itself or in an external mapping class.
The first option is often called the Active Record pattern and has the advantage that each object knows how to persist itself and has sufficient access to its internal structure to allow it to perform the mapping without needing to expose non-business related fields.
E.g
public class User
{
	private string name;
	private AccountStatus status;

	private User()
	{
	}

	public string Name
	{
		get { return name; }
		set { name = value; }
	}

	public AccountStatus Status
	{
		get { return status; }
	}

	public void Activate()
	{
		status = AccountStatus.Active;
	}

	public void Suspend()
	{
		status = AccountStatus.Suspended;
	}

	public static User GetById(int id)
	{
		User fetchedUser = new User();

		// Lots of database and error-checking code
		// omitted for clarity
		// ...

		fetchedUser.name = (string) reader[""Name""];
		fetchedUser.status = (int)reader[""statusCode""] == 0 ? AccountStatus.Suspended : AccountStatus.Active;

		return fetchedUser;
	}

	public static void Save(User user)
	{
		// Code to save User's internal structure to database
		// ...
	}
}

In this example, we have an object that represents a User with a Name and an AccountStatus. We don't want to allow the Status to be set directly, perhaps because we want to check that the change is a valid status transition, so we don't have a setter. Fortunately, the mapping code in the GetById and Save static methods have full access to the object's name and status fields.
The second option is to have a second class that is responsible for the mapping. This has the advantage of seperating out the different concerns of business logic and persistence which can allow your design to be more testable and flexible. The challenge with this method is how to expose the name and status fields to the external class. Some options are:
  1. Use reflection (which has no qualms about digging deep into your object's private parts)
  2. Provide specially-named, public setters (e.g. prefix them with the word 'Private') and hope no one uses them accidentally
  3. If your language suports it, make the setters internal but grant your data mapper module access. E.g. use the InternalsVisibleToAttribute in .NET 2.0 onwards or friend functions in C++
For more information, I'd recommend Martin Fowler's classic book 'Patterns of Enterprise Architecture'
However, as a word of warning, before going down the path of writing your own mappers I'd strongly recommend looking at using a 3rd-party object relational mapper (ORM) tool such as nHibernate or Microsoft's Entity Framework. I've worked on four different projects where, for various reasons, we wrote our own mapper and it is very easy to waste a lot of time maintaining and extending the mapper instead of writing code that provides end user value. I've used nHibernate on one project so far and, although it has quite a steep learning curve initially, the investment you put in early on pays off considerably.
"
9410,"Declaration
A prototype for a function which takes a function parameter looks like the following:
void func ( void (*f)(int) );

This states that the parameter f will be a pointer to a function which has a void return type and which takes a single int parameter. The following function (print) is an example of a function which could be passed to func as a parameter because it is the proper type:
void print ( int x ) {
  printf(""%d\n"", x);
}

Function Call
When calling a function with a function parameter, the value passed must be a pointer to a function. Use the function's name (without parentheses) for this:
func(print);

would call func, passing the print function to it.
Function Body
As with any parameter, func can now use the parameter's name in the function body to access the value of the parameter. Let's say that func will apply the function it is passed to the numbers 0-4. Consider, first, what the loop would look like to call print directly:
for ( int ctr = 0 ; ctr < 5 ; ctr++ ) {
  print(ctr);
}

Since func's parameter declaration says that f is the name for a pointer to the desired function, we recall first that if f is a pointer then *f is the thing that f points to (i.e. the function print in this case). As a result, just replace every occurrence of print in the loop above with *f:
void func ( void (*f)(int) ) {
  for ( int ctr = 0 ; ctr < 5 ; ctr++ ) {
    (*f)(ctr);
  }
}

From http://math.hws.edu/bridgeman/courses/331/f05/handouts/c-c++-notes.html
"
9570,"As a bare minimum:
mscoree.lib
MSVCRT.lib
mfc90.lib (adjust version appropriately)
And iterate from there.
"
9650,"You could also try DrScheme, which whilst not exactly a standalone interpreter, isn't emacs :)
It's basically a simple IDE that has an area to type in code that can be executed as a file, and then another area that is the running interpreter that you can interact with.
(Also, find the UC Berkeley CS61A podcasts and listen to them, as well as reading SICP)
"
9750,"I claim trick question. :) Reversing all bits means a flip-flop, but only the bits that are on clearly means:
return 0;

"
10190,"On MS SQL Server 2005 and above, ROW_NUMBER() seems to work:
T-SQL: Paging with ROW_NUMBER()
DECLARE @PageNum AS INT;
DECLARE @PageSize AS INT;
SET @PageNum = 2;
SET @PageSize = 10;

WITH OrdersRN AS
(
    SELECT ROW_NUMBER() OVER(ORDER BY OrderDate, OrderID) AS RowNum
          ,OrderID
          ,OrderDate
          ,CustomerID
          ,EmployeeID
      FROM dbo.Orders
)

SELECT * 
  FROM OrdersRN
 WHERE RowNum BETWEEN (@PageNum - 1) * @PageSize + 1 
                  AND @PageNum * @PageSize
 ORDER BY OrderDate
         ,OrderID;

"
10230,"Yes, it depends on language, since string storage differs between languages.

Pascal-type strings: Length = 0.
C-style strings: [0] == 0. 
.NET: .IsNullOrEmpty.

Etc. 
"
10260,"For ASP.NET, you have a lot of improvements:

split view (code and design)
faster switching between code and design view
embedded master pages (one master page in another)
javascript debugging

Anyway most of the useful stuff are really in the meat of the language, and for .NET 3.5 the new language features for C# 3.0 will be (and yes, I find ALL of them useful)

anonymous objects
automatic properties
object initializers
collection initializers (inline initialization for collections)
implicit typing (var keyword)
lambda expressions
LINQ
Extension methods

I might have forgotten a few, but I think this is about most of the new cool and useful stuff.
"
10300,"Here's an overview of the flow in MVC:

/new - render your ""New"" view containing a form for the user to fill out
User fills out form and it is posted to /create
The post is routed to the Create action on your controller
In your action method, update the model with the data that was posted.
Your Model should validate itself.
Your Controller should read if the model is valid.
If the Model is valid, save it to your db.  Redirect to /show to render the show View for your object.
If the Model is invalid, save the form values and error messages in the TempData, and redirect to the New action again.  Fill your form fields with the data from TempData and show the error message(s).

The validation frameworks will help you along in this process.  Also, I think the ASP.NET MVC team is planning a validation framework for the next preview.
"
10580,"The short answer is that early (or static) binding refers to compile time binding and late (or dynamic) binding refers to runtime binding (for example when you use reflection).
"
10600,"Although SAS-based DAS is likely to be quickest for a single DB server (ideally with 15krpm 2.5 inch SFF disks in a RAID 10 configuration) for most systems you lose a lot of the advantages that a SAN can bring. For that reason I'd always build databases with dual FC (4 or 8Gbps fibre links) adapters into dual SAN switches, connected to a dual-controller SAN array. Not only will this scenario be very quick indeed but it will open up the options to utilise the various snapshot techniques that these boxes have to offer. These can enable'live-live' DB replication between sites for DR, instant database restoration and excellent capacity expansion/reduction with no impact on the server/s themselves. Hope this helps, let me know if I can add any more.
"
10610,"Boost, for c++
"
10680,"You should use atexit() if possible.  on_exit() is nonstandard and less common.  For example, it's not available on OS X.
Kernel.org - on_exit():

This function comes from SunOS 4, but is also present in libc4, libc5 and
  glibc.  It no longer occurs in Solaris (SunOS 5).  Avoid this function, and
  use the standard atexit(3) instead.

"
10810,"For AzMan with ASP.NET, turn on impersonation in web.config (<identity impersonate=""true"" username=""xx"" pasword=""xx"" />), and make sure with an AD administrator that the impersonation account has ""reader"" permissions on the AzMan store; plus, give write permissions to this account on the Temporary ASP.NET Files folder (under C:\Windows\Microsoft.NET\<framework>).
"
10860,"It really depends on your view of the world - I used to be in the uncoupled camp. The DAL was only there to supply data to the BAL - end of story.
With emerging technologies such as Linq to SQL and Entity Framework becoming a bit more popular, then the line between DAL and BAL have been blurred a bit. In L2S especially your DAL is quite tightly coupled to the Business objects as the object model has a 1-1 mapping to your database field.
Like anything in software development there is no right or wrong answer. You need to understand your requirements and future requirments and work from there. I would no more use a Ferrari on the Dakhar rally as I would a Range Rover on a track day.
"
10870,"Are you using only the dragEnter method? If you are trying to reject the drag while still dragging over the same component you need to use both the dragEnter and dragOver methods.
Check out this example:
<?xml version=""1.0"" encoding=""utf-8""?>
<mx:Application xmlns:mx=""http://www.adobe.com/2006/mxml"" layout=""absolute"">
    <mx:Script>
    	<![CDATA[
    		import mx.core.DragSource;
    		import mx.managers.DragManager;
    		import mx.events.DragEvent;

    		private function onDragEnter(e:DragEvent):void {
    			if ( e.target == lbl ) {

    				if ( e.localX < lbl.width/2 ) {
    					trace(""accept"");
    					DragManager.acceptDragDrop(this);
    				}
    				else {
    					DragManager.acceptDragDrop(null);
    				}
    			}
    		}

    		private function doStartDrag(e:MouseEvent):void {
    			if ( e.buttonDown ) {
    				var ds:DragSource = new DragSource();
    				ds.addData(""test"", ""text"");

    				DragManager.doDrag(btn, ds, e);
    			}
    		}
    	]]>
    </mx:Script>
    <mx:Label id=""lbl"" text=""hello world!"" left=""10"" top=""10"" dragEnter=""onDragEnter(event)"" dragOver=""onDragEnter(event)"" />
    <mx:Button id=""btn"" x=""47"" y=""255"" label=""Button"" mouseMove=""doStartDrag(event)""/>
</mx:Application>

"
10880,"No specific article, really, but I've found EmacsWiki to be full of useful information. Consider checking out these entries:

CPlusPlus as a starting point for many C++-related articles, and
CppTemplate to define a template that can give you a good skeleton when you start new files

"
10980,"There are multiple issues here as ikvm is currently being transitioned away from the GNU classpath system to Sun's OpenJDK.  Both are licensed as GPL+Exceptions to state explicitly that applications which merely use the OpenJDK libraries will not be considered derived works.
Generally speaking, applications which rely upon components with defined specs such as this do not fall under the GPL anyway.  For example, linking against public POSIX APIs does not trigger GPL reliance in a Linux application, despite the kernel being GPL.  A similar principal will usually (the details can be tricky) apply to replacing Sun's Java with a FOSS/GPL implementation.
"
10990,"You can create a new group with both the apache user and FTP user as members and then make the permission on the upload folder 775.  This should give both the apache and FTP users the ability to write to the files in the folder but keep everyone else from modifying them.
"
11060,"I started writing up a summary of my experience with my own code generator, then went back and re-read your question and found you had already touched upon the same issues yourself, focus on the execution results instead of the code layout/look.
Problem is, this is hard to test, the generated code might not be suited to actually run in the environment of the unit test system, and how do you encode the expected results?
I've found that you need to break down the code generator into smaller pieces and unit test those. Unit testing a full code generator is more like integration testing than unit testing if you ask me.
"
11200,"Last epoch is when 1970 GMT?
SELECT DATEDIFF(s,'19700101 05:00:00:000',lastModified)

See also Epoch Date
"
11330,"Ah, if only C supported closures...
Antonio is right; if you need to pass extra parameters, you'll need to redefine your function pointer to accept the additional arguments. If you don't know exactly what parameters you'll need, then you have at least three choices:

Have the last argument in your prototype be a void*. This gives you flexibility of passing in anything else that you need, but it definitely isn't type-safe.
Use variadic parameters (...). Given my lack of experience with variadic parameters in C, I'm not sure if you can use this with a function pointer, but this gives even more flexibility than the first solution, albeit still with the lack of type safety.
Upgrade to C++ and use function objects.

"
11430,"Actually it ships with .NET 3.5 SP1.  So yes, the stored procs can use 3.5 features and libraries.
"
11460,"Why won't any old proxy software work for this?  Why does it need to be an ASP.NET application?  There are TONS of tools out there (both Windows and *nix) that will get the job done quite easily.  Check Squid or NetProxy for starters.
If you need to integrate with IIS, IISProxy looks like it would do the trick too.
"
11500,"
Script Combining in .net 3.5 SP1
Best Practices for fast websites
HTTP Compression (gzip)
Compress JS / CSS (different than http compression, minify javascript)

YUI Compressor
.NET YUI Compressor


My best advice is to check out the YUI content. They have some great articles that talk about things like CSS sprites and have some nice javascript libraries to help reduce the number of requests the browser is making.
"
11520,"Aside from trying out Visual AssistX, the only other one I've tried is ReSharper (which I highly recommend). If you do decide to go for ReSharper, you'll likely notice that it's missing a spell checker for code though - however the Agent Smith plugin fixes that.
"
11620,"See Kill All Active Connections To A Database.
The reason that the approach that Adam suggested won't work is that during the time that you are looping over the active connections new one can be established, and you'll miss those. The article I linked to uses the following approach which does not have this drawback:
-- set your current connection to use master otherwise you might get an error

use master
ALTER DATABASE YourDatabase SET SINGLE_USER WITH ROLLBACK IMMEDIATE 

--do you stuff here 

ALTER DATABASE YourDatabase SET MULTI_USER

"
11680,"
Just write your file parser, using whatever techniques come to mind
Write lots of unit tests for it to make sure all your edge cases are covered

Once you've done this, you will actually have a reasonable idea of the problem/solution.
Right now you just have theories floating around in your head, most of which will turn out to be misguided.
Step 3: Refactor mercilessly. Your aim should be to delete about half of your code
You'll find that your code at the end will either resemble an existing design pattern, or you'll have created a new one. You'll then be qualified to answer this question :-)
"
11690,"This is because the font used in the tooltip doesn't include the characters you are trying to display. Try installing a font pack that includes those characters. I'm affraid you can't do much for your site's visitors other than implementating a tooltip yourself using javascript.
"
11720,"You can actually script a fair number of tasks in MS Virtual Server:
http://www.microsoft.com/technet/scriptcenter/scripts/vs/default.mspx?mfr=true
http://msdn.microsoft.com/en-us/library/aa368876(VS.85).aspx
Also Virtual PC guy has got a ton of stuff on his blog about scripting Virtual Server/PC and now Hyper-V here:
http://blogs.msdn.com/virtual_pc_guy/default.aspx
VMware has similar capabilities:
http://www.vmware.com/support/developer/scripting-API/
"
11740,"I've now researched what it takes to do this in both Entity Framework and LINQ to SQL and documented the steps required in each. It's much longer than answers here tend to be so I'll be content with a link to the answer rather than duplicate it here. It's relatively involved for each, but the LINQ to SQL is the more flexible solution and also the easiest to implment.
"
11820,"Typically a byte array is sent as a base64 encoded string, not as individual bytes in tags. 
http://en.wikipedia.org/wiki/Base64
The base64 encoded version is about 137% of the size of the original content.
"
11930,"On Windows, OSX, Linux, etc then Chris Bunch's answer can be much improved by using 
netstat -rn

in place of a traceroute command.
Your gateway's IP address will appear in the second field of the line that starts either default or 0.0.0.0.
This gets around a number of problems with trying to use traceroute:

on Windows traceroute is actually tracert.exe, so there's no need for O/S dependencies in the code
it's a quick command to run - it gets information from the O/S, not from the network
traceroute is sometimes blocked by the network

The only downside is that it will be necessary to keep reading lines from the netstat output until the right line is found, since there'll be more than one line of output.
EDIT: The Default Gateway's IP Address is in the second field of the line that starts with 'default' if you are on a MAC (tested on Lion), or in the third field of the line that starts with '0.0.0.0' (tested on Windows 7)
Windows:


Network Destination        Netmask          Gateway       Interface  Metric
0.0.0.0              0.0.0.0    192.168.2.254     192.168.2.46     10


Mac:


Destination        Gateway            Flags        Refs      Use   Netif Expire
default            192.168.2.254      UGSc          104        4     en1


"
11950,"I use elmah.  It has some really nice features and here is a CodeProject article on it.  I think the StackOverflow team uses elmah also!
"
12140,"You could use Martin Fowlers ServiceLocator pattern. In php it could look like this:
class ServiceLocator {
  private static $soleInstance;
  private $globalSettings;

  public static function load($locator) {
    self::$soleInstance = $locator;
  }

  public static function globalSettings() {
    if (!isset(self::$soleInstance->globalSettings)) {
      self::$soleInstance->setGlobalSettings(new GlobalSettings());
    }
    return self::$soleInstance->globalSettings;
  }
}

Your production code then initializes the service locator like this:
ServiceLocator::load(new ServiceLocator());

In your test-code, you insert your mock-settings like this:
ServiceLocator s = new ServiceLocator();
s->setGlobalSettings(new MockGlobalSettings());
ServiceLocator::load(s);

It's a repository for singletons that can be exchanged for testing purposes.
"
12290,"Maybe try this question at http://www.codeplex.com/n2/Thread/List.aspx
They might be able to tell you about performance limitations or bottlenecks.
"
12330,"I believe this is what you want.
WMI Code Creator
A part of this nifty utility allows you to browse namespaces/classes/properties on the local and remote PCs, not to mention generating WMI code in VBScript/C#/VB on the fly.  Very useful.
Also, the source code used to create the utility is included in the download, which could provide a reference if you wanted to create your own browser like interface.
"
12720,"You'll want to setup launch condition in your deployment project to make sure version 2.0 SP1 is installed. You'll want to set a requirement based off the MsiNetAssemblySupport variable, tied to the version number of .NET 2.0 SP1 (2.0.50727.1433 and above according to this page.)
Bootstrapping the project to actually download the framework if it isn't installed is a different matter, and there are plenty of articles out there on how to do that.
"
12870,"Don't try to be as dynamic as PHP is. You could try to first define what you need.
interface Season
{
    public string getDays();
}

interface User
{
    public Season getWinter();
    public Season getSpring();
    public Season getSummer();
    public Season getFall();
}

interface UserMap
{
    public User getUser(string name);
}

And please, read the documentation of Hashtable before using it. This class is synchronized which means that each call is protected against multithreading which really slows the access when you don't need the extra protection. Please use any Map implementation instead like HashMap or TreeMap.
"
12880,"Check out the netflix contest.  I believe they exposed their database, or a large subset, to facilitate the contest.
UPDATE: Their faq says they have 100 million entries in the subset you can download.
"
12890,"I know more about mssql that mysql, but I don't think the number of joins or number of rows you are talking about should cause you too many problems with the correct indexes in place.  Have you analyzed the query plan to see if you are missing any?
http://dev.mysql.com/doc/refman/5.0/en/explain.html
That being said, once you are satisifed with your indexes and have exhausted all other avenues, de-normalization might be the right answer.  If you just have one or two queries that are problems, a manual approach is probably appropriate, whereas some sort of data warehousing tool might be better for creating a platform to develop data cubes.
Here's a site I found that touches on the subject:
http://www.meansandends.com/mysql-data-warehouse/?link_body%2Fbody=%7Bincl%3AAggregation%7D
Here's a simple technique that you can use to keep denormalizing queries simple, if you're just doing a few at a time (and I'm not replacing your OLTP tables, just creating a new one for reporting purposes).  Let's say you have this query in your application:
select a.name, b.address from tbla a 
join tblb b on b.fk_a_id = a.id where a.id=1

You could create a denormalized table and populate with almost the same query:
create table tbl_ab (a_id, a_name, b_address); 
-- (types elided)

Notice the underscores match the table aliases you use
insert tbl_ab select a.id, a.name, b.address from tbla a
join tblb b on b.fk_a_id = a.id 
-- no where clause because you want everything

Then to fix your app to use the new denormalized table, switch the dots for underscores.  
select a_name as name, b_address as address 
from tbl_ab where a_id = 1;

For huge queries this can save a lot of time and makes it clear where the data came from, and you can re-use the queries you already have.
Remember, I'm only advocating this as the last resort.  I bet there's a few indexes that would help you.  And when you de-normalize, don't forget to account for the extra space on your disks, and figure out when you will run the query to populate the new tables.  This should probably be at night, or whenever activity is low.  And the data in that table, of course, will never exactly be up to date.
[Yet another edit]  Don't forget that the new tables you create need to be indexed too!  The good part is that you can index to your heart's content and not worry about update lock contention, since aside from your bulk insert the table will only see selects.
"
13000,"Most PHP sites should have a file (I call it a header) that you include on every single page of the site. If you put that first line of code in the header file, then include it like this on every page:
 include 'header.php';

you won't have to use the global keyword or anything, the second line of code you wrote should work.
Edit: Oh sorry, that won't work inside functions... now I see your problem.
Edit #2: Ok, take my original advice with the header, but use a define() rather than a variable. Those work inside functions after being included.
"
13060,"By default (in C#), passing an object to a function actually passes a copy of the reference to that object. Changing the parameter itself only changes the value in the parameter, and not the variable that was specified.
void Test1(string param)
{
    param = ""new value"";
}

string s1 = ""initial value"";
Test1(s1);
// s1 == ""initial value""

Using out or ref passes a reference to the variable specified in the call to the function. Any changes to the value of an out or ref parameter will be passed back to the caller.
Both out and ref behave identically except for one slight difference: ref parameters are required to be initialised before calling, while out parameters can be uninitialised. By extension, ref parameters are guaranteed to be initialised at the start of the method, while out parameters are treated as uninitialised.
void Test2(ref string param)
{
    param = ""new value"";
}

void Test3(out string param)
{
    // Use of param here will not compile
    param = ""another value"";
}

string s2 = ""initial value"";
string s3;
Test2(ref s2);
// s2 == ""new value""
// Test2(ref s3); // Passing ref s3 will not compile
Test3(out s2);
// s2 == ""another value""
Test3(out s3);
// s3 == ""another value""

Edit: As dp points out, the difference between out and ref is only enforced by the C# compiler, not by the CLR. As far as I know, VB has no equivalent for out and implements ref (as ByRef) only, matching the support of the CLR.
"
13160,"It depends on how often you are going to be calling the web service.  If you're going to be calling it almost constantly, it would probably be better to use method #2.  However, if it's not going to be getting called quite so often, you are better off using method #1, and only instantiating it when you need it.
"
13170,"It's possible for a thread to be in more than one state at once therefore the ThreadState property is actually a bitmap of possible states. So testing for equality with just one state will not give you the right result. You would need to do something like:
if((mThread.ThreadState & ThreadState.Running) != 0)

However, checking thread state is the wrong to do anything. I'm not entirely clear what you're trying to achieve but I will guess that you're waiting for a thread to terminate before restarting it. In that case you should do:
mThread.Join();
mThread = new Thread(new ParameterizedThreadStart(Monitor));
if(check)
    mThread.Start(60000);
else
    mThread.Start(0);

Although if you describe the problem you're trying to solve in more detail I'm almost certain there will be a better solution. Waiting around for a thread to end just to restart it again doesn't seem that efficient to me. Perhaps you just need some kind of inter-thread communication?
John.
"
13200,"At my company we've recently adopted the (commercial) Atlassian stack - including JIRA for issue tracking and Bamboo for builds. Much like the Microsoft world (I'm guessing - we're a Java shop), if you get all your products from a single vendor you get the bonus of tight integration.
For an example of how they've done interoperability, view their interoperability page.
Enough shilling. Generally speaking, I can summarize their general approach as:

Create issues in your bug tracker (ex: issue key of PROJ-123).
When you commit code, add ""PROJ-123"" to your commit comment to indicate what bug this code change fixes.
When your CI server checks out the code, scan the commit comments of the diffs. Record any strings matching the regex of your issue keys.
When the build completes, generate a report of what issue keys were found.

Specifically to your second problem:
Your CI doesn't doesn't have to put anything into your bug tracker. Bamboo doesn't put anything into JIRA. Instead, the Atlassian folks have provided a plugin to JIRA that will make a remote api call into Bamboo, asking the question ""Bamboo, to what builds am I (a JIRA issue) related?"". This is probably best explained with a screenshot.
"
13430,"Here is a helpful article that worked for me:
Getting CruiseControl.NET working under IIS7
"
13460,"Think of source control as a giant ""Undo"" button for your source code. Every time you check in, you're adding a point to which you can roll back. Even if you don't use branching/merging, this feature alone can be very valuable.
Additionally, by having one 'authoritative' version of the source control, it becomes much easier to back up.
Centralized vs. distributed... the difference is really that in distributed, there isn't necessarily one 'authoritative' version of the source control, although in practice people usually still do have the master tree.
The big advantage to distributed source control is two-fold:

When you use distributed source control, you have the whole source tree on your local machine. You can commit, create branches, and work pretty much as though you were all alone, and then when you're ready to push up your changes, you can promote them from your machine to the master copy. If you're working ""offline"" a lot, this can be a huge benefit.
You don't have to ask anybody's permission to become a distributor of the source control. If person A is running the project, but person B and C want to make changes, and share those changes with each other, it becomes much easier with distributed source control.

"
13470,"@Rob: I disagree.  To enforce what you are asking for I think you would need to use negative-look-behind, which is possible but is certainly not related to use {1}.  Neither version of the regexp address that particular issue.
To let the code speak:
tibook 0 /home/jj33/swap > cat text
Text this is <http://example.com> text this is
Text this is <http://http://example.com> text this is
tibook 0 /home/jj33/swap > cat p
#!/usr/bin/perl

my $re1 = '((mailto\:|(news|(ht|f)tp(s?))\://){1}\S+)';
my $re2 = '((mailto\:|(news|(ht|f)tp(s?))\://)\S+)';

while (<>) {
  print ""Evaluating: $_"";
  print ""re1 saw \$1 = $1\n"" if (/$re1/);
  print ""re2 saw \$1 = $1\n"" if (/$re2/);
}
tibook 0 /home/jj33/swap > cat text | perl p
Evaluating: Text this is <http://example.com> text this is
re1 saw $1 = <http://example.com>
re2 saw $1 = <http://example.com>
Evaluating: Text this is <http://http://example.com> text this is
re1 saw $1 = <http://http://example.com>
re2 saw $1 = <http://http://example.com>
tibook 0 /home/jj33/swap >

So, if there is a difference between the two versions, it's doesn't seem to be the one you suggest.
"
13540,"Your assumption is right, this is the optimal way to do it and it's called upsert/merge.
Importance of UPSERT - from sqlservercentral.com: 

For every update in the case mentioned above we are removing one
  additional read from the table if we
  use the UPSERT instead of EXISTS.
  Unfortunately for an Insert, both the
  UPSERT and IF EXISTS methods use the
  same number of reads on the table.
  Therefore the check for existence
  should only be done when there is a
  very valid reason to justify the
  additional I/O. The optimized way to
  do things is to make sure that you
  have little reads as possible on the
  DB.
The best strategy is to attempt the
  update. If no rows are affected by the
  update then insert. In most
  circumstances, the row will already
  exist and only one I/O will be
  required.

Edit: 
Please check out this answer and the linked blog post to learn about the problems with this pattern and how to make it work safe.
"
13550,"We use a CASE tool at my current company for code generation and we are trying to move away from it.
The benefits that it brings - a graphical representation of the code making components 'easier' to pick up for new developers - are outweighed by the disadvantges in my opinion.
Those main disadvantages are:

We cannot do automatic merges, making it close to impossible for parallel development on one component.
Developers get dependant on the tool and 'forget' how to handcode.

"
13620,"The performance difference has been irrelevant since at least January 2012, and likely earlier:
Single quotes: 0.061846971511841 seconds
Double quotes: 0.061599016189575 seconds

Earlier versions of PHP may have had a difference - I personally prefer single quotes to double quotes, so it was a convenient difference. The conclusion of the article makes an excellent point:

Never trust a statistic you didnât forge yourself.

(Although the article quotes the phrase, the original quip was likely falsely attributed to Winston Churchill, invented by Joseph Goebbels' propaganda ministry to portray Churchill as a liar:

Ich traue keiner Statistik, die ich nicht selbst gefÃ¤lscht habe.

This loosely translates to, ""I do not trust a statistic that I did not fake myself."")
"
14040,"It's the difference between ""black box"" testing (where you know what the code is supposed to do, but not how it works), and ""white box"" testing (where knowing how it works drives how you test it). ""Black box"" testing is what most people think of when you mention Quality Assurance.
I work for a company where the QA team are also software developers.  (That narrows the field a lot if you care to guess the company.)  I know Joel's opinion, and my experience leads me to partially disagree: for the same reason that a ""white hat"" hacker is more effective finding security holes, certain kinds of errors are more effectively found by white box testers who know how to write code (and therefore what the common mistakes are - for example, resource management issues like memory leaks).  
Also, since QA-oriented developers are part of the process from the initial design phase, they can theoretically help to drive higher-quality code throughout the process.  Ideally, for each developer working on the project with a mental focus on functionality, you have an opposing developer with a mental focus on breaking the code (and thus making it better).  
Seen in that light, it's less a matter of using developers for testers than it is kind of disconnected pair-programming where one developer has an emphasis on controlling quality.  
On the other hand, a lot of testing (such as basic UI functionality) frankly doesn't need that kind of skill.  That's where Joel has a point. 
For many businesses, I could see a system where programming teams trade off code review and testing duties for each others' code.  Members of the Business Logic team, for example, could spend an occasional tour testing and reviewing code for the UI team, and vice-versa.  That way you're not ""wasting"" developer talent on full-time testing, but you are gaining the advantages of exposing the code to (hopefully) expert scrutiny and punishment.  Then, a more traditional QA team can take up the ""black box"" testing.
"
14300,"Drop into a cmd instance (or indeed PowerShell itself) and type this:
powershell -?

You'll see that powershell.exe has a ""-noexit"" parameter which tells it not to exit after executing a ""startup command"".
"
14310,"There's a simple solution.
Assuming your (non-display) textures are 1024x1024 and you are restricted to a 256x256 window/display.
unsigned int WIN_WIDTH = 256;
unsigned int WIN_HEIGHT = WIN_WIDTH;
unsigned int TEX_WIDTH = 1024;
unsigned int TEX_HEIGHT = TEX_WIDTH;

Use the window size to create your OpenGL window:
glutInitWindowSize(WIN_WIDTH, WIN_HEIGHT);

But, use the texture size for everything else:
glViewport(0, 0, TEX_WIDTH, TEX_HEIGHT);
gluOrtho2D(0.0, TEX_WIDTH, 0.0, TEX_HEIGHT);
glTexCoord2i(TEX_WIDTH, TEX_HEIGHT);

"
14330,"I found one possible solution in the Color FAQ. The luminance component Y (from the CIE XYZ system) captures what is most perceived by humans as color in one channel. So, use those coefficients:
mono = (0.2125 * color.r) + (0.7154 * color.g) + (0.0721 * color.b);

"
14350,"This is all described in The Adobe Flex 3 Programming ActionScript 3 PDF on page 550 (Chapter 27: Flash Player Security / Cross-scripting):

If two SWF files written with ActionScript 3.0 are served from different domainsâfor example, http://siteA.com/swfA.swf and http://siteB.com/swfB.swfâthen, by default, Flash Player does not allow swfA.swf to script swfB.swf, nor swfB.swf to script swfA.swf. A SWF file gives permission to SWF files from other domains by calling Security.allowDomain(). By calling Security.allowDomain(""siteA.com""), swfB.swf gives SWF files from siteA.com permission to script it.

It goes on in some more detail, with diagrams and all.
"
14370,"Creating and using pop-up menus with GLUT is very simple. Here is a code sample that creates a pop-up menu with 4 options:
// Menu items
enum MENU_TYPE
{
        MENU_FRONT,
        MENU_SPOT,
        MENU_BACK,
        MENU_BACK_FRONT,
};

// Assign a default value
MENU_TYPE show = MENU_BACK_FRONT;

// Menu handling function declaration
void menu(int);

int main()
{
        // ...

        // Create a menu
        glutCreateMenu(menu);

        // Add menu items
        glutAddMenuEntry(""Show Front"", MENU_FRONT);
        glutAddMenuEntry(""Show Back"", MENU_BACK);
        glutAddMenuEntry(""Spotlight"", MENU_SPOT);
        glutAddMenuEntry(""Blend 'em all"", MENU_BACK_FRONT);

        // Associate a mouse button with menu
        glutAttachMenu(GLUT_RIGHT_BUTTON);

        // ...

        return;
}

// Menu handling function definition
void menu(int item)
{
        switch (item)
        {
        case MENU_FRONT:
        case MENU_SPOT:
        case MENU_DEPTH:
        case MENU_BACK:
        case MENU_BACK_FRONT:
                {
                        show = (MENU_TYPE) item;
                }
                break;
        default:
                {       /* Nothing */       }
                break;
        }

        glutPostRedisplay();

        return;
}

"
14410,"Early software was often modal, but usability took a turn at some point, away from this style. 
VI-based editors are total enigmas -- they're the only real surviving members of that order of software. 
Modes are a no-no in usability and interaction design because we humans are fickle mammals who cannot be trusted to remember what mode the application is in. 
If you think you are in one ""mode"" when you are actually in another, then all sorts of badness can ensue. What you believe to be a series of harmless keystrokes can (in the wrong mode) cause unlimited catastrophe. This is known as a ""mode error"".
To learn more, search for the term ""modeless"" (and ""usability"")
As mentioned in the comments below, a Modal interface in the hands of an experienced and non-fickle person can be extremely efficient.
"
14530,"Some advantages of LINQ over sprocs:

Type safety: I think we all understand this.
Abstraction: This is especially true with LINQ-to-Entities.  This abstraction also allows the framework to add additional improvements that you can easily take advantage of.  PLINQ is an example of adding multi-threading support to LINQ.  Code changes are minimal to add this support.  It would be MUCH harder to do this data access code that simply calls sprocs.
Debugging support: I can use any .NET debugger to debug the queries.  With sprocs, you cannot easily debug the SQL and that experience is largely tied to your database vendor (MS SQL Server provides a query analyzer, but often that isn't enough).
Vendor agnostic: LINQ works with lots of databases and the number of supported databases will only increase.  Sprocs are not always portable between databases, either because of varying syntax or feature support (if the database supports sprocs at all).
Deployment: Others have mentioned this already, but it's easier to deploy a single assembly than to deploy a set of sprocs.  This also ties in with #4.
Easier: You don't have to learn T-SQL to do data access, nor do you have to learn the data access API (e.g. ADO.NET) necessary for calling the sprocs.  This is related to #3 and #4.

Some disadvantages of LINQ vs sprocs:

Network traffic: sprocs need only serialize sproc-name and argument data over the wire while LINQ sends the entire query.  This can get really bad if the queries are very complex.  However, LINQ's abstraction allows Microsoft to improve this over time.
Less flexible: Sprocs can take full advantage of a database's featureset.  LINQ tends to be more generic in it's support.  This is common in any kind of language abstraction (e.g. C# vs assembler).
Recompiling: If you need to make changes to the way you do data access, you need to recompile, version, and redeploy your assembly.  Sprocs can sometimes allow a DBA to tune the data access routine without a need to redeploy anything.

Security and manageability are something that people argue about too.

Security: For example, you can protect your sensitive data by restricting access to the tables directly, and put ACLs on the sprocs.  With LINQ, however, you can still restrict direct access  to tables and instead put ACLs on updatable table views to achieve a similar end (assuming your database supports updatable views).  
Manageability: Using views also gives you the advantage of shielding your application non-breaking from schema changes (like table normalization).  You can update the view without requiring your data access code to change.

I used to be a big sproc guy, but I'm starting to lean towards LINQ as a better alternative in general.  If there are some areas where sprocs are clearly better, then I'll probably still write a sproc but access it using LINQ. :)
"
14570,"
Should I just do it when I'm going to use it?

I would recommend that you only retrieve the data when you are going to use it. If you are not going to need it, there is no reason to waste resources by retrieving it in Page_Load. If you are going to need it multiple times throughout the page load, consider saving the query results to a private variable or collection so that the same data can be reused multiple times throughout the page load.

Am I opening a new connection when I create a new instance?

Asp.net handles connection pooling, and opens and closes connections in an efficient way. You shouldn't have to worry about this.
One other thing to consider from a performance perspective is to avoid using Datasets and TableAdapters. In many cases, they add extra overhead into data retrieval that does not exist when using Linq to Sql, Stored Procedures or DataReaders.
"
14760,"This is a really cool feature. I've poked through the feature documentation, and the accompanying command list, and not a heck of a lot is showing up in terms of turning it off.
If you want to search for >exit, you could always type >Edit.Find >exit in the search box; that seems to do the trick. A bit verbose, though, but it really is an edge case.
"
14770,"In solutions with multiple projects, one thing I've found very helpful is to have all the AssemblyInfo files point to a single project that governs the versioning. So my AssemblyInfos have a line:
[assembly: AssemblyVersion(Foo.StaticVersion.Bar)]

I have a project with a single file that declares the string:
namespace Foo
{
    public static class StaticVersion
    {
         public const string Bar= ""3.0.216.0""; // 08/01/2008 17:28:35
    }
}

My automated build process then just changes that string by pulling the most recent version from the database and incrementing the second last number.
I only change the Major build number when the featureset changes dramatically.
I don't change the file version at all.
"
15040,"Assuming you have VMware workstation, VMware player or anything that can run vmware appliance, you just need to:

Download, unzip Ubuntu 8.04 Server and start the virtual machine.
Update ubuntu and set the layout and the timezone:

sudo apt-get update
sudo apt-get upgrade
sudo dpkg-reconfigure console-setup
sudo dpkg-reconfigure tzdata
sudo vim /etc/network/interfaces

set a fixed IP (Optional). 
install apache+mysql+php:
sudo tasksel install lamp-server


"
15190,"I am not sure I completely understand your question.

If you are referring to the folder the IDE has as the current folder, then you can just change the shortcut that launches Delphi to set the current directory where ever you want it to be.

"
15240,"I still do it the old way, by defining a macro (XTRACE, below) which correlates to either a no-op or a function call with a variable argument list. Internally, call vsnprintf so you can keep the printf syntax:
#include <stdio.h>

void XTrace0(LPCTSTR lpszText)
{
   ::OutputDebugString(lpszText);
}

void XTrace(LPCTSTR lpszFormat, ...)
{
    va_list args;
    va_start(args, lpszFormat);
    int nBuf;
    TCHAR szBuffer[512]; // get rid of this hard-coded buffer
    nBuf = _vsnprintf(szBuffer, 511, lpszFormat, args);
    ::OutputDebugString(szBuffer);
    va_end(args);
}

Then a typical #ifdef switch:
#ifdef _DEBUG
#define XTRACE XTrace
#else
#define XTRACE
#endif

Well that can be cleaned up quite a bit but it's the basic idea.
"
15310,"

Does anyone know of anyway to
  reduce/optimize the PDF export phase
  and or the size of the PDF without
  lowering the total page count?


I have a few ideas and questions:
1. Is this a graphics-heavy report?  If not, do you have tables that start out as text but are converted into a graphic by the SSRS PDF renderer (check if you can select the text in the PDF)?  41K per page might be more than it should be, or it might not, depending on how information-dense your report is.  But we've had cases where we had minor issues with a report's layout, like having a table bleed into the page's margins, that resulted in the SSRS PDF renderer ""throwing up its hands"" and rendering the table as an image instead of as text.  Obviously, the fewer graphics in your report, the smaller your file size will be.
2. Is there a way that you could easily break the report into pieces?  E.g., if it's a 10-location report, where Location 1 is followed by Location 2, etc., on your final report, could you run the Location 1 portion independent of the Location 2 portion, etc.?  If so, you could join the 10 sub-reports into one final PDF using PDFSharp after you've received them all.  This leads to some difficulties with page numbering, but nothing insurmountable.

3. Does anyone else have any other
  theories as to why this runs on the
  server but not through the API?

My guess would be the sheer size of the report.  I don't remember everything about what's an IIS setting and what's SSRS-specific, but there might be some overall IIS settings (maybe in Metabase.xml) that you would have to be updated to even allow that much data to pass through. 
You could isolate the question of whether the time is the problem by taking one of your working reports and building in a long wait time in your stored procedures with WAITFOR (assuming SQL Server for your DBMS).
Not solutions, per se, but ideas.  Hope it helps.
"
15390,"The approach that I've found works for me is having seperate JS files for each class (just as you would in Java, C# and others). Alternatively you can group your JS into application functional areas if that's easier for you to navigate.
If you put all your JS files into one directory, you can have your server-side environment (PHP for instance) loop through each file in that directory and output a <script src='/path/to/js/$file.js' type='text/javascript'> in some header file that is included by all your UI pages. You'll find this auto-loading especially handy if you're regularly creating and removing JS files.
When deploying to production, you should have a script that combines them all into one JS file and ""minifies"" it to keep the size down.
"
15470,"Just change ""Home"" to an empty string.
routes.MapRoute(
    ""Home"",
    """",
    new { action = Index, controller = Home }
);

"
15690,"Do you know much about OOP?  If so, look into Spring and Hibernate to keep your implementation clean and orthogonal.  If you get that, you should find TDD a good way to keep your design compact and lean, especially since you have ""automated testing"" up and running.
UPDATE:
Looking at the first slew of answers, I couldn't disagree more.  Particularly in the Java space, you should find plenty of mentors/resources on working out your application with Objects, not a database-centric approach.  Database design is typically the first step for Microsoft folks (which I do daily, but am in a recovery program, er, Alt.Net).  If you keep the focus on what you need to deliver to a customer and let your ORM figure out how to persist your objects, your design should be better.
"
15700,"If you're using a winforms app you could try using UserProperties to store this info. Another possible solution could be custom configuration sections.
"
15880,"Update: I have found a 3rd party COM library called Outlook Redemption which is working fine for me at the moment. If you use it via COM-Interop in .NET, don't forget to release every COM object after you are done with it, otherwise your application crashes randomly.
"
15900,"Here are some 3rd-party diagramming tools:

http://www.nevron.com/Products.DiagramFor.NET.Overview.aspx
http://www.nwoods.com/GO/dotnet.htm
http://www.syncfusion.com/products/diagram/web/default.aspx

"
16100,"It's rather ugly:
StatusEnum MyStatus = (StatusEnum) Enum.Parse(typeof(StatusEnum), ""Active"", true);

I tend to simplify this with:
public static T ParseEnum<T>(string value)
{
    return (T) Enum.Parse(typeof(T), value, true);
}

Then I can do:
StatusEnum MyStatus = EnumUtil.ParseEnum<StatusEnum>(""Active"");

One option suggested in the comments is to add an extension, which is simple enough:
public static T ToEnum<T>(this string value)
{
    return (T) Enum.Parse(typeof(T), value, true);
}

StatusEnum MyStatus = ""Active"".ToEnum<StatusEnum>();

Finally, you may want to have a default enum to use if the string cannot be parsed:
public static T ToEnum<T>(this string value, T defaultValue) 
{
    if (string.IsNullOrEmpty(value))
    {
        return defaultValue;
    }

    T result;
    return Enum.TryParse<T>(value, true, out result) ? result : defaultValue;
}

Which makes this the call:
StatusEnum MyStatus = ""Active"".ToEnum(StatusEnum.None);

However, I would be careful adding an extension method like this to string as (without namespace control) it will appear on all instances of string whether they hold an enum or not (so 1234.ToString().ToEnum(StatusEnum.None) would be valid but nonsensical) . It's often be best to avoid cluttering Microsoft's core classes with extra methods that only apply in very specific contexts unless your entire development team has a very good understanding of what those extensions do. 
"
16110,"Hook into the KeyPress event on the TextBox, and when it encounters the Enter key, run your hardware setting code, and then highlight the full text of the textbox again (see below) - Windows will take care of clearing the text with the next keystroke for you.
TextBox1.Select(0, TextBox1.Text.Length);

"
16140,"Well, since you can not have one part OSGi and one part non-OSGi you'll need to make your entire app OSGi. In its simplest form you make a single OSGi bundle out of your entire application. Clearly this is not a best practice but it can be useful to get a feel for deploying a bundle in an OSGi container (Equinox, Felix, Knoplerfish, etc).
To take it to the next level you'll want to start splitting your app into components, components should typically have a set of responsibilities that can be isolated from the rest of your application through a set of interfaces and class dependencies. Identifying these purely by hand can range from rather straightforward for a well designed highly cohesive but loosely coupled application to a nightmare for interlocked source code that you are not familiar with.
Some help can come from tools like JDepend which can show you the coupling of Java packages against other packages/classes in your system. A package with low efferent coupling should be easier to extract into an OSGi bundle than one with high efferent coupling. Even more architectural insight can be had with pro tools like Structure 101.
Purely on a technical level, working daily with an application that consists of 160 OSGi bundles and using Spring DM I can confirm that the transition from ""normal"" Spring to Spring DM is largely pain free. The extra namespace and the fact that you can (and should) isolate your OSGi specific Spring configuration in separate files makes it even easier to have both with and without OSGi deployment scenarios.
OSGi is a deep and wide component model, documentation I recommend:

OSGi R4 Specification: Get the PDFs of the Core and Compendium specification, they are canonical, authoritative and very readable. Have a shortcut to them handy at all times, you will consult them.
Read up on OSGi best practices, there is a large set of things you can do but a somewhat smaller set of things you should do and there are some things you should never do (DynamicImport: * for example). 

Some links: 

OSGi best practices and using Apache Felix
Peter Kriens and BJ Hargrave in a Sun presentation on OSGi best practices 
one key OSGi concept are Services, learn why and how they supplant the Listener pattern with the Whiteboard pattern
The Spring DM Google Group is very responsive and friendly in my experience
The Spring DM Google Group is no longer active and has moved to Eclipse.org as the Gemini Blueprint project which has a forum here.

"
16320,"I like a single object to be correlated to a single record in the database, i.e. an object must be instantiated.  This is your basic ActiveRecord pattern.  In my experience, the one-object-to-one-row approach creates a much more fluid and literate presentation in code.  Also, I like to treat objects as records and the class as the table. For example to change the name of a record I do:
objPerson = new Person(id)

objPerson.name = ""George""

objPerson.save()

while to get all people who live in Louisiana I might do
aryPeople = Person::getPeopleFromState(""LA"")

There are plenty of criticisms of Active Record.  You can especially run into problems where you are querying the database for each record or your classes are tightly coupled to your database, creating inflexibility in both.  In that case you can move up a level and go with something like DataMapper. 
Many of the modern frameworks and ORM's are aware of some of these drawbacks and provide solutions for them.  Do a little research and you will start to see that this is a problem that has a number of solutions and it all depend on your needs. 
"
16330,"Investigate the post-redirect-get pattern.
http://weblogs.asp.net/mhawley/archive/tags/MVC/default.aspx
http://devlicio.us/blogs/tim_barcz/archive/2008/08/22/prg-pattern-in-the-asp-net-mvc-framework.aspx
Use that along with a robust domain model (for tracking steps or form completion state or whatever you call it) and you're golden.
"
16340,"The hash code of an object shouldn't be unique. 
The checking rule is: 

Are the hash codes equal? Then call the full (slow) Equals method.
Are the hash codes not equal? Then the two items are definitely not equal.

All you want is a GetHashCode algorithm that splits up your collection into roughly even groups - it shouldn't form the key as the HashTable or Dictionary<> will need to use the hash to optimise retrieval.
How long do you expect the data to be? How random? If lengths vary greatly (say for files) then just return the length.  If lengths are likely to be similar look at a subset of the bytes that varies.
GetHashCode should be a lot quicker than Equals, but doesn't need to be unique.
Two identical things must never have different hash codes. Two different objects should not have the same hash code, but some collisions are to be expected (after all, there are more permutations than possible 32 bit integers).
"
16460,"If you want to specify both a limit for number of items to remove and a condition to select the items to remove, you can use this approach:
int limit = 30; // Suppose you want to remove 30 items at most
list.RemoveAll(item => ShouldIRemoveThis(item) && limit-- > 0);

"
16550,"We actually use a combination of NAnt and MSBuild with CruiseControl. NAnt is used for script flow control and calls MSBuild to compile projects. After the physical build is triggered, NAnt is used to publish the individual project build outputs to a shared location.
I am not sure this is the best process. I think many of us are still looking for a great build tool. One promising thing I heard recently on .NET Rocks, episode 362, is James Kovac's PSake, a build system he based entirely on PowerShell. It sounds really promising since what you can do with PowerShell is fairly limitless in theory.
"
16610,"I posted an answer on another question on another topic that might have some use here.  That answer involved SMB connections, not SQL.  However it was identical in that it involved a low-level transport error.
What we found was that in a heavy load situation, it was fairly easy for the remote server to time out connections at the TCP layer simply because the server was busy.  Part of the reason was the defaults for how many times TCP will retransmit data on Windows weren't appropriate for our situation.
Take a look at the registry settings for tuning TCP/IP on Windows.  In particular you want to look at TcpMaxDataRetransmissions and maybe TcpMaxConnectRetransmissions.  These default to 5 and 2 respectively, try upping them a little bit on the client system and duplicate the load situation.
Don't go crazy!  TCP doubles the timeout with each successive retransmission, so the timeout behavior for bad connections can go exponential on you if you increase these too much.  As I recall upping TcpMaxDataRetransmissions to 6 or 7 solved our problem in the vast majority of cases.
"
16660,"AS far as I know, there is no way to localize a report (meaning automating the translation of string litterals)...
Like you said,you basically have to use the User!Language global variable to catch the user's settings and then use that to retrieve the appropriate strings from the DB...
However, you can adapt the display of currency/numeric/date fields according to the user locale. Also possible is changing the interface of the Report Viewer to match your user's langage.
Here are a few links giving tips on how to adapt the locale:
http://www.ssw.com.au/Ssw/Standards/Rules/RulesToBetterSQLReportingServices.aspx#LanguageSetting
Langage pack for Report Viewer:
http://www.microsoft.com/downloads/details.aspx?displaylang=en&FamilyID=e3d3071b-d919-4ff9-9696-c11d312a36a0
"
16770,"Haskell's algebraic data types are named such since they correspond to an initial algebra in category theory, giving us some laws, some operations and some symbols to manipulate. We may even use algebraic notation for describing regular data structures, where:

+ represents sum types (disjoint unions, e.g. Either).
â¢ represents product types (e.g. structs or tuples)
X for the singleton type (e.g. data X a = X a)
1 for the unit type ()
and Î¼ for the least fixed point (e.g. recursive types), usually implicit.

with some additional notation:

XÂ² for Xâ¢X

In fact, you might say (following Brent Yorgey) that a Haskell data type is regular if it can be expressed in terms of 1, X, +, â¢, and a least ï¬xed point.
With this notation, we can concisely describe many regular data structures:

Units: data () = ()
1
Options: data Maybe a = Nothing | Just a
1 + X
Lists: data [a] = [] | a : [a]
L = 1+Xâ¢L
Binary trees: data BTree a = Empty | Node a (BTree a) (BTree a)
B = 1 + Xâ¢BÂ²

Other operations hold (taken from Brent Yorgey's paper, listed in the references):

Expansion: unfolding the fix point can be helpful for thinking about lists. L = 1 + X + XÂ² + XÂ³ + ... (that is, lists are either empty, or they have one element, or two elements, or three, or ...)
Composition, â¦, given types F and G, the composition F â¦ G is a type which builds âF-structures made out of G-structuresâ (e.g. R = X â¢ (L â¦ R) ,where L is lists, is a rose tree.
Differentiation, the derivative of a data type D (given as D') is the type of D-structures with a single âholeâ, that is, a distinguished location not containing any data. That amazingly satisfy the same rules as for differentiation in calculus:
1â² = 0
Xâ² = 1
(F + G)â² = F' + Gâ²
(F â¢ G)â² = F â¢ Gâ² + Fâ² â¢ G
(F â¦ G)â² = (Fâ² â¦ G) â¢ Gâ²


References:

Species and Functors and Types, Oh My!, Brent A. Yorgey, Haskellâ10, September 30, 2010, Baltimore, Maryland, USA
Clowns to the left of me, jokers to the right (Dissecting Data Structures), Conor McBride POPL 2008

"
16860,"Ok here's some best practices from some one who doesn't unit test as much as he should...cough.

Make sure your tests test one
thing and one thing only.
Write unit tests as you go. Preferably before you write the code you are testing against.
Do not unit test the GUI. 
Separate your concerns. 
Minimise the dependencies of your tests.
Mock behviour with mocks.

"
16940,"You can right click on the tab strip and insert a new vertical (or horizontal) tab group.
This allows you to view multiple tabs at the same time.
"
16970,"None of the APIs for the more 'Word' like online editors seem to have any 'edit' functionality, just download and upload. This is obviously due to the complexity of the documents being stored.
With Google Docs API you can get a document, edit it, and then re-upload it (you may need to delete the previous version as well I think). Zoho seems to provide an 'update' method which combines the two operations.
Have you looked at the Google Notebook API instead? This might provide more granular access to the data in the 'note' due to its structured approach to storing the data.
"
17020,"If you partition your drive using LVM you won't have to worry about any individual partition running out of space in the future. Just move space around as necessary.
"
17140,"If you want to perform more complicated operations, like reading the output of the external program, you may be better served by the popen system call. For example, to programmatically access a directory listing (this is a somewhat silly example, but useful as an example), you could write something like this:
#include <stdio.h>

int main()
{
  int entry = 1;
  char line[200];
  FILE* output = popen(""/usr/bin/ls -1 /usr/man"", ""r"");
  while ( fgets(line, 199, output) )
  {
    printf(""%5d: %s"", entry++, line);
  }
}

to give output like this
1: cat1
2: cat1b
3: cat1c
4: cat1f
5: cat1m
6: cat1s
...

"
17170,"There are two rules I follow:

Accept the most basic type that will work
Return the richest type your user will need

So when writing a function or method that takes a collection, write it not to take a List, but an IList<T>, an ICollection<T>, or IEnumerable<T>.  The generic interfaces will still work even for heterogenous lists because System.Object can be a T too.  Doing this will save you headache if you decide to use a Stack or some other data structure further down the road.  If all you need to do in the function is foreach through it, IEnumerable<T> is really all you should be asking for.
On the other hand, when returning an object out of a function, you want to give the user the richest possible set of operations without them having to cast around.  So in that case, if it's a List<T> internally, return a copy as a List<T>.
"
17250,"I created a simple library to create a password encrypted zip file in python. - here
import pyminizip

compression_level = 5 # 1-9
pyminizip.compress(""src.txt"", ""dst.zip"", ""password"", compression_level)

The library requires zlib.
I have checked that the file can be extracted in WINDOWS/MAC.
"
17320,"Ben, Almost all seasoned programmers are still students in programming. You never stops learning anything when you are a developer. But if you are really starting off on your career then you should be least worried about the specialization thing. All APIs, frameworks and skills that you expect that gives you a long term existence in the field is not going to happen. Technology seems changing a lot and you should be versatile and flexible enough to learn anything. The knowledge you acquire on one platform/api/framework doesn't die off. You can apply the skills to the next greatest platform/api/framework. 
That being said you should just stop worrying about the future and concentrate on the basics. DataStructures, Algorithm Analysis and Design, Compiler Design, Operating system design are the bare minimum stuff you need.  And further you should be willing to go back and read tho books in those field any time in your career. Thats all is required. Good luck. 
Sorry if I sounded like a big ass advisor; but thats what I think. :-)
"
17370,"Yes, the OpenGL Extension Wrangler Library (GLEW) is a painless way to use OpenGL extensions on Windows. Here's how to get started on it:
Identify the OpenGL extension and the extension APIs you wish to use. OpenGL extensions are listed in the OpenGL Extension Registry.
Check if your graphic card supports the extensions you wish to use. Download and install the latest drivers and SDKs for your graphics card.
Recent versions of NVIDIA OpenGL SDK ship with GLEW. If you're using this, then you don't need to do some of the following steps.
Download GLEW and unzip it.
Add the GLEW bin path to your Windows PATH environment variable. Alternatively, you can also place the glew32.dll in a directory where Windows picks up its DLLs.
Add the GLEW include path to your compiler's include directory list.
Add the GLEW lib path to your compiler's library directory list.
Instruct your compiler to use glew32.lib during linking. If you're using Visual C++ compilers then one way to do this is by adding the following line to your code:
#pragma comment(lib, ""glew32.lib"")

Add a #include <GL/glew.h> line to your code. Ensure that this is placed above the includes of other GL header files. (You may actually not need the GL header files includes if you include glew.h.)
Initialize GLEW using glewInit() after you've initialized GLUT or GL. If it fails, then something is wrong with your setup.
if (GLEW_OK != glewInit())
{
    // GLEW failed!
    exit(1);
}

Check if the extension(s) you wish to use are now available through GLEW. You do this by checking a boolean variable named GLEW_your_extension_name which is exposed by GLEW.

Example:

if (!GLEW_EXT_framebuffer_object)
{
    exit(1);
}

That's it! You can now use the OpenGL extension calls in your code just as if they existed naturally for Windows.
"
17430,"You don't test the converter, you test the final code. 
If the code doesn't compile, clearly your converter is failing. If the code compiles and your functionality tests fail, then you can tweak the code so that it passes the test. If you are fairly successful you should see that you only need to fix the modules that actually fail.
Goodluck!
"
17500,"A Microsoft employee recently stated CheckAccess is used only for ""advanced scenarios"", so they hid it from Intellisense.

""CheckAccess and VerifyAccess have
  always been marked to be not visible,
  maybe IntelliSense wasn't respecting
  it.  You can use Reflector to confirm.
  The idea here is that CheckAccess and
  VerifyAccess are advances scenarios,
  that normal developers don't need.
However, I do think that
  EditorBrowsableState.Advanced would
  have been a more appropriate level.""

There's a Microsoft Connect case for this shortcoming. Vote for it if it's important to you.
"
17670,"Any semi-decent algorithm will end up with a strong chance of generating a NULL value somewhere in the resulting ciphertext.
Why not do something like base-64 encode your resulting binary blob before persisting to the DB? (sample implementation in C++).
"
17770,"Two Things I do:

I blog about it - this allows me to go back and search my own blog.
We use the code snippet feature in Visual Studio.

Cheers.
"
17840,"I wrote 8 longish blog entries on monadic parser combinators in C# and F#; see here for the first one.
See also FParsec (Parsec for F#)
"
17870,"Sure thing, the simplest way is this:
select foo from bar where baz in (1,2,3)

"
17880,"I'd suggest that modifying the underlying XML file is ""considered harmful"".  Especially if you haven't checked to see if the document is open!
I've had a quick look at the Scripting Dictionary for Pages, and it seems pretty comprehensive; here is part of one entry:

documentân [inh. document > item; see also Standard Suite] : A Pages document.
elements
contains captured pages, character
  styles, charts, graphics, images,
  lines, list styles, pages, paragraph
  styles, sections, shapes, tables, text
  boxes.
properties
body text (text) : The main text flow of the document.
bottom margin (real) : The bottom margin of the publication.
facing pages (boolean) : Whether or not the view is set to facing
  pages.
footer margin (real) : The footer margin of the publication.
header margin (real) : The header margin of the publication.
id (integer, r/o) : The unique identifier of the document.
...

So, I guess I'd want to know what it is that you want to do that you can't do with AppleScript?
"
17960,"Cross-referencing with this thread, which helped me with the same question:
Subsonic Access To App.Config Connection Strings From Referenced DLL in Powershell Script
I added the following to my script, before invoking the DLL that needs config settings, where $configpath is the location of the file I want to load:
[appdomain]::CurrentDomain.SetData(""APP_CONFIG_FILE"", $configpath)
Add-Type -AssemblyName System.Configuration

"
17980,"http://en.wikipedia.org/wiki/Printf#printf_format_placeholders is Wikipedia's reference for format placeholders in printf. http://www.cplusplus.com/reference/clibrary/cstdio/printf.html is also helpful
Basically in a simple form it's %[width].[precision][type]. Width allows you to make sure that the variable which is being printed is at least a certain length (useful for tables etc). Precision allows you to specify the precision a number is printed to (eg. decimal places etc) and the informs C/C++ what the variable you've given it is (character, integer, double etc).
Hope this helps
UPDATE:
To clarify using your examples:
printf( ""%10.1f     %10.2\n"", radius, area );

%10.1f (referring to the first argument: radius) means make it 10 characters long (ie. pad with spaces), and print it as a float with one decimal place.
%10.2 (referring to the second argument: area) means make it 10 character long (as above) and print with two decimal places.
"
18010,"Older AnkhSVN (pre 2.0) was very crappy and I was only using it for shiny icons in the solution explorer. I relied on Tortoise for everything except reverts.
The newer Ankh is a complete rewrite (it is now using the Source Control API of the IDE) and looks & works much better. Still, I haven't forced it to any heavy lifting. Icons is enough for me.
The only gripe I have with 2.0 is the fact that it slaps its footprint to .sln files. I always revert them lest they cause problems for co-workers who do not have Ankh installed. Dunno if my fears are groundless or not.

addendum:
I have been using v2.1.7141 a bit more extensively for the last few weeks and here are the new things I have to add:

No ugly crashes that plagued v1.x. Yay!
For some reason, ""Show Changes"" (diff) windows are limited to only two. Meh.
Diff windows do not allow editing/reverting yet. Boo!
Updates, commits and browsing are MUCH faster than Tortoise. Yay!

All in all, I would not use it standalone, but once you start using it, it becomes an almost indispensable companion to Tortoise.
"
18080,"It should be noted that google analytics is not an accurate representation of web site usage. This is because the web beacon (web bug) used on the page does not always load for these reasons:

Google analytics servers are called by millions of pages every second and can not always process the requests in a timely fashion.
Users often browse away from a page before the full page has loaded and thus there is not enough time to load Googles web beacon to record a hit.
Google analytics require javascript to be installed which can be disabled.
Quite a few (but not substantial amount) of people block google-analytics.com from their browsers, myself included.

The physical log files are the best 'real' representation of site usage as they record every request. Alternatively there are far better 'professional' packages, of which Omniture is my favourite, which have much better response times, alternative methods for recording actions and more functionality.
"
18250,"Delete the executable as part of a pre-link event.
Edit:
Hah, I forgot about Explorer resetting the creation date if you name a file exactly the same as a file that was recently deleted.
Why are you keying off the creation date anyway?
"
18290,"The way I have tackled this is to put the database password in a file with read permissions only for the user I run my application as.  Then, in database.yml I use ERB to read the file:
production:
  adapter: mysql
  database: my_db
  username: db_user
  password: <%= begin IO.read(""/home/my_deploy_user/.db"") rescue """" end %>

Works a treat.
"
18450,"There are a couple of scenarios to consider: (a) if you are porting an existing application and wondering if Mono is good enough for this task;   (b) you are starting to write some new code, and you want to know if Mono is mature enough.
For the first case, you can use the Mono Migration Analyzer tool (Moma) to evaluate how far your application is from running on Mono.  If the evaluation comes back with flying colors, you should start on your testing and QA and get ready to ship.
If your evaluation comes back with a report highlighting features that are missing or differ significantly in their semantics in Mono you will have to evaluate whether the code can be adapted, rewritten or in the worst case whether your application can work with reduced functionality.      
According to our Moma statistics based on user submissions (this is from memory) about 50% of the applications work out of the box, about 25% require about a week worth of work (refactoring, adapting) another 15% require a serious commitment to redo chunks of your code, and the rest is just not worth bothering porting since they are so incredibly tied to Win32.   At that point, either you start from zero, or a business decision will drive the effort to make your code portable, but we are talking months worth of work (at least from the reports we have).
If you are starting from scratch, the situation is a lot simpler, because you will only be using the APIs that are present in Mono.   As long as you stay with the supported stack (which is pretty much .NET 2.0, plus all the core upgrades in 3.5 including LINQ and System.Core, plus any of the Mono cross-platform APIs) you will be fine.  
Every once in a while you might run into bugs in Mono or limitations, and you might have to work around them, but that is not different than any other system.
As for portability: ASP.NET applications are the easier ones to port, as those have little to no dependencies on Win32 and you can even use SQL server or other popular databases (there are plenty of bundled database providers with Mono).   
Windows.Forms porting is sometimes trickier because developers like to escape the .NET sandbox and P/Invoke their brains out to configure things as useful as the changing the cursor blinking rate expressed as two bezier points encoded in BCD form in a wParam.   Or some junk like that.
"
18460,"I've been using forms authentication and creating the necessary GenericIdentity and CustomPrincipal objects that allows me to leverage the User.IsInRole type functions you typically only get with Windows authentication.
That way in my web.config file, I can do stuff like...
<location path=""Login.aspx"">
   <system.web>
      <authorization>
         <allow users =""*"" />
      </authorization>
   </system.web>
</location>

<location path=""ManagementFolder"">
   <system.web>
      <authorization>
         <allow roles =""Administrator, Manager"" />
      </authorization>
   </system.web>
</location>

"
18700,"
Popularity
Community contribution
Public scrutiny
We will be forced to adhere to standards. (which will in turn make the product better)
Goodwill

"
18920,"You can, but probably don't want to, set the document root on a per-file basis in the  head of your file:

<base href=""my-root"">

"
19030,"
I want to add a rule that checks for
  the presence of a folder.jpg file in
  each directory, but to add this would
  make the code substantially more messy
  in it's current state..

This doesn't look bad.  In fact your current code does it very nicely, and Sven mentioned a good way to do it as well:

Get a list of all the files
Check for ""required"" files

You would just have have add to your dictionary a list of required files:
checker = {
  ...
  'required': ['file', 'list', 'for_required']
}

As far as there being a better/extensible way to do this?  I am not exactly sure.  I could only really think of a way to possibly drop the ""multiple"" regular expressions and build off of Sven's idea for using a delimiter.  So my strategy would be defining a dictionary as follows (and I'm sorry I don't know Python syntax and I'm a tad to lazy to look it up but it should make sense.  The /regex/ is shorthand for a regex):
check_dict = {
  'delim'    : /\-/,
  'parts'    : [ 'Show Name', 'Episode Name', 'Episode Number' ],
  'patterns' : [/valid name/, /valid episode name/, /valid number/ ],
  'required' : ['list', 'of', 'files'],
  'ignored'  : ['.*', 'hidden.txt'],
  'start_dir': '/path/to/dir/to/test/'
}


Split the filename based on the delimiter.
Check each of the parts.

Because its an ordered list you can determine what parts are missing and if a section doesn't match any pattern it is malformed.  Here the parts and patterns have a 1 to 1 ratio.  Two arrays instead of a dictionary enforces the order.
Ignored and required files can be listed.  The . and .. files should probably be ignored automatically.  The user should be allowed to input ""globs"" which can be shell expanded.  I'm thinking here of svn:ignore properties, but globbing is natural for listing files.
Here start_dir would be default to the current directory but if you wanted a single file to run automated testing of a bunch of directories this would be useful.
The real loose end here is the path template and along the same lines what path is required for ""valid files"".  I really couldn't come up with a solid idea without writing one large regular expression and taking groups from it... to build a template.  It felt a lot like writing a TextMate language grammar.  But that starts to stray on the ease of use.  The real problem was that the path template was not composed of parts, which makes sense but adds complexity.
Is this strategy in tune with what you were thinking of?
"
19280,"Javascript offers 3 modal boxes.  Prompt, confirm and alert.  None of those satisfy your request.  
There are a plethora of js modal popup solutions.  Here's an example.

ModalBox

"
19790,"You can use a DataList control instead. It has a RepeatColumns property that you can define the number of columns you want to display.
In .NET Framework 3.5, there is an even better solution, the ListView control. You can find further information about how to use the ListView control here.
"
19970,"I don't really know javascript, but couldn't you create a stack of windows?
"
20040,"The number one rule is do NOT just ask for status updates.  It is Especially annoying when phrases like ""where are we on this?"" are used.   If you aren't directly involved in the details then just make sure you have established communication times or plans so that you know whats going on rather than asking for updates.
"
20420,"You sound as if you're looking for three major things: code templates, refactoring tools, and auto-completion.
The good news is that Xcode 3 and later come with superb auto-completion and template support.  By default, you have to explicitly request completion by hitting the escape key.  (This actually works in all NSTextViews; try it!)  If you want to have the completions appear automatically, you can go to Preferences -> Code Sense and set the pop-up to appear automatically after a few seconds.  You should find good completions for C and Objective-C code, and pretty good completions for C++.
Xcode also has a solid template/skeleton system that you can use.  You can see what templates are available by default by going to Edit -> Insert Text Macro.  Of course, you don't want to insert text macros with the mouse; that defeats the point.  Instead, you have two options:

Back in Preferences,go to Key Bindings, and then, under Menu Key Bindings, assign a specific shortcut to macros you use often.  I personally don't bother doing this, but I know plenty of great Mac devs who do
Use the CompletionPrefix.  By default, nearly all of the templates have a special prefix that, if you type and then hit the escape key, will result in the template being inserted.  You can use Control-/ to move between the completion fields.
You can see a full list of Xcode's default macros and their associated CompletionPrefixes at Crooked Spin.
You can also add your own macros, or modify the defaults.  To do so, edit the file /Developer/Library/Xcode/Specifications/{C,HTML}.xctxtmacro.  The syntax should be self-explanatory, if not terribly friendly.

Unfortunately, if you're addicted to R#, you will be disappointed by your refactoring options.  Basic refactoring is provided within Xcode through the context menu or by hitting Shift-Apple-J.  From there, you can extract and rename methods, promote and demote them through the class hierarchy, and a few other common operations.  Unfortunately, neither Xcode nor any third-party utilities offer anything approaching Resharper, so on that front, you're currently out of luck.  Thankfully, Apple has already demonstrated versions of Xcode in the works that have vastly improved refactoring capabilities, so hopefully you won't have to wait too long before the situation starts to improve.
"
20450,"I would use a hidden RichTextBox, set the Rtf member, then retrieve the Text member to sanitize the RTF in a well-supported way.  Then I would use manually inject the desired formatting afterwards.
"
20510,"There's no need for the JavaScript function, the first argument to ExternalInterface can be any JavaScript code, it doesn't have to be a function name (the documentation says so, but it is wrong).
Try this:
ExternalInterface.call(""alert('hello')"");

"
20840,"From MSDN:

When this option is set, it is possible to read uncommitted or dirty data; values in the data can be changed and rows can appear or disappear in the data set before the end of the transaction. 

Simply put, when you are using this isolation level, and you are performing multiple queries on an active table as part of one transaction, there is no guarantee that the information returned to you within different parts of the transaction will remain the same. You could query the same data twice within one transaction and get different results (this might happen in the case where a different user was updating the same data in the midst of your transaction). This can obviously have severe ramifications for parts of your application that rely on data integrity.
"
20850,"The following entry in /etc/fstab will do what you want, even on 10.5 (Leopard):
LABEL=VolumeName  none    ntfs    noauto

If the file is not already there, just create it. Do not use /etc/fstab.hd! No reloading of diskarbitrationd needed.
If this still doesn't work for you, maybe you can find a hint in the syslog.
"
20880,"Can you give us some more information on how you add the combo boxes to the JPanel?  This is a pretty common thing to do in Swing so I doubt that it's a JVM issue but I guess anything is possible.
Specifically, I would double check to make sure you're not accessing the GUI from any background threads.  In this case, maybe you're reading the choices from a DB or something and updating the JComboBox from a background thread, which is a big no-no in Swing.  See SwingUtils.invokeLater().
"
20910,"I think you should look at Silverlight as a long-term play, just as Microsoft seems to be doing. There's an obvious balance on when to use Silverlight vs. Flash when you're concerned about reach and install base, but here are some reasons Silverlight is a good direction to move in:

Second mover advantage - Just as Microsoft built a ""better Java"" with .NET, they're able to look at how you'd design a RIA plugin from scratch, today. They have the advantage of knowing how people use the web today, something the inventors of Flash could never have accurately guessed. Flash can add features, but they can't realistically chuck the platform and start over.
Developer familiarity - While Silverlight is a new model, it's not entirely unfamiliar to developers. They'll ""get"" the way Silverlight works a lot more quickly than they'll understand firing up a new development environment with a new scripting language and new event paradigms.
Being rid of the timeline model in Flash - Flash was originally built for keyframe based animations, and while there are ways to abstract this away, it's at the core of how Flash works. Silverlight ditches that for an application-centric model. 
ScottGu - ScottGu is fired up about Silverlight. Nuff said.
Cool new features - While Silverlight still has some catching up to do with Flash on some obvious features (like webcam / mic integration, or 3d / graphics acceleration), there are some slick new technologies built in to Silverlight - Deep Zoom is one example. I'm seeing more ""revolutionary"" technologies on the Silverlight side, while Flash seems to be in maintenance mode at this point.

"
21280,"LINQ is not about SQL. LINQ is about being apply functional programming paradigmns on objects.
LINQ to SQL is an ORM built ontop of the LINQ foundation, but LINQ is much more. I don't use LINQ to SQL, yet I use LINQ all the time.
Take the task of finding the intersection of two lists:
Before LINQ, this tasks requires writing a nested foreach that iterates the small list once for every item in the big list O(N*M), and takes about 10 lines of code.
foreach (int number in list1)
{
    foreach (int number2 in list2)
    {
        if (number2 == number)
        {
            returnList.add(number2);
        }
    }
}

Using LINQ, it does the same thing in one line of code:
var results = list1.Intersect(list2);

You'll notice that doesn't look like LINQ, yet it is. You don't need to use the expression syntax if you don't want to.
"
21460,"I know this is an old question, but here is the answer: yes, Hostmonster does support Django
There used to be this Hostmonster KB article for details, including instructions on how to set it up, but that link appears to be dead these days, and the only article about Hostmonster article about Django is about troubleshooting. You can find instructions on how to set up Django on Hostmonster elsewhere.
"
21560,"I finally got Multisampling working with my wxWidgets OpenGL program. It's a bit messy right now, but here's how:
wxWidgets doesn't have Multisampling support in their stable releases right now (latest version at this time is 2.8.8). But, it's available as a patch and also through their daily snapshot. (The latter is heartening, since it means that the patch has been accepted and should appear in later stable releases if there are no issues.)
So, there are 2 options:

Download and build from their daily snapshot.
Get the patch for your working wxWidgets installation.

I found the 2nd option to be less cumbersome, since I don't want to disturb my working installation as much as possible. If you don't know how to patch on Windows, see this.
At the very least, for Windows, the patch will modify the following files:
$(WX_WIDGETS_ROOT)/include/wx/glcanvas.h
$(WX_WIDGETS_ROOT)/include/wx/msw/glcanvas.h
$(WX_WIDGETS_ROOT)/src/msw/glcanvas.cpp

After patching, recompile the wxWidgets libraries.
To enable multisampling in your wxWidgets OpenGL program, minor changes to the code are required.
An attribute list needs to be passed to the wxGLCanvas constructor:
int attribList[] = {WX_GL_RGBA,
                    WX_GL_DOUBLEBUFFER,
                    WX_GL_SAMPLE_BUFFERS, GL_TRUE, // Multi-sampling
                    WX_GL_DEPTH_SIZE, 16,
                    0, 0};

If you were already using an attribute list, then add the line with GL_SAMPLE_BUFFERS, GL_TRUE to it. Else, add this attribute list definition to your code.
Then modify your wxGLCanvas constructor to take this attribute list as a parameter:
myGLFrame::myGLFrame    // Derived from wxGLCanvas
(
    wxWindow *parent,
    wxWindowID id,
    const wxPoint& pos,
    const wxSize& size,
    long style,
    const wxString& name
)
: wxGLCanvas(parent, (wxGLCanvas*) NULL, id, pos, size, style, name, attribList)
{
    // ...
}

After the wxGLCanvas element is created, multisampling is turned on by default. To disable or enable it at will, use the related OpenGL calls:
glEnable(GL_MULTISAMPLE);
glDisable(GL_MULTISAMPLE);

Multisampling should now work with the wxWidgets OpenGL program. Hopefully, it should be supported in the stable release of wxWidgets soon, making this information irrelevant :-)
"
21640,"Even though @Rick has the accepted answer for this question, there's actually a shorter way to do this, using the poorly named Uri.GetLeftPart() method.
Uri url = new Uri(""http://www.mywebsite.com:80/pages/page1.aspx"");
string output = url.GetLeftPart(UriPartial.Authority);

There is one catch to GetLeftPart(), however. If the port is the default port for the scheme, it will strip it out. Since port 80 is the default port for http, the output of GetLeftPart() in my example above will be http://www.mywebsite.com. 
If the port number had been something other than 80, it would be included in the result.
"
21830,"First of all, do you need to use them for text search indexing? GIN and GiST are index specialized for some data types. If you need to index simple char or integer values then the normal B-Tree index is the best.
Anyway, PostgreSQL documentation has a chapter on GIST and one on GIN, where you can find more info.
And, last but not least, the best way to find which is best is to generate sample data (as much as you need to be a real scenario) and then create a GIST index, measuring how much time is needed to create the index, insert a new value, execute a sample query. Then drop the index and do the same with a GIN index. Compare the values and you will have the answer you need, based on your data.
"
21870,"These are the items that I consider for the topic of Caching:
MemCached Win32
Velocity
.net Cache
Enterprise Library Caching Application Block
MemCached Win32: Up until recently I have used MemCached Win32.  This is a akin to a web farm (many servers serving the same content for high availability) but it is a cache farm.  This means that you can install it locally on your web server initially if you don't have the resources to go bigger.  Then as you go down the road you can scale horizontally (more servers) or vertically (more hardware).  This is a product that was ported from the original MemCached to work on Windows.  This product has been used extensively in very high traffic sites.  http://lineofthought.com/tools/memcached
Velocity: This is Microsofts answer to products such as MemCached.  MemCached has been out for quite some time, Velocity is in CTP mode.  I must say that from what I have read so far this product will certainly turn my head once it is out.  But I can't bring myself to run big production projects on a CTP product with zero track record.  I have started playing with it though as once it gains momentum MemCached won't even compare for those locked in the windows world!  http://blogs.msdn.com/velocity/
.NET Cache:  There is no reason to discount the standard .NET Cache.  It is built in and ready to use for free and with no (major) set up required.  It offers flexibility by way of offering mechanisms for storing items in local memory, a SINGLE state server, or a centralized database.  Where Velocity steps in is when you need more than a single state server (cache in memory) and don't want to use a slow database for holding your cache.
Enterprise Application Block: I stay away from all of the Enterprise Application Blocks.  They are heavy frameworks that give more than I generally require!  As long as you remember to wrap everything that touches code that is not your own and follow simple rules for coding, stick to any of the other methods over this one!  (just my opinion of course - MySpace leverages as much as they can out of Enterprise Application Blocks!)
You don't have to choose up front!  I generally create a cache wrapper that I communicate with in my code for methods such as Get, Set, Exists, Remove, ListKeys, etc.  This then points to an underlying level of cache abstraction that can point to MemCached, Velocity, or .NET cache.  I use StructureMap (or choose another IoC container) to inject which form of cache I want to use for a given environment.  In my local dev box I might use .NET cache in the session.  In production I generally use MemCached Win 32.  But regardless of how it is set up you can easily swap things around to try each system out to see what works best for you.  You just need to make sure that you application knows as little as possible about how things are cached!  Once this layer of abstraction is in place you can then do things such as run a compression algorithm (gzip) for all the data that is going in and out of cache which would allow you to store 10 times the amount of data in cache. - transparently.
I cover .NET Cache, MemCached Win32, StructureMap, and the appropriate abstractions in my book if you are interested!
ASP.NET 3.5 Social Networking (http://www.amazon.com/ASP-NET-3-5-Social-Networking-Enterprise-ready/dp/1847194788/ref=sr_1_1?ie=UTF8&s=books&qid=1225408005&sr=8-1 )
Andrew Siemer www.andrewsiemer.com blog.andrewsiemer.com www.socialnetworkingin.net
Update
Changed the link that lists sites using memcached.  Thank you David for noticing that it was broken!
"
22000,"I think you need to use display: block on your images. When images are inline there's a little extra space for the line spacing.
"
22140,"I think the way to do(get around) this problem is to develop a ""./configure && make"" script that your client uses to install, specify and compile the binaries. That would offcourse require that the client has all the source-code installed on his server or you can make it available on an NFS share.
"
22340,"I've found a couple of solutions:
ZeroC Ice GPL with a commercial option. Have only tested quickly. Looks more powerful than .NET Remoting and is very actively developed.
RemObjects Commercial, active development, supports everything but does not seem to have all the more advanced features that GenuineChannels use.
GenuineChannels. It uses remoting with a lot of nice added features, the most important one being it works through NATs without the need to open the client firewall. Unfortunately seems to be very dead.
Another solution is to use streaming with IIS, according to this article: Keeping connections open in IIS
The client makes the first connection (http with IIS6, tcp with IIS7) to the server at port 80, the connection is then kept open with a streaming response that never ends.
I haven't had the time to experiment with this, and I haven't found a sample that says it specifically solves the firewall-problem, but here's an excellent sample that probably works: Streaming XML. 
"
22500,"There may be some confusion here about what ""K&R C"" is. The term refers to the language as documented in the first edition of ""The C Programming Language."" Roughly speaking: the input language of the Bell Labs C compiler circa 1978.
Kernighan and Ritchie were involved in the ANSI standardization process. The ""ANSI C"" dialect superceded ""K&R C"" and subsequent editions of ""The C Programming Language"" adopt the ANSI conventions. ""K&R C"" is a ""dead language,"" except to the extent that some compilers still accept legacy code.
"
22570,"This is much more concise:
where 
  datediff(day, date1, date2) = 0

"
22590,"In our scenario, we have a separate file server that both of our front end app servers write to, that way you either server has access to the same sets of files.
"
22880,"Encrypting the session value will have zero effect. The session cookie is already an arbitrary value, encrypting it will just generate another arbitrary value that can be sniffed.
The only real solution is HTTPS. If you don't want to do SSL on your whole site (maybe you have performance concerns), you might be able to get away with only SSL protecting the sensitive areas. To do that, first make sure your login page is HTTPS. When a user logs in, set a secure cookie (meaning the browser will only transmit it over an SSL link) in addition to the regular session cookie. Then, when a user visits one of your ""sensitive"" areas, redirect them to HTTPS, and check for the presence of that secure cookie. A real user will have it, a session hijacker will not.
EDIT: This answer was originally written in 2008. It's 2016 now, and there's no reason not to have SSL across your entire site. No more plaintext HTTP!
"
22980,"The following will work
<%= Post.find_unread_by(current_user).size %>

or
<%= Post.find_unread_by(current_user).length %>

However if you check your development.log you should see that it gets the unread count by 

Retrieving all the posts
Retrieving all the posts read by the user
Removing all of 2. from 1. in ruby

This will be very bad performance wise with lots of posts. 
A better way would be to retrieve the posts read by the current user and then use ActiveRecord::Calculations to get a count without retrieving all the posts in the database
Post.count(:conditions => [ ""id NOT IN (?)"", Post.find_read_by(current_user)])

This should go into your Post model to follow best practices of not having finders in the view  or controller 
Post.rb
def self.unread_post_count_for_user(user)
  count(:conditions => [ ""id NOT IN (?)"", Post.find_read_by(user)])
end

Then your view will just be
<%= Post.unread_post_count_for_user(current-user) %>

"
23190,"@Jeff
I actually think this is an interesting question. I'm not sure how useful it is, but it is a valid question.
@Ed
Can you provide a little more info on this question? You said the dimension of the array is dynamic, but is the number of elements dynamic as well?
EDIT: I'm going to try and answer the question anyways. I can't give you the code off the top of my head (it would take a while to get it right without any compiler here on this PC), but I can point you in the right direction ...
Let's use 8 dimensions (0-7) with indexes 0 to 3 as an example. You care about only 1,2 and 6. This means you have two arrays. First, array_care[4][4][4] for 1,2, and 6. The array_care[4][4][4] will hold the end result.
Next, we want to iterate in a very specific way. We have the array input[4][4][4][4][4][4][4][4] to parse through, and we care about dimensions 1, 2, and 6.
We need to define some temporary indexes:
int dim[8] = {0,0,0,0,0,0,0,0};

We also need to store the order in which we want to increase the indexes:
int increase_index_order[8] = {7,5,4,3,0,6,2,1};
int i = 0;

This order is important for doing what you requested.
Define a termination flag:
bool terminate=false;

Now we can create our loop:
while (terminate)
{
array_care[dim[1]][dim[2]][dim[6]] += input[dim[0]][dim[1]][dim[2]][dim[3]][dim[4]][dim[5]][dim[6]][dim[7]];

while ((dim[increase_index_order[i]] = 3) && (i < 8))
{
dim[increase_index_order[i]]=0;
i++;
}

if (i < 8) {
dim[increase_index_order[i]]++; i=0;
} else {
terminate=true;
}
}

That should work for 8 dimensions, caring about 3 dimensions. It would take a bit more time to make it dynamic, and I don't have the time. Hope this helps. I apologize, but I haven't learned the code markups yet. :(
"
23250,"I don't mean this to sound snarky, but it doesn't matter.
Seriously.
Look at the things that are important: your project, your code, your job, your personal life. None of them are going to have their success rest on whether or not you use the ""this"" keyword to qualify access to fields. The this keyword will not help you ship on time. It's not going to reduce bugs, it's not going to have any appreciable effect on code quality or maintainability. It's not going to get you a raise, or allow you to spend less time at the office. 
It's really just a style issue. If you like ""this"", then use it. If you don't, then don't. If you need it to get correct semantics then use it. The truth is, every programmer has his own unique programing style. That style reflects that particular programmer's notions of what the ""most aesthetically pleasing code"" should look like. By definition, any other programmer who reads your code is going to have a different programing style. That means there is always going to be something you did that the other guy doesn't like, or would have done differently. At some point some guy is going to read your code and grumble about something. 
I wouldn't fret over it. I would just make sure the code is as aesthetically pleasing as possible according to your own tastes. If you ask 10 programmers how to format code, you are going to get about 15 different opinions. A better thing to focus on is how the code is factored. Are things abstracted right? Did I pick meaningful names for things? Is there a lot of code duplication? Are there ways I can simplify stuff? Getting those things right, I think, will have the greatest positive impact on your project, your code, your job, and your life. Coincidentally, it will probably also cause the other guy to grumble the least. If your code works, is easy to read, and is well factored, the other guy isn't going to be scrutinizing how you initialize fields. He's just going to use your code, marvel at it's greatness, and then move on to something else.
"
23270,"I could use a little more information to narrow down my answer, but here is what I have:
Internet Explorer has 5 different security zones be default: Local Machine Zone, Intranet, Internet, Trusted, and Restricted
These are determined in urlmon.dll (Url Moniker)
More information here: http://msdn.microsoft.com/en-us/library/ms537183(VS.85).aspx
But you can also implement your own custom security zone:
http://msdn.microsoft.com/en-us/library/ms537182(VS.85).aspx
The way that IE determines the security zones should not have changes between IE6 and IE7 (or IE8 for that matter)
Intranet sites are determined:
1. By url host names do not have any dots (http://stackoverflow vs http://stackoverflow.com)

Sites from the file:// scheme where the resource is collected from UNC

"
23310,"Anything but Visual Source Safe; preferably one which supports the concepts of branching and merging. As others have said, Subversion is a great choice, especially with the TortoiseSVN client.
Be sure to check out (pardon the pun) Eric Sink's classic series of Source Control HOWTO articles.
"
23370,"There are a few ambiguities in your question. What operation needs to be successful?
For everything you want to know about drag and drop, browse through these search results (multiple pages worth):
Raymond Chen on drag and drop
"
23490,"Let me be general [then specific]:

Your IDE of choice [VS 2008 here]
Your debugger [It is usually part of your IDE, but sometimes WinDbg is needed]
Its plugins for refactoring and source control [Resharper 4+ and Ankh SVN 2+]
Your OS's addons for source control [Tortoise SVN]
A better Diff and Merge Tool to plug into the above SCM tools [WinMerge]
A fast loading text editor for when your IDE is too much [vim, Notepad++]
If you're doing web development, get tools for that [Firefox 3 with Add-ons: Web Developer, Firebug, TamperData, Poster, Firecookie, FireFTP, FirePHP, Rainbow for Firebug, ReloadEvery, Selenium IDE]
Requisite tools for working with text [GNU TextUtils, via cygwin or gnuwin32.sf.net]
Scripting tools [Perl, Python, zsh, all those GNU base packages in cygwin]
A Regular Expression testing tool for when your eyes hurt [Expresso, RegexBuddy]

For Java I swap out 1 and 3 with Eclipse, and its plugins for Maven and SVN, I haven't found a refactoring plug in... you'd think I'd use IntelliJ IDEA but I never started using it.
"
23610,"Programatically or Manually?
Manually, i prefer AdExplorer, which is a nice Active directory Browser. You just connect to your domain controller and then you can look for the user and see all the details. Of course, you need permissions on the Domain Controller, not sure which though.
Programatically, it depends on your language of couse. On .net, the System.DirectoryServices Namespace is your friend. (I don't have any code examples here unfortunately)
For Active Directory, I'm not really an expert apart from how to query it, but here are two links I found useful:
http://www.computerperformance.co.uk/Logon/LDAP_attributes_active_directory.htm
http://en.wikipedia.org/wiki/Active_Directory (General stuff about the Structure of AD)
"
23620,"TinyMCE only goes out of its way to disable spell-checking when you don't specify the gecko_spellcheck option (i verified this with their example code). Might want to double-check your tinyMCE.init() call - it should look something like this:
tinyMCE.init({
	mode : ""textareas"",
	theme : ""simple"",
	gecko_spellcheck : true
});

"
23640,"I know a few of the developers on the Carleton University developed Blindside Project.  They are actively developing an open-source web conferencing and presentation tool for e-learning, with the intent of eventually offering university courses online.
It's pretty fully featured software, and is meant to be installed as a server that can host many conference rooms at a time.  It has voice, video, text, and a whiteboard/slideshow (Edit: supports PDF at the moment) capability.  One feature I think it neat is that students can 'raise their hands' in the class to ask the instructor a question, where they can take the floor for a moment.
Check out the demo on the site (if it's not working anymore I'll nudge the developers).  Another pro is that the clients only need to have flash installed.
I just logged onto the online demo and created this preview:
This project is now called BigBlueButton : http://code.google.com/p/bigbluebutton/
Here is the demo: http://demo.bigbluebutton.org/
"
23770,"One strategy you could use is MVCC, Multi-Value Concurrency Control.  In this scheme, you never do updates to any of your tables, you just do inserts, maintaining version numbers for each record.  This has the advantage of providing an exact snapshot from any point in time, and it also completely sidesteps the update lock problems that plague many databases.
But it makes for a huge database, and selects all require an extra clause to select the current version of a record.
"
23930,"Polyglot: 5 languages, all using bignums
So, I wrote a polyglot which works in the three languages I often write in, as well as one from my other answer to this question and one I just learned today.  It's a standalone program, which reads a single line containing a nonnegative integer and prints a single line containing its factorial.  Bignums are used in all languages, so the maximum computable factorial depends only on your computer's resources.

Perl: uses built-in bignum package.  Run with perl FILENAME.
Haskell: uses built-in bignums.  Run with runhugs FILENAME or your favorite compiler's equivalent.
C++: requires GMP for bignum support.  To compile with g++, use g++ -lgmpxx -lgmp -x c++ FILENAME to link against the right libraries.  After compiling, run ./a.out.  Or use your favorite compiler's equivalent.
brainf*ck: I wrote some bignum support in this post.  Using Muller's classic distribution, compile with bf < FILENAME > EXECUTABLE.  Make the output executable and run it.  Or use your favorite distribution.
Whitespace: uses built-in bignum support.  Run with wspace FILENAME.

Edit: added Whitespace as a fifth language.  Incidentally, do not wrap the code with <code> tags; it breaks the Whitespace.  Also, the code looks much nicer in fixed-width.
char //# b=0+0{- |0*/; #>>>>,----------[>>>>,--------
#define	a/*#--]>>>>++<<<<<<<<[>++++++[<------>-]<-<<<
#Perl	><><><>	 <> <> <<]>>>>[[>>+<<-]>>[<<+>+>-]<->
#C++	--><><>	<><><><	> < > <	+<[>>>>+<<<-<[-]]>[-]
#Haskell >>]>[-<<<<<[<<<<]>>>>[[>>+<<-]>>[<<+>+>-]>>]
#Whitespace	>>>>[-[>+<-]+>>>>]<<<<[<<<<]<<<<[<<<<
#brainf*ck > < ]>>>>>[>>>[>>>>]>>>>[>>>>]<<<<[[>>>>*/
exp; ;//;#+<<<<-]<<<<]>>>>+<<<<<<<[<<<<][.POLYGLOT^5.
#include <gmpxx.h>//]>>>>-[>>>[>>>>]>>>>[>>>>]<<<<[>>
#define	eval int	main()//>+<<<-]>>>[<<<+>>+>->
#include <iostream>//<]<-[>>+<<[-]]<<[<<<<]>>>>[>[>>>
#define	print std::cout	<< // >	<+<-]>[<<+>+>-]<<[>>>
#define	z std::cin>>//<< +<<<-]>>>[<<<+>>+>-]<->+++++
#define c/*++++[-<[-[>>>>+<<<<-]]>>>>[<<<<+>>>>-]<<*/
#define	abs int $n //><	<]<[>>+<<<<[-]>>[<<+>>-]]>>]<
#define	uc mpz_class fact(int	$n){/*<<<[<<<<]<<<[<<
use bignum;sub#<<]>>>>-]>>>>]>>>[>[-]>>>]<<<<[>>+<<-]
z{$_[0+0]=readline(*STDIN);}sub fact{my($n)=shift;#>>
#[<<+>+>-]<->+<[>-<[-]]>[-<<-<<<<[>>+<<-]>>[<<+>+>+*/
uc;if($n==0){return 1;}return $n*fact($n-1);	}//;#
eval{abs;z($n);print fact($n);print(""\n"")/*2;};#-]<->
'+<[>-<[-]]>]<<[<<<<]<<<<-[>>+<<-]>>[<<+>+>-]+<[>-+++
-}--	<[-]]>[-<<++++++++++<<<<-[>>+<<-]>>[<<+>+>-++
fact 0	= 1 -- ><><><><	> <><><	]+<[>-<[-]]>]<<[<<+ +
fact	n=n*fact(n-1){-<<]>>>>[[>>+<<-]>>[<<+>+++>+-}
main=do{n<-readLn;print(fact n)}-- +>-]<->+<[>>>>+<<+
{-x<-<[-]]>[-]>>]>]>>>[>>>>]<<<<[>+++++++[<+++++++>-]
<--.<<<<]+written+by+++A+Rex+++2009+.';#+++x-}--x*/;}

"
23950,"class Producer implements Runnable {
   private final BlockingQueue queue;
   Producer(BlockingQueue q) { queue = q; }
   public void run() {
     try {
       while (true) { queue.put(produce()); }
     } catch (InterruptedException ex) { ... handle ...}
   }
   Object produce() { ... }
 }

 class Consumer implements Runnable {
   private final BlockingQueue queue;
   Consumer(BlockingQueue q) { queue = q; }
   public void run() {
     try {
       while (true) { consume(queue.take()); }
     } catch (InterruptedException ex) { ... handle ...}
   }
   void consume(Object x) { ... }
 }

 class Setup {
   void main() {
     BlockingQueue q = new SomeQueueImplementation();
     Producer p = new Producer(q);
     Consumer c1 = new Consumer(q);
     Consumer c2 = new Consumer(q);
     new Thread(p).start();
     new Thread(c1).start();
     new Thread(c2).start();
   }
 }

This example was taken from the JDK 1.6 docs of BlockingQueue. So You can see that you are doing it the right way. Here's the quote which tells you that it have to work:

Memory consistency effects: As with
  other concurrent collections, actions
  in a thread prior to placing an object
  into a BlockingQueue happen-before
  actions subsequent to the access or
  removal of that element from the
  BlockingQueue in another thread.

"
23970,"You cannot marshal a Lambda or Proc. This is because both of them are considered closures, which means they close around the memory on which they were defined and can reference it. (In order to marshal them you'd have to Marshal all of the memory they could access at the time they were created.)
As Gaius pointed out though, you can use ruby2ruby to get a hold of the string of the program. That is, you can marshal the string that represents the ruby code and then reevaluate it later. 
"
24040,"So far, from what I have seen, RMC seems to be one-of-a-kind, which is both cool, but sad :(
It seems pretty inactive, but I have posted a couple of questions on there, and amazed at the response (a lot of people just have the RSS feed and wait for something to happen). So I would definately recommend just getting active on there..
However, I have read some great books on Safari including MS Press' ""Test Driven Development"" which I found really helped . However I have to admit, I still need a lot of work in adjusting my brain for TDD etc.
Following this question though! (+1) look forward to seeing if there is more out there! :)
Edit:
Just found this blog post that outlines a number of good bits of software, websites and books :) I knew I had one somewhere!
"
24130,"The ""class"" that you've constructed above is what most people would use a struct for in other languages. I'm not sure what the performance implications are in PHP, though I suspect instantiating the objects is probably more costly here, if only by a little bit.
That being said, if the cost is relatively low, it IS a bit easier to manage the objects, in my opinion.
I'm only saying the following based on the title and your question, but:
Bear in mind that classes provide the advantage of methods and access control, as well. So if you wanted to ensure that people weren't changing weights to negative numbers, you could make the weight field private and provide some accessor methods, like getWeight() and setWeight(). Inside setWeight(), you could do some value checking, like so:
public function setWeight($weight)
{
    if($weight >= 0)
    {
        $this->weight = $weight;
    }
    else
    {
        // Handle this scenario however you like
    }
}

"
24200,"You're already using SqlBulkCopy, which is a good start.
However, just using the SqlBulkCopy class does not necessarily mean that SQL will perform a bulk copy. In particular, there are a few requirements that must be met for SQL Server to perform an efficient bulk insert.
Further reading:

Prerequisites for Minimal Logging in Bulk Import
Optimizing Bulk Import Performance

Out of curiosity, why is your index set up like that? It seems like ContainerId/BinId/Sequence is much better suited to be a nonclustered index. Is there a particular reason you wanted this index to be clustered?
"
24270,"
The real world isn't ""OO"", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed

While this is true and has been observed by other people (take Stepanov, inventor of the STL), the rest is nonsense. OOP may be flawed and it certainly is no silver bullet but it makes large-scale applications much simpler because it's a great way to reduce dependencies. Of course, this is only true for âgoodâ OOP design. Sloppy design won't give any advantage. But good, decoupled design can be modelled very well using OOP and not well using other techniques.
There are much better, more universal models (Haskell's type model comes to mind) but these are also often more complicated and/or difficult to implement efficiently. OOP is a good trade-off between extremes.
"
24310,"An earlier post mentioned RFC1459. While it is a very good introduction to IRC, it has actually been superseded by RFCs 2810-2813. Here is a more complete list of documentation you need to program anything IRC-related:

RFC1459 (original RFC; superseded, but still useful)
RFC2810 (IRC architecture)
RFC2811 (IRC channel management)
RFC2812 (IRC client protocol)
RFC2813 (IRC server protocol)
CTCP specification
DCC specification
Updated CTCP specification (not all clients support this)
ISupport (response code 005) draft (almost all servers support this nowadays)
Client capabilities (CAP command) draft (supported by some servers/clients)
IRCv3 standards and proposals (the future features of IRC, some of which are already widely supported)

"
24450,"In my opinion, with contributions from the SO community

Zend Fraemwork for PHP
Django for Python
Rails for Ruby
Merb for Ruby (for the experienced)
ASP.NET MVC for .NET
Seaside for Smalltalk
Catalyst for Perl

"
24470,"Remember that the MAX aggregate function will work on text as well as numbers. This query  will only require the table to be scanned once.
SELECT Action,
       MAX( CASE data WHEN 'View' THEN data ELSE '' END ) ViewCol, 
       MAX( CASE data WHEN 'Edit' THEN data ELSE '' END ) EditCol
 FROM t
 GROUP BY Action

"
24580,"With VS2008 you can do this:
devenv solution.sln /build configuration

"
24610,"ViEmu works great with Visual Studio.  I used Vi(m) strictly in Linux, but I was turned on to bringing the Vi(m) editing process into the Windows world by JP Boodhoo.  JP praises about it also.
"
24620,"Because writing classes to be substitutably extended is damn hard and requires you to make accurate predictions of how future users will want to extend what you've written.
Sealing your class forces them to use composition, which is much more robust.
"
24680,"I would agree that Tortoise SVN in Windows Explorer would be the best way to use SVN with VB6.
The biggest change you will find migrating to SVN is the idea of ""Check out"" and ""Check in"" aren't exactly the same as ""Update"" and ""Commit"". . . thus, any IDE integration with VB6 is limited because VB6 supports MSSCCI, a check-out/check-in mechanism.  I once used TamTam SVN (http://www.daveswebsite.com/software/tamtamsvn/index.shtml) with Visual Studio 2003, but stopped since I found it limiting.  Merging/branching/blaming, etc. are very powerful features Tortoise SVN provides that weren't in TamTam. Tigris also has http://svnvb6.tigris.org/, but I have not tried it.
Again, while you quite possibly get an IDE to work with VB6, I would not recommend it since the greatest strength of migrating to SVN is to break the Source Safe philosophy of check-in/check-out.
"
24730,"I ran into this a long time ago with working in ASP.  I found this knowledge base article and it helped me out.  I hope it solves your problem.
http://support.microsoft.com/kb/269495
If this doesn't work and everything checks out, then it is probably your connection string.  I would try these steps next:
Remove:
DRIVER={SQL Server};

Edit the Provider to this:
Provider=SQLOLEDB;

"
25200,"I've seen similar behaviour when setting certain properties of controls in the constructor of the form itself. They seem to revert back to their design-time defaults.
I notice you're already overriding the OnLoad method. Have you tried setting AutoSize = false there? Or are you mainly concerned with providing a default value of false?
"
25240,"It looks like you could use a combination of GetHTML and SetHTML to get the current contents, append your html and reinsert everything into the editor. Although it does say 

Note that when using this method, you will lose any listener that you may have previously registered on the editor.EditorDocument.

Hope that helps!
"
25450,"What I found works best is to really learn CSS. I mean really learn CSS.
It can be a confusing language to learn, but if you read enough about it and practice, eventually you'll learn the best way to do things.
The key is to do it enough that it comes natural. CSS can be very elegant if you know what you want to do before you start and you have enough experience to do it.
Granted, it is also a major PITA to do sometimes, but even cross-browser issues aren't so bad if you really practice at it and learn what works and what doesn't, and how to get around problems.
All it takes is practice and in time you can become good at it.
"
25460,"Executive summary:  Yes, if your database has a message queue service.
You can push a message onto a queue and the queue processor will consume it asynchronously.

Oracle: queues
Sql Server: service broker
DB2: event broker

For ""pure"" stored procedure languages (PL/Sql or T-Sql) the answer is no, since it works against the fundamental transaction model most databases have.
However, if your database has a queuing mechanism, you can use that to get the same result.
"
25530,"I've had great success with Java Service Wrapper myself.  I haven't looked at the others, but the major strengths of ServiceWrapper are:

Great x-platform support - I've used it on Windows and Linux, and found it easy on both
Solid Documentation - The docs are clear and to the point, with great examples
Deep per-platform support - There are some unique features in the window service management system that are supported perfectly by service wrapper (w/o restarting).  And on Windows, you will even see your app name in the process list instead of just ""java.exe"".
Standards Compliant - Unlike many ad-hoc Java init scripts, the scripts for service wrapper tend to be compliant with LSB standards.  This can end up being very important if you ever want high availability management from something like Linux Heartbeat/HA.

Anyway, just my 2 cents... :)
"
25550,"We use Xpdf in one of our applications. Its a c++ library which is primarily used for pdf rendering, although it does have a text extractor which could be useful for this project.
"
25730,"I personally use Visual Leak Detector, though it can cause large delays when large blocks are leaked (it displays the contents of the entire leaked block).
"
25950,"There are some benchmarks of 1.8 vs 1.9 at http://www.rubychan.de/share/yarv_speedups.html. Overall, it looks like 1.9 is a lot faster in most cases.
"
26020,"I'm with, Bruce.  I AM using http://system.data.sqlite.org/ with great success as well.  Here's a simple class example that I created:
using System;
using System.Text;
using System.Data;
using System.Data.SQLite;

namespace MySqlLite
{
      class DataClass
      {
        private SQLiteConnection sqlite;

        public DataClass()
        {
              //This part killed me in the beginning.  I was specifying ""DataSource""
              //instead of ""Data Source""
              sqlite = new SQLiteConnection(""Data Source=/path/to/file.db"");

        }

        public DataTable selectQuery(string query)
        {
              SQLiteDataAdapter ad;
              DataTable dt = new DataTable();

              try
              {
                    SQLiteCommand cmd;
                    sqlite.Open();  //Initiate connection to the db
                    cmd = sqlite.CreateCommand();
                    cmd.CommandText = query;  //set the passed query
                    ad = new SQLiteDataAdapter(cmd);
                    ad.Fill(dt); //fill the datasource
              }
              catch(SQLiteException ex)
              {
                    //Add your exception code here.
              }
              sqlite.Close();
              return dt;
  }
}

"
26230,"Using computer management (an MMC snap-in. See Control Panel Administrative tools) you can see a list of all folders that are shared. You could delete the shares or change the permissions on the share to only allow access for certain people or groups.
"
26260,"It's just your app domain loading up and loading any binaries into memory. Also, it's initializing static variables, so if you have a static variable that loads up a lot of data from the db, it might take a bit.
"
26450,"Have you tried calling .SaveOrUpdateCopy()? 
It should work in all instances, if there is an entity by the same id in the session or if there is no entity at all. This is basically the catch-all method, as it converts a transient object into a persistent one (Save), updates the object if it is existing (Update) or even handles if the entity is a copy of an already existing object (Copy).
Failing that, you may have to identify and .Evict() the existing object before Attaching (.Update()) your ""new"" object.
This should be easy enough to do:
IPersistable entity = Whatever(); // This is the object we're trying to update
// (IPersistable has an id field)
session.Evict(session.Get(entity.GetType(), entity.Id));
session.SaveOrUpdate(entity);

Although the above code could probably do with some null checking for the .Get() call.
"
26570,"You need Marshal.SizeOf
Edit: This is for unsafe code, but then, so is sizeof().
"
26620,"If you want to use $.getJSON() you can add the following before the call :
$.ajaxSetup({
    scriptCharset: ""utf-8"",
    contentType: ""application/json; charset=utf-8""
});

You can use the charset you want instead of utf-8.
The options are explained here.
contentType : When sending data to the server, use this content-type. Default is application/x-www-form-urlencoded, which is fine for most cases.
scriptCharset : Only for requests with jsonp or script dataType and GET type. Forces the request to be interpreted as a certain charset. Only needed for charset differences between the remote and local content.
You may need one or both ...
"
26670,"A PDF is what I'm after, so I'm not sure how outputting another format would help.
As it turns out, the footer space just wasn't enough to fit all of this text; verified by the fact that changing the font size to 4pt would fit it all in without a problem.
I spent some time attempting to rewrite the footer code using DDX as outlined here and the CFPDF tag to implement it; but even after several hours of hacking away and finally getting a valid DDX as reported by the new isDDX function, the CFPDF tag reported that it was invalid DDX for some reason.
At this point I decided I had wasted enough of the client's time/money and just reformatted the footer to be 2 lines of centered text, which was good enough.
"
26760,"This seems to work, though it is a bit hackish:
TimeSpan span;


if (TimeSpan.TryParse(""05h:30m"".Replace(""m"","""").Replace(""h"",""""), out span))
            MessageBox.Show(span.ToString());

"
26800,"// at the beginning of an XPath expression starts from the document root.  Try "".//stuffChild"".  . is shorthand for self::node(), which will set the context for the search, and // is shorthand for the descendant axis.
So you have:
XmlNode stuffChild = stuff.SelectSingleNode("".//stuffChild"");

which translates to:
xmlNode stuffChild = stuff.SelectSingleNode(""self::node()/descendant::stuffChild"");
xmlNode stuffChild = stuff.SelectSingleNode(""self::node()/descendant-or-self::stuffChild"");

In the case where the child node could have the same name as the parent, you would want to use the slightly more verbose syntax that follows, to ensure that you don't re-select the parent:
xmlNode stuffChild = stuff.SelectSingleNode(""self::node()/descendant::stuffChild"");

Also note that if ""stuffChild"" is a direct descendant of ""stuff"", you can completely omit the prefixes, and just select ""stuffChild"".
XmlNode stuffChild = stuff.SelectSingleNode(""stuffChild"");

The W3Schools tutorial has helpful info in an easy to digest format.
"
26860,"
Are screen readers really so primitive that they would read text that isn't even displayed on the screen?

What you have to remember is that any HTML parser doesn't read the screen - it reads the source markup. Whta you see on the screen is the browser's attempt to apply CSS to the source code. It's irrelevant.

You could probably even identify parts of the page that are menus or table of contents, and give some sort of easy way for those parts to be read exclusively or skipped over.

You could, if there were a standard for such a thing.
I'm not very hot on the limitations of screen readers, however I've read a lot about them not being ideal. The best thing I can reccommend is to put your source in order - how you'd read it. 
There are a set of CSS properties you should also look at for screen readers.
"
27020,"I use this formula to get the input for a conditional formatting:
=IF(B2=B1,E1,MOD(E1+1,2))    [content of cell E2]

Where column B contains the item that needs to be grouped and E is an auxiliary column. Every time that the upper cell (B1 on this case) is the same as the current one (B2), the upper row content from column E is returned. Otherwise, it will return that content plus 1 MOD 2 (that is, the outupt will be 0 or 1, depending on the value of the upper cell).



"
27030,"EDIT: You cannot overload operators in current, common browser-based implementations of JavaScript interpreters.
To answer the original question, one way you could do this, and mind you, this is a bit of a hack, simply serialize the two arrays to JSON and then compare the two JSON strings. That would simply tell you if the arrays are different, obviously you could do this to each of the objects within the arrays as well to see which ones were different.
Another option is to use a library which has some nice facilities for comparing objects - I use and recommend MochiKit.

EDIT: The answer kamens gave deserves consideration as well, since a single function to compare two given objects would be much smaller than any library to do what I suggest (although my suggestion would certainly work well enough).
Here is a naÃ¯ve implemenation that may do just enough for you - be aware that there are potential problems with this implementation:
function objectsAreSame(x, y) {
   var objectsAreSame = true;
   for(var propertyName in x) {
      if(x[propertyName] !== y[propertyName]) {
         objectsAreSame = false;
         break;
      }
   }
   return objectsAreSame;
}

The assumption is that both objects have the same exact list of properties.
Oh, and it is probably obvious that, for better or worse, I belong to the only-one-return-point camp. :)
"
27220,"Thanks for the link to the MSDN article. This is exactly what I was looking for.
std::wstring s2ws(const std::string& s)
{
    int len;
    int slength = (int)s.length() + 1;
    len = MultiByteToWideChar(CP_ACP, 0, s.c_str(), slength, 0, 0); 
    wchar_t* buf = new wchar_t[len];
    MultiByteToWideChar(CP_ACP, 0, s.c_str(), slength, buf, len);
    std::wstring r(buf);
    delete[] buf;
    return r;
}

std::wstring stemp = s2ws(myString);
LPCWSTR result = stemp.c_str();

"
27240,"As an easy and clean way of using an Enumeration with the enhanced for loop, convert to an ArrayList with java.util.Collections.list.
for (TableColumn col : Collections.list(columnModel.getColumns()) {

(javax.swing.table.TableColumnModel.getColumns returns Enumeration.)
Note, this may be very slightly less efficient.
"
27570,"You should use the Directory.GetFiles(path, searchPattern, SearchOption) overload of Directory.GetFiles().
Path specifies the path, searchPattern specifies your wildcards (e.g., *, *.format) and SearchOption provides the option to include subdirectories.
The Length property of the return array of this search will provide the proper file count for your particular search pattern and option:
string[] files = directory.GetFiles(@""c:\windows\system32"", ""*.dll"", SearchOption.AllDirectories);

return files.Length;

EDIT: Alternatively you can use Directory.EnumerateFiles method
return Directory.EnumerateFiles(@""c:\windows\system32"", ""*.dll"", SearchOption.AllDirectories).Count();

"
27610,"I wrote a short article on using the Trace Listener - maybe it will be of some help, especially for beginners - http://www.daveoncsharp.com/2009/09/create-a-logger-using-the-trace-listener-in-csharp/
"
27640,"In my company, we are currently using Qt and are very happy with it.
I personnally never had to move a MFC-app into using the Qt framework, but here is something which might be of some interest for you :
Qt/MFC Migration Framework
Qt/MFC Migration Framework
It's part of Qt-Solutions, so this means you'll have to buy a Qt license along with a Qt-Solutions license. (edit: not any more)
I hope this helps !
"
27670,"Here is an article describing what might be your problem.
"
27700,"
Is there a way to open file in a non-exclusive way,

Yes, using Win32, passing the various FILE_SHARE_Xxxx flags to CreateFile.

is it cross platform?

No, it requires platform-specific code.
Due to annoying backwards compatibility concerns (DOS applications, being single-tasking, assume that nothing can delete a file out from under them, i.e. that they can fclose() and then fopen() without anything going amiss; Win16 preserved this assumption to make porting DOS applications easier, Win32 preserved this assumption to make porting Win16 applications easier, and it's awful), Windows defaults to opening files exclusively.
The underlying OS infrastructure supports deleting/renaming open files  (although I believe it does have the restriction that memory-mapped files cannot be deleted, which I think isn't a restriction found on *nix), but the default opening semantics do not.
C++ has no notion of any of this; the C++ operating environment is much the same as the DOS operating environment--no other applications running concurrently, so no need to control file sharing.
"
27850,"A variation is where you use a direct hierarchical representation (ie. parent link in node), but also store a path value.
ie. for a directory tree consisting of the following:
C:\
   Temp
   Windows
       System32

You would have the following nodes
Key     Name     Parent     Path
1       C:                  *1*
2       Temp       1        *1*2*
3       Windows    1        *1*3*
4       System32   3        *1*3*4*

Path is indexed, and will allow you to quickly do a query that picks up a node and all its children, without having to manipulate ranges.
ie. to find C:\Temp and all its children:
WHERE Path LIKE '*1*2*%'

This representation is the only place I can think of where storing id's in a string like this is ok.
"
27910,"Ok, I'm currently extracting thousands of DOIs from free form text (XML) and I realized that my previous approach had a few problems, namely regarding encoded entities and trailing punctuation, so I went on reading the specification and this is the best I could come with.


The DOI prefix shall be composed of a directory indicator followed by
  a registrant code. These two components shall be separated by a full
  stop (period).
The directory indicator shall be ""10"". The directory indicator
  distinguishes the entire set of character strings (prefix and suffix)
  as digital object identifiers within the resolution system.

Easy enough, the initial \b prevents us from ""matching"" a ""DOI"" that doesn't start with 10.:
$pattern = '\b(10[.]';



The second element of the DOI prefix shall be the registrant code. The
  registrant code is a unique string assigned to a registrant.

Also, all assigned registrant code are numeric, and at least 4 digits long, so:
$pattern = '\b(10[.][0-9]{4,}';



The registrant code may be further divided into sub-elements for
  administrative convenience if desired. Each sub-element of the
  registrant code shall be preceded by a full stop.

$pattern = '\b(10[.][0-9]{4,}(?:[.][0-9]+)*';



The DOI syntax shall be made up of a DOI prefix and a DOI suffix
  separated by a forward slash.

However, this isn't absolutely necessary, section 2.2.3 states that uncommon suffix systems may use other conventions (such as 10.1000.123456 instead of 10.1000/123456), but lets cut some slack.
$pattern = '\b(10[.][0-9]{4,}(?:[.][0-9]+)*/';



The DOI name is case-insensitive and can incorporate any printable
  characters from the legal graphic characters of Unicode. The DOI
  suffix shall consist of a character string of any length chosen by the
  registrant. Each suffix shall be unique to the prefix element that
  precedes it. The unique suffix can be a sequential number, or it might
  incorporate an identifier generated from or based on another system.

Now this is where it gets trickier, from all the DOIs I have processed, I saw the following characters (besides [0-9a-zA-Z] of course) in their suffixes: .-()/:- -- so, while it doesn't exist, the DOI 10.1016.12.31/nature.S0735-1097(98)2000/12/31/34:7-7 is completely plausible.
The logical choice would be to use \S or the [[:graph:]] PCRE POSIX class, so lets do that:
$pattern = '\b(10[.][0-9]{4,}(?:[.][0-9]+)*/\S+'; // or
$pattern = '\b(10[.][0-9]{4,}(?:[.][0-9]+)*/[[:graph:]]+';


Now we have a difficult problem, the [[:graph:]] class is a super-set of the [[:punct:]] class, which includes characters easily found in free text or any markup language: ""'&<> among others.
Lets just filter the markup ones for now using a negative lookahead:
$pattern = '\b(10[.][0-9]{4,}(?:[.][0-9]+)*/(?:(?![""&\'<>])\S)+'; // or
$pattern = '\b(10[.][0-9]{4,}(?:[.][0-9]+)*/(?:(?![""&\'<>])[[:graph:]])+';


The above should cover encoded entities (&), attribute quotes ([""']) and open / close tags ([<>]).
Unlike markup languages, free text usually doesn't employ punctuation characters unless they are bounded by at least one space or placed at the end of a sentence, for instance:

This is a long DOI:
  10.1016.12.31/nature.S0735-1097(98)2000/12/31/34:7-7!!!

The solution here is to close our capture group and assert another word boundary:
$pattern = '\b(10[.][0-9]{4,}(?:[.][0-9]+)*/(?:(?![""&\'<>])\S)+)\b'; // or
$pattern = '\b(10[.][0-9]{4,}(?:[.][0-9]+)*/(?:(?![""&\'<>])[[:graph:]])+)\b';

And voilÃ¡, here is a demo.
"
28080,"This recent thread gives an example of where it comes in handy. There is a base Shape class and classes Circle and Rectangle derived from it. In testing for equality, it is obvious that a Circle cannot be equal to a Rectangle and it would be a disaster to try to compare them. While iterating through a collection of pointers to Shapes, dynamic_cast does double duty, telling you if the shapes are comparable and giving you the proper objects to do the comparison on.
http://stackoverflow.com/questions/301959/vector-iterator-not-dereferencable
"
28110,"Place the CASE and ISDATE inside the CONVERT() function.

SELECT COUNT(*) FROM MyTable
WHERE
    DATEDIFF(dd, CONVERT(DATETIME, CASE IsDate(lastUpdate) when 1 then lastUpdate ELSE  '12-30-1899' end), getDate()) < 31

Replace '12-30-1899' with the default date of your choice.
"
28150,"If this is for XML serialization and NHibernate, where you want the parameterless constructor to be accessible (as is the case in the example you referenced), then use a private or protected parameterless constructor for serialization, or a protected constructor for NHibernate.  With the protected version, you are opening yourself up to inherited classes being able to call that code.
If you don't want code calling a method, don't make it accessible.
EDIT: To perhaps answer the deeper question, AFAIK the compiler only knows about three attributes: Obsolete, Conditional, and AttributeUsage. To add special handling for other attributes would require modifying the compiler.
"
28160,"Overwhelmed by thousands lines of code?
Having one set of header/source files per class in a directory can seem overkill. And if the number of classes goes toward 100 or 1000, it can even be frightening.
But having played with sources following the philosophy ""let's put together everything"", the conclusion is that only the one who wrote the file has any hope to not be lost inside. Even with an IDE, it is easy to miss things because when you're playing with a source of 20,000 lines, you just close your mind for anything not exactly refering to your problem.
Real life example: the class hierarchy defined in those thousand lines sources closed itself into a diamond-inheritance, and some methods were overridden in child classes by methods with exactly the same code. This was easily overlooked (who wants to explore/check a 20,000 lines source code?), and when the original method was changed (bug correction), the effect was not as universal as excepted.
Dependancies becoming circular?
I had this problem with templated code, but I saw similar problems with regular C++ and C code.
Breaking down your sources into 1 header per struct/class lets you:

Speed up compilation because you can use symbol forward-declaration instead of including whole objects
Have circular dependencies between classes (Â§) (i.e. class A has a pointer to B, and B has a pointer to A)

In source-controlled code, class dependencies could lead to regular moving of classes up and down the file, just to make the header compile. You don't want to study the evolution of such moves when comparing the same file in different versions.
Having separate headers makes the code more modular, faster to compile, and makes it easier to study its evolution through different versions diffs
For my template program, I had to divide my headers into two files: The .HPP file containing the template class declaration/definition, and the .INL file containing the definitions of the said class methods.
Putting all this code inside one and only one unique header would mean putting class definitions at the begining of this file, and the method definitions at the end.
And then, if someone needed only a small part of the code, with the one-header-only solution, they still would have to pay for the slower compilation.
(Â§) Note that you can have circular dependencies between classes if you know which class owns which. This is a discussion about classes having knowledge of the existence of other classes, not shared_ptr circular dependencies antipattern.
One last word: Headers should be self-sufficients
One thing, though, that must be respected by a solution of multiple headers and multiple sources.
When you include one header, no matter which header, your source must compile cleanly.
Each header should be self-sufficient. You're supposed to develop code, not treasure-hunting by greping your 10,000+ source files project to find which header defines the symbol in the 1,000 lines header you need to include just because of one enum.
This means that either each header defines or forward-declare all the symbols it uses, or include all the needed headers (and only the needed headers).
"
28280,"If you have 2 users hitting it at the same time they will get the same id. Why didn't you use an id table with an identity instead, insert into that and use that as the unique (which is guaranteed) id, this will also perform much faster


sp_getNextID 


never ever prefix procs with sp_, this has performance implication because the optimizer first checks the master DB to see if that proc exists there and then th local DB, also if MS decide to create a sp_getNextID in a service pack yours will never get executed
"
28380,"I Managed to do it in the Adndroid 2.2 Emulator.
Go to ""Settings"" -> ""Wireless & Networks"" -> ""Mobile Networks"" -> ""Access Point Names"" -> ""Telkila""

Over there set the proxy host name in the property ""Proxy""
and the Proxy port in the property ""Port""
"
28530,"I recommend the Apache License (specifically, version 2).  It is not a âcopy leftâ license and it addresses several matters that are important to established companies and their lawyers.
âCopy leftâ is the philosophy of the free software foundation requiring anything incorporating the licensed opens source code to also be licensed as open source.  That philosophy is regarded as poison by established companies that want to keep their products proprietary.
Aside from not having âcopy leftâ provisions, the Apache license specifically addresses the grant of rights from project contributors and it expressly addresses the fact that modern companies are typically made up for more than one legal entity (for example, a parent company and its subsidiaries).  Most open source licenses donât address these points.
Whatever license you choose, if you want your code to be âcorporate friendly,â in the sense that you want it to be incorporated into commercial, non-open source products, it is essential that you avoid GPL and other âcopy leftâ type licenses.  While it would be best to consult with your own lawyer before investing time or money in a project for which this is an important factor, a quick shorthand for licenses that are and are not âcopy leftâ can be found on the Free Software Foundationâs website.  They identify which licenses they donât find meet their standards as âcopy left.â  The ones FSF rejects are most likely the ones that will be corporate friendly in this sense.
(Although the question didnât ask this, it is worth mentioning that, with very few exceptions, even GPL and other âcopy leftâ type licenses are perfectly corporate friendly if they are only used internally by the commercial entities and not incorporated into their products.)
"
28560,"Yes, sort of.  
There is no support included in the trunk, you need to write your own dialect.  Or you can port the Paradox dialect created for Hibernate.
"
28590,"Database connections are a limited resource.  Some DBs have a very low connection limit, and wasting connections is a major problem.  By consuming many connections, you may be blocking others for using the database.
Additionally, throwing a ton of extra connections at the DB doesn't help anything unless there are resources on the DB server sitting idle.  If you've got 8 cores and only one is being used to satisfy a query, then sure, making another connection might help.  More likely, though, you are already using all the available cores.  You're also likely hitting the same harddrive for every DB request, and adding additional lock contention.
If your DB has anything resembling high utilization, adding extra connections won't help.  That'd be like spawning extra threads in an application with the blind hope that the extra concurrency will make processing faster.  It might in some certain circumstances, but in other cases it'll just slow you down as you thrash the hard drive, waste time task-switching, and introduce synchronization overhead.
"
28820,"I work on windows mobile full time and have never really come across a good Windows Mobile scripting implementation unfortunately.  For some reason MS has never seen the need for it.  For example, even though you can actually get a command console on WM, it does not support running batch files, even though all the commands are still there and it would be relatively easy.  There is definitely not a VBScript engine I've ever heard of nor JScript.  There is PythonCE but the WM specific support is minimal and you don't get access to a lot of WM only things.
Also, I've done a lot of work with a company called SOTI which has a product called MobiControl that does incorporate a basic scripting engine. Though most of the commands are specific to their system and actually have to be run from a desktop-side management console.
Given all of the times I have tried to find a good scripting engine for WM myself you would think I would've just written one ;)
So, sorry, but the basic answer is no, there is not a scripting engine available for VB in the context that you specified.
"
28840,"Have you tried working with your customer to define / formulate acceptance tests?
Using something like Fit to come up with these tests - would result in better specs as well as force the customer to think about what is really required. The icing on the cake is instant-doc-executable specs at the end of this process.
That is of course, if your customers are available and open to this approach. Give it a try!
If not (and that seems to be the majority - because it is less work) - calendar flash 'em - schedule meetings/telecons every week until they sing like canaries :) +1 to Dana 
"
28950,"Google first hit seems pretty comprehensive.
I think the problem here is there are too many advocates of one or the other, may be better of googling and getting more of a handle of the pro's/con's yourself and making your own decision.
I know that sounds kinda lame, but ultimately these sort of design decisions fall down to the developer/architect working on it, and 99% of the time, the problem domain will be the deciding factor (or at least it should be), not a guide on the net.
"
29030,"I would be surprised if you could do something in a _Layouts file that you can't do in a forms template. You have pretty much the same technologies at your disposal. 
Looking at the way SharePoint works with ListItems and Layouts pages (for example ""Manage Permissions"" on a list item), I can see that they pass some variables in via querystrings:
?obj={76113B3A-FABA-4389-BC85-4BB2CC5AB423},6,LISTITEM&List={76113B3A-FABA-4389-BC85-4BB2CC5AB423}
Perhaps they grab the context back each time programmatically using these values.
"
29040,"What you are asking for is a level of optimisation the linq-to-sql does not provide. I think your best bet is to create a query that returns exactly the data you want, possibly as an anonymous type:
from order in DB.GetTable<Orders>()
join product in DB.GetTable<Products>()
on order.ProductID = product.ID
select new { ID = order.ID, Name = order.Name, ProductName = product.Name };

"
29100,"This might be a reference to RSpec, which is a really clever way of developing tests as a series of requirements. I'm still getting used to it, but it's been very handy in both defining what I need to do and then ensuring I do it.
"
29370,"Are you required to have it run as x86? I had similar issues with web apps under Visual Studio's dev web server (which is x86), but switching over to IIS (x64) worked for me. Since I was deploying to IIS x64, I called it a day at that point.
I tried tracing with Filemon and Regmon, but didn't get any denied or missing keys errors. If I were to look again, I'd check HKLM\Software\WOW6432Node, guessing that the installer writes to the x64 HKLM\Software node, but not the x86 one.
"
29460,"The FlashWindowEx function which controls the flashing takes a FLASHWINFO struct which has a uCount field to control how many times it flashes.  Also, a possible value for the dwFlags field is FLASHW_STOP to cause the flashing to stop.
EDIT: Forgot was a C# tagged question ... so P/Invoke goodness found here.
"
29580,"Because in most cases you've got to sort your results first. For example, when you search on Google, you can view only up to 100 pages of results. They don't bother sorting by page-rank beyond 1000 websites for given keyword (or combination of keywords).
Pagination is fast. Sorting is slow.
"
29630,"Simply move your code into an Excel Addin (XLA) - this gets loaded at startup (assuming it's in the %AppData%\Microsoft\Excel\XLSTART folder) but if it's a addin, not a workbook, then only your macros and defined startup functions will be loaded.
If the functions depend on a spreadsheet itself, then you might want to use a combination of templates and addins.
I'm distributing part of an application like this, we have addins for Word, Excel and Powerpoint (XLA, PPA, DOT) and also Office 2007 'ribbon' versions (DOTM, XLAM and PPAM)
The addin startup code creates toolbar buttons if they're not found, this means in any workbook/document/etc they can simply hit the toolbar button to run our code (we have two action buttons and one button that displays a settings dialog)
Templates aren't really the way to go for VBA code, Addins are definitely the way to go...
So to load the toolbars on startup we're using something like.. (checking to see if toolbar exists though - code will run for each worksheet that is opened, but toolbars are persistent for the user session)
Public Sub Workbook_Open()
     ' startup code / add toolbar / load saved settings, etc.
End Sub

hope that helps :)
"
29680,"Mark's comment is correct; The NTLM auth prompt is triggered by a 401 response code and the presence of NTLM as the first mechanism offered in the WWW-Authenticate header (Ref: The NTLM Authentication Protocol).
I'm not sure if I understand the question description correctly, but I think you are trying to wrap the NTLM authentication for SharePoint, which means you don't have control over the server-side authentication protocol, correct? If you're not able to manipulate the server side to avoid sending a 401 response on failed credentials, then you will not be able to avoid this problem, because it's part of the (client-side) spec:
The XMLHttpRequest Object

If the UA supports HTTP Authentication [RFC2617] it SHOULD consider requests
  originating from this object to be part of the protection space that includes the
  accessed URIs and send Authorization  headers and handle 401 Unauthorised requests
  appropriately. if authentication fails, UAs should prompt the users for credentials.

So the spec actually calls for the browser to prompt the user accordingly if any 401 response is received in an XMLHttpRequest, just as if the user had accessed the URL directly. As far as I can tell the only way to really avoid this would be for you to have control over the server side and cause 401 Unauthorized responses to be avoided, as Mark mentioned. 
One last thought is that you may be able to get around this using a proxy, such a separate server side script on another webserver. That script then takes a user and pass parameter and checks the authentication, so that the user's browser isn't what's making the original HTTP request and therefore isn't receiving the 401 response that's causing the prompt. If you do it this way you can find out from your ""proxy"" script if it failed, and if so then prompt the user again until it succeeds. On a successful authentication event, you can simply fetch the HTTP request as you are now, since everything works if the credentials are correctly specified.
"
29700,"Scott Hanselmann has blogged extensively about his experience in learning WPF by creating his 'BabySmash' windows application. All the source code is on codeplex and he has many blog articles describing his progress.
Initial BabySmash article
Codeplex source
BabySmash website
"
29760,"You can use the LogonUser property of Windows Installer as a condition to the action launching the EXE.
"
29810,"I've worked with Word documents in SVN. With TortoiseSVN, you can easily diff Word documents (between working copy and repository, or between two repository revisions). It's really slick and definitely recommended.
The other thing to do if you're using Word documents in SVN is to add the svn:needs-lock property to the Word documents. This will prevent two people from trying to edit the same document at the same time, since unfortunately there's no good way to merge Word documents.
With the above two things, handling revision controlled Word documents is at least tolerable. It certainly beats the alternative of using a shared folder and track-changes.
"
29820,"Turn that into a spec:
-that objects need to implement an interface in order to be allowed into the collection
Something like ArrayList<ICloneable>()
Then you can be assured that you always do a deep copy - the interface should have a method that is guaranteed to return a deep copy.  
I think that's the best you can do.  
"
29870,"This is my general approach to testing/launching.
How you test/launch depends mostly on:

What your application is.
Who your users are.

If you application is a technical application and is geared to the technically-minded, the word ""beta"" won't really scare them - but provide an opportunity to test the product before it goes 'live', and help to improve the system.  This is the ideal circumstance in which to use either an open or closed beta.  It's usually beneficial to start off 'closed' with a group of people you select and trust to bug-find quickly and reliably - after you're more confident that all the critical bugs are gone, open it up with an invite system (for example).
If, however, your application is 'trivial' from a technical standpoint (i.e. it's something like Twitter, or Facebook, or Flickr - nothing that is inherently geared towards technical usage), then you're going to have to be more careful in how you plan your testing.  Closed testing is most definitely your first port of call, and this should last for longer than a closed beta on a more 'technical' product.  The reason?  Your 'average Joe' doesn't necessarily know what the word ""beta"" means, and others may well be scared by it, or judge your service prematurely (not understanding the concept of this 'public testing' phase).  Many won't want to be used as guinea pigs.
"
29890,"You could enumerate all the network adapters, get their IP addresses and compare the part covered by the subnet mask with the sender's address.
Like:
IPAddress FindLocalIPAddressOfIncomingPacket( senderAddr )
{
    foreach( adapter in EnumAllNetworkAdapters() )
    {
        adapterSubnet = adapter.subnetmask & adapter.ipaddress;
        senderSubnet = adapter.subnetmask & senderAddr;
        if( adapterSubnet == senderSubnet )
        {
            return adapter.ipaddress;
        }
    }
}

"
29980,"To make this less tedious, you will need to encapsulate/refactor the mapping between the DataReader and the Object you hold in the list.  There is quite of few steps to encapsulate that logic out.  If that is the road you want to take, I can post code for you.  I am just not sure how practical it would be to post the code here on StackOverflow, but I can give it a shot to keep it concise and to the point.  Otherwise, you are stuck with the tedious task of repeating each expectation on the index accessor for the reader.  The encapsulation process will also get rid of the strings and make those strings more reusable through your tests.
Also, I am not sure at this point how much you want to make the existing code more testable.  Since this is legacy code that wasn't built with testing in mind.
"
30080,"From my ""Geometry"" class:
public struct Line
{
    public static Line Empty;

    private PointF p1;
    private PointF p2;

    public Line(PointF p1, PointF p2)
    {
        this.p1 = p1;
        this.p2 = p2;
    }

    public PointF P1
    {
        get { return p1; }
        set { p1 = value; }
    }

    public PointF P2
    {
        get { return p2; }
        set { p2 = value; }
    }

    public float X1
    {
        get { return p1.X; }
        set { p1.X = value; }
    }

    public float X2
    {
        get { return p2.X; }
        set { p2.X = value; }
    }

    public float Y1
    {
        get { return p1.Y; }
        set { p1.Y = value; }
    }

    public float Y2
    {
        get { return p2.Y; }
        set { p2.Y = value; }
    }
}

public struct Polygon: IEnumerable<PointF>
{
    private PointF[] points;

    public Polygon(PointF[] points)
    {
        this.points = points;
    }

    public PointF[] Points
    {
        get { return points; }
        set { points = value; }
    }

    public int Length
    {
        get { return points.Length; }
    }

    public PointF this[int index]
    {
        get { return points[index]; }
        set { points[index] = value; }
    }

    public static implicit operator PointF[](Polygon polygon)
    {
        return polygon.points;
    }

    public static implicit operator Polygon(PointF[] points)
    {
        return new Polygon(points);
    }

    IEnumerator<PointF> IEnumerable<PointF>.GetEnumerator()
    {
        return (IEnumerator<PointF>)points.GetEnumerator();
    }

    public IEnumerator GetEnumerator()
    {
        return points.GetEnumerator();
    }
}

public enum Intersection
{
    None,
    Tangent,
    Intersection,
    Containment
}

public static class Geometry
{

    public static Intersection IntersectionOf(Line line, Polygon polygon)
    {
        if (polygon.Length == 0)
        {
            return Intersection.None;
        }
        if (polygon.Length == 1)
        {
            return IntersectionOf(polygon[0], line);
        }
        bool tangent = false;
        for (int index = 0; index < polygon.Length; index++)
        {
            int index2 = (index + 1)%polygon.Length;
            Intersection intersection = IntersectionOf(line, new Line(polygon[index], polygon[index2]));
            if (intersection == Intersection.Intersection)
            {
                return intersection;
            }
            if (intersection == Intersection.Tangent)
            {
                tangent = true;
            }
        }
        return tangent ? Intersection.Tangent : IntersectionOf(line.P1, polygon);
    }

    public static Intersection IntersectionOf(PointF point, Polygon polygon)
    {
        switch (polygon.Length)
        {
            case 0:
                return Intersection.None;
            case 1:
                if (polygon[0].X == point.X && polygon[0].Y == point.Y)
                {
                    return Intersection.Tangent;
                }
                else
                {
                    return Intersection.None;
                }
            case 2:
                return IntersectionOf(point, new Line(polygon[0], polygon[1]));
        }

        int counter = 0;
        int i;
        PointF p1;
        int n = polygon.Length;
        p1 = polygon[0];
        if (point == p1)
        {
            return Intersection.Tangent;
        }

        for (i = 1; i <= n; i++)
        {
            PointF p2 = polygon[i % n];
            if (point == p2)
            {
                return Intersection.Tangent;
            }
            if (point.Y > Math.Min(p1.Y, p2.Y))
            {
                if (point.Y <= Math.Max(p1.Y, p2.Y))
                {
                    if (point.X <= Math.Max(p1.X, p2.X))
                    {
                        if (p1.Y != p2.Y)
                        {
                            double xinters = (point.Y - p1.Y) * (p2.X - p1.X) / (p2.Y - p1.Y) + p1.X;
                            if (p1.X == p2.X || point.X <= xinters)
                                counter++;
                        }
                    }
                }
            }
            p1 = p2;
        }

        return (counter % 2 == 1) ? Intersection.Containment : Intersection.None;
    }

    public static Intersection IntersectionOf(PointF point, Line line)
    {
        float bottomY = Math.Min(line.Y1, line.Y2);
        float topY = Math.Max(line.Y1, line.Y2);
        bool heightIsRight = point.Y >= bottomY &&
                             point.Y <= topY;
        //Vertical line, slope is divideByZero error!
        if (line.X1 == line.X2)
        {
            if (point.X == line.X1 && heightIsRight)
            {
                return Intersection.Tangent;
            }
            else
            {
                return Intersection.None;
            }
        }
        float slope = (line.X2 - line.X1)/(line.Y2 - line.Y1);
        bool onLine = (line.Y1 - point.Y) == (slope*(line.X1 - point.X));
        if (onLine && heightIsRight)
        {
            return Intersection.Tangent;
        }
        else
        {
            return Intersection.None;
        }
    }

}

"
30160,"DrJava is your best bet. It also has an Eclipse plugin to use the interactions pane like GroovyConsole.
"
30170,"Elements can belong to more than one class, so you can do something like this:  
.DefaultBackColor
{
    background-color: #123456;
}
.SomeOtherStyle
{
    //other stuff here
}
.DefaultForeColor
{
    color:#654321;
}

And then in the content portion somewhere:  
<div class=""DefaultBackColor SomeOtherStyle DefaultForeColor"">Your content</div>

The weaknesses here are that it gets pretty wordy in the body and you're unlikely to be able to get it down to listing a color only once.  But you might be able to do it only two or three times and you can group those colors together, perhaps in their own sheet.  Now when you want to change the color scheme they're all together and the change is pretty simple.
But, yeah, my biggest complain with CSS is the inability to define your own constants.
"
30230,"It turns out this is a bug with Firefox + ASP.NET where the generated javascript for the defaultButton stuff doesn't work in Firefox. I had to put a replacement for the WebForm_FireDefatultButton function as described here:
function WebForm_FireDefaultButton(event, target) {
    var element = event.target || event.srcElement;
    if (event.keyCode == 13 &&
    !(element &&
    element.tagName.toLowerCase() == ""textarea""))
    {
        var defaultButton;
        if (__nonMSDOMBrowser)
        {
            defaultButton = document.getElementById(target);
        }
        else
        {
            defaultButton = document.all[target];
        }
        if (defaultButton && typeof defaultButton.click != ""undefined"")
        {
            defaultButton.click();
            event.cancelBubble = true;
            if (event.stopPropagation)
            {
                event.stopPropagation();
            }
            return false;
        }
    }
    return true;
}

"
30310,"You can use the ActionName attribute like so:
[ActionName(""My-Action"")]
public ActionResult MyAction() {
    return View();
}

Note that you will then need to call your View file ""My-Action.cshtml"" (or appropriate extension). You will also need to reference ""my-action"" in any Html.ActionLink methods.
There isn't such a simple solution for controllers.
Edit: Update for MVC5
Now with MVC5, Attribute Routing has been absorbed into the project. You can now use:
[Route(""My-Action"")]

On Action Methods. 
For controllers, you can apply a RoutePrefix attribute which will be applied to all action methods in that controller:
[RoutePrefix(""my-controller"")]

One of the benefits of using RoutePrefix is URL parameters will also be passed down to any action methods.
[RoutePrefix(""clients/{clientId:int}"")]
public class ClientsController : Controller .....

Snip..
[Route(""edit-client"")]
public ActionResult Edit(int clientId) // will match /clients/123/edit-client

"
30430,"Yes it's possible.  In the project properties you can target different versions of the .Net Framework going back to .NET 2.0.
Upgrading to VS 2008 will upgrade your Solution file and you won't be able to go back to VS 2005 unless you have backed up your solution
"
30540,"Are you using javascript to communicate between frames/iframes which point to different domains? This is not permitted by the JS ""same origin/domain"" security policy. Ie, if you have
<iframe name=""foo"" src=""foo.com/script.js"">
<iframe name=""bar"" src=""bar.com/script.js"">

And the script on bar.com tries to access window[""foo""].Location.toString, you will get this (or similar) exceptions. Please also note that the same origin policy can also kick in if you have content from different subdomains. Here you can find a short and to the point explanation of it with examples.
"
30660,"stop slave; set global sql_slave_skip_counter=1; start slave;
You can ignore only the current error and continue the replication process.
"
30710,"I would suggest mocking out your calls to the database.  Mocks are basically objects that look like the object you are trying to call a method on, in the sense that they have the same properties, methods, etc. available to caller.  But instead of performing whatever action they are programmed to do when a particular method is called, it skips that altogether, and just returns a result. That result is typically defined by you ahead of time.  
In order to set up your objects for mocking, you probably need to use some sort of inversion of control/ dependency injection pattern, as in the following pseudo-code:
class Bar
{
    private FooDataProvider _dataProvider;

    public instantiate(FooDataProvider dataProvider) {
        _dataProvider = dataProvider;
    }

    public getAllFoos() {
        // instead of calling Foo.GetAll() here, we are introducing an extra layer of abstraction
        return _dataProvider.GetAllFoos();
    }
}

class FooDataProvider
{
    public Foo[] GetAllFoos() {
        return Foo.GetAll();
    }
}

Now in your unit test, you create a mock of FooDataProvider, which allows you to call the method GetAllFoos without having to actually hit the database.
class BarTests
{
    public TestGetAllFoos() {
        // here we set up our mock FooDataProvider
        mockRepository = MockingFramework.new()
        mockFooDataProvider = mockRepository.CreateMockOfType(FooDataProvider);

        // create a new array of Foo objects
        testFooArray = new Foo[] {Foo.new(), Foo.new(), Foo.new()}

        // the next statement will cause testFooArray to be returned every time we call FooDAtaProvider.GetAllFoos,
        // instead of calling to the database and returning whatever is in there
        // ExpectCallTo and Returns are methods provided by our imaginary mocking framework
        ExpectCallTo(mockFooDataProvider.GetAllFoos).Returns(testFooArray)

        // now begins our actual unit test
        testBar = new Bar(mockFooDataProvider)
        baz = testBar.GetAllFoos()

        // baz should now equal the testFooArray object we created earlier
        Assert.AreEqual(3, baz.length)
    }
}

A common mocking scenario, in a nutshell.  Of course you will still probably want to unit test your actual database calls too, for which you will need to hit the database.
"
30770,"I would suggest you start by removing the UpdatePanels at first, and make sure your control orgy is working correctly with postbacks.  Once you have that working, try adding the UpdatePanels back in from the bottom up.
"
30790,"No, LINQ to SQL is very much MS SQL only - think of it as a client driver.
Microsoft is/was helping Oracle and DataDirect develop providers for Oracle and other non-MS database servers.
"
30800,"If you're on an intranet, Windows authentication can be handled for ""free"" by configuration alone. 
If this isn't appropriate, token services work just fine, but for some situations they may be just too much.
The application I'm working on needed bare-bones authentication. Our server and client run inside a (very secure) intranet, so we didn't care too much for the requirement to use an X.509 certificate to encrypt the communication, which is required if you're using username authentication.
So we added a custom behavior to the client that adds the username and (encrypted) password to the message headers, and another custom behavior on the server that verifies them.
All very simple, required no changes to the client side service access layer or the service contract implementation. And as it's all done by configuration, if and when we need to move to something a little stronger it'll be easy to migrate.
"
30940,"Try log4php. I'm using log4net for my .NET project and it's just terrific. :)
"
31090,"I used the draggable search in Spy++ (installed with VS) to look at the split open button on the file-open dialog of VS.
This revealed that it's an ordinary windows button with a style which includes BS_DEFSPLITBUTTON.   That's a magic keyword which gets you to some interesting places, including
http://www.codeplex.com/windowsformsaero/SourceControl/FileView.aspx?itemId=212902&changeSetId=9930
and here
http://msdn.microsoft.com/en-us/library/bb775949.aspx#using_splits
Hope this helps you.  
EDIT:
I've actually just tried that code from CodePlex and it does create a split button - but you do have to make sure you've set the button's FlatStyle to 'System' rather than 'Standard' which is the default.   I've not bothered to hook-up the event handling stuff for the drop-down, but that's covered in the MSDN link, I think.
Of course, this is Vista-only (but doesn't need Aero enabled, despite the name on codeplex) - if you need earlier OS support, you'll be back to drawing it yourself.
"
31140,"If you set the Modifiers property of your components to strict protected makes them accessible without the use of a components collection. 
Edit:
Discoverability could be done using reflection to walk over each field. Although that might be suboptimal in your case.
"
31200,"Question 2: Yes. Use your Exchange server as you normally would then add your IMAP email account to Outlook. I have a client that has done this for his office staff and it's been working fine for years.
"
31250,"Microsoft, who co-authored the spec for MHT, seem to think that it should be 'message/rfc822' on this support page.
No specific MIME type seems to be given in the spec though:
RFC2557: MIME Encapsulation of Aggregate Documents, such as HTML (MHTML) 
"
31320,"I picked up this technique a while back and have found it quite handy.
When it's in place, you can add ?profile=true to any URL that hits a controller. Your action will run as usual, but instead of delivering the rendered page to the browser, it'll send a detailed, nicely formatted ruby-prof page that shows where your action spent its time.
First, add ruby-prof to your Gemfile, probably in the development group:
group :development do
    gem ""ruby-prof""
end

Then add an around filter to your ApplicationController:
around_filter :profile if Rails.env == 'development'

def profile
  if params[:profile] && result = RubyProf.profile { yield }

    out = StringIO.new
    RubyProf::GraphHtmlPrinter.new(result).print out, :min_percent => 0
    self.response_body = out.string

  else
    yield
  end
end

Reading the ruby-prof output is a bit of an art, but I'll leave that as an exercise.
Additional note by ScottJShea:
If you want to change the measurement type place this:
RubyProf.measure_mode = RubyProf::GC_TIME #example
Before the if in the profile method of the application controller. You can find a list of the available measurements at the ruby-prof page. As of this writing the memory and allocations data streams seem to be corrupted (see defect).
"
31340,"Yes, because of the Global Interpreter Lock (GIL) there can only run one thread at a time. Here are some links with some insights about this:

http://www.artima.com/weblogs/viewpost.jsp?thread=214235
http://smoothspan.wordpress.com/2007/09/14/guido-is-right-to-leave-the-gil-in-python-not-for-multicore-but-for-utility-computing/

From the last link an interesting quote:

Let me explain what all that means. 
  Threads run inside the same virtual
  machine, and hence run on the same
  physical machine.  Processes can run
  on the same physical machine or in
  another physical machine.  If you
  architect your application around
  threads, youâve done nothing to access
  multiple machines.  So, you can scale
  to as many cores are on the single
  machine (which will be quite a few
  over time), but to really reach web
  scales, youâll need to solve the
  multiple machine problem anyway.

If you want to use multi core, pyprocessing defines an process based API to do real parallelization. The PEP also includes some interesting benchmarks.
"
31380,"In this case, I would do as you are doing (use a byte array for buffering and not one of the stream buffers).
There are exceptions, though. One place you see buffers (output this time) is in the servlet API. Data isn't written to the underlying stream until flush() is called, allowing you to buffer output but then dump the buffer if an error occurs and write an error page instead. You might buffer input if you needed to reset the stream for rereading using mark(int) and reset(). For example, maybe you'd inspect the file header before deciding on which content handler to pass the stream to.
Unrelated, but I think you should rewrite your stream handling. This pattern works best to avoid resource leaks:
    InputStream stream = new FileInputStream(""in"");
    try { //no operations between open stream and try block
        //work
    } finally { //do nothing but close this one stream in the finally
        stream.close();
    }

If you are opening multiple streams, nest try/finally blocks.
Another thing your code is doing is making the assumption that the returned content is encoded in your VM's default character set (though that might be adequate, depending on the use case).
"
31410,"I saw this functionality in older versions of VS.Net (2003 I think).  It may still exist in current versions, but I haven't encountered it.  Seems that files with the same name, even in different directories confuse VS.Net, and it ends up setting a break point in a file with the same name.  May only happen if the classes in the file both have the same name also.  So much for namespaces I guess.  
You also may want to check your build configuration to make sure that all the projects are in fact building in debug mode.  I know I've been caught a couple times when the configuration got changed somehow for the solution, and some projects weren't compiling in debug mode.
"
31480,"MS do have a history of ""fire and movement"" with regards to introducing new technology into their development stack, but they also have a strong history of maintaining support for the older stuff, and backwards-compatibility. WPF seems to be getting stuff added to it with each new release of the framework but the things you learn aren't being superceded or invalidated.
The only breaking change I've seen in my own WPF applications with a new release of the framework was one recently in 3.5 SP1, and that was because we were unknowingly relying on a bug to get a certain behaviour from our code. We adjusted the XAML to be more correct and it started working fine.
So yeah, I think WPF is pretty ""stable"" as a client-side development technology.
"
31500,"Yeah, that's right.  If your employee table has 10,000 records, and only 5 records have employeetypeID in (1,2,3), then it will most likely use the index to fetch the records.  However, if it finds that 9,000 records have the employeeIDType in (1,2,3), then it would most likely just do a table scan to get the corresponding EmployeeIDs, as it's faster just to run through the whole table than to go to each branch of the index tree and look at the records individually.  
SQL Server does a lot of stuff to try and optimize how the queries run.  However, sometimes it doesn't get the right answer.  If you know that SQL Server isn't using the index, by looking at the execution plan in query analyzer, you can tell the query engine to use a specific index with the following change to your query.
Select EmployeeId From Employee WITH (Index(Index_EmployeeTypeId )) Where EmployeeTypeId IN (1,2,3)

Assuming the index you have on the EmployeeTypeId field is named Index_EmployeeTypeId. 
"
31790,"WCF services can have multiple endpoints, each of which can implement a different service contract.
For example, you could have a service declared as follows:
[ServiceBehavior(Namespace = ""DemoService"")]
public class DemoService : IDemoService, IDoNothingService

Which would have configuration along these lines:
<service name=""DemoService"" behaviorConfiguration=""Debugging"">
  <host>
    <baseAddresses>
      <add baseAddress = ""http://localhost/DemoService.svc"" />
    </baseAddresses>
  </host>
  <endpoint 
    address =""""
    binding=""customBinding""
    bindingConfiguration=""InsecureCustom""
    bindingNamespace=""http://schemas.com/Demo"" contract=""IDemoService""/>
  <endpoint 
    address =""""
    binding=""customBinding""
    bindingConfiguration=""InsecureCustom""
    bindingNamespace=""http://schemas.com/Demo"" contract=""IDoNothingService""/>
</service>

Hope that helps, but if you were after the theoretical maximum interfaces you can have for a service I suspect it's some crazily large multiple of 2.
"
31800,"I'd personally plump for returning the resource rather than faffing with a redirect, although I suspect that's only because my subcoscious is telling me redirects are slower.
However, if you were to decide to use a redirect I'd think a 302 or 307 might be more appropiate than a 303, although the w3.org has details of the different redirect codes you could use.
"
31840,"I'd say you're probably fine with util.logging for the needs you describe.
For a good decision tree, have a look at Log4j vs java.util.logging

Question One :
  Do you anticipate a need for any of the clever handlers that Log4j has that JUL does not have, such as the SMTPHandler, NTEventLogHandler, or any of the very convenient FileHandlers?
Question Two :
  Do you see yourself wanting to frequently switch the format of your logging output? Will you need an easy, flexible way to do so? In other words, do you need Log4j's PatternLayout?
Question Three :
  Do you anticipate a definite need for the ability to change complex logging configurations in your applications, after they are compiled and deployed in a production environment? Does your configuration sound something like, ""Severe messages from this class get sent via e-mail to the support guy; severe messages from a subset of classes get logged to a syslog deamon on our server; warning messages from another subset of classes get logged to a file on network drive A; and then all messages from everywhere get logged to a file on network drive B""? And do you see yourself tweaking it every couple of days?
If you can answer yes to any of the above questions, go with Log4j. If you answer a definite no to all of them, JUL will be more than adequate and it's conveniently already included in the SDK.

That said, pretty much every project these days seems to wind up including log4j, if only because some other library uses it.
"
31870,"You can use CDATA section
<xsl:text disable-output-escaping=""yes""><![CDATA[&nbsp;]]></xsl:text>

or you can describe &nbsp in local DTD:
<!DOCTYPE xsl:stylesheet [ <!ENTITY nbsp ""&#160;""> ]>

or just use &#160; instead of &nbsp;
"
32000,"using (var conn = new SqlConnection(yourConnectionString))
{
    var cmd = new SqlCommand(""insert into Foo values (@bar)"", conn);
    cmd.Parameters.AddWithValue(""@bar"", 17);
    conn.Open();
    cmd.ExecuteNonQuery();
}

"
32010,"Yes, [A-Za-z] will be much faster than setting the RegexOptions.IgnoreCase, largely because of Unicode strings. But it's also much more limiting -- [A-Za-z] does not match accented international characters, it's literally the A-Za-z ASCII set and nothing more.
I don't know if you saw Tim Bray's answer to my message, but it's a good one:

One of the trickiest issues in internationalized search is upper and lower case. This notion of case is limited to languages written in the Latin, Greek, and Cyrillic character sets. English-speakers naturally expect search to be case-insensitive if only because theyâre lazy: if Nadia Jones wants to look herself up on Google sheâll probably just type in nadia jones and expect the system to take care of it.
So itâs fairly common for search systems to ânormalizeâ words by converting them all to lower- or upper-case, both for indexing and queries.
The trouble is that the mapping between cases is not always as straightforward as it is in English. For example, the German lower-case character âÃâ becomes âSSâ when upper-cased, and good old capital âIâ when down-cased in Turkish becomes the dotless âÄ±â (yes, they have âiâ, its upper-case version is âÄ°â). I have read (but not verified first-hand) that the rules for upcasing accented characters such âÃ©â are different in France and QuÃ©bec. One of the results of all this is that software such as java.String.toLowerCase() tends to run astonishingly slow as it tries to work around all these corner-cases.

http://www.tbray.org/ongoing/When/200x/2003/10/11/SearchI18n
"
32020,"I use soapUI, and it's generally pretty good.  Be aware that it seems to leak memory, and eventually it will no longer save your project, so save regularly!
This is about the only hassle I have with it (other than the general ugliness that almost every Java application has!), and I can't live without it.
"
32100,"SELECT MAX( col )
  FROM table
 WHERE col < ( SELECT MAX( col )
                 FROM table )

"
32260,"Be sure to use System.Net.Mail, not the deprecated System.Web.Mail. Doing SSL with System.Web.Mail is a gross mess of hacky extensions.
using System.Net;
using System.Net.Mail;

var fromAddress = new MailAddress(""from@gmail.com"", ""From Name"");
var toAddress = new MailAddress(""to@example.com"", ""To Name"");
const string fromPassword = ""fromPassword"";
const string subject = ""Subject"";
const string body = ""Body"";

var smtp = new SmtpClient
{
    Host = ""smtp.gmail.com"",
    Port = 587,
    EnableSsl = true,
    DeliveryMethod = SmtpDeliveryMethod.Network,
    UseDefaultCredentials = false,
    Credentials = new NetworkCredential(fromAddress.Address, fromPassword)
};
using (var message = new MailMessage(fromAddress, toAddress)
{
    Subject = subject,
    Body = body
})
{
    smtp.Send(message);
}

"
32280,"General rule is if your method doesn't expect null arguments then you should throw System.ArgumentNullException. Throwing proper exception not only protects you from resource corruption and other bad things but serves as a guide for users of your code saving time spent debugging your code.
Also read an article on Defensive programming
"
32360,"A foreign key column with the UNIQUE and NOT NULL constraints that references a UNIQUE, NOT NULL column in another table creates a 1:(0|1) relationship, which is probably what you want.
If there was a true 1:1 relationship, every record in the first table would have a corresponding record in the second table and vice-versa. In that case, you would probably just want to make one table (unless you needed some strange storage optimization).
"
32460,"Not Exactly a sexy piece of code but their doesn't seem to be an automated way to find the row without just looping the table.
        DataRowView newRowView = null;
        foreach (DataRowView tempRowView in myDataTable.DefaultView)
        {
            if (tempRowView.Row == rowToMatch)
                newRowView = tempRowView;
        }
        if (newRow != null)
            UseNewRowView(newRowView);
        else
            HandleRowNotFound();

"
32540,"..but Javascript has many facets that are OO.
Consider this:
var Vehicle = jQuery.Class.create({ 
   init: function(name) { this.name = name; } 
});

var Car = Vehicle.extend({ 
   fillGas: function(){ 
      this.gas = 100; 
   } 
});

I've used this technique to create page-level javascript classes that have their own state, this helps keep it contained (and I often identify areas that I can reuse and put into other classes).
This is also especially useful when you have components/server controls that have their own script to execute, but when you might have multiple instances on the same page.  This keeps the state separate.
"
32550,"According to Kalen Delaney...
The NOLOCK hint has nothing to do with the index options. The hint tells SQL
Server not to request locks when doing SELECT operations, so there will be
no conflict with data that is already locked. The index options just tell
SQL Server that this level of locking is allowed, when locking is going to
occur. For example, if ALLOW_ROW_LOCKS was off, the only possible locks
would be page or table locks. The index options don't force locks to be
held, they just control the possible size of the locks.
In answer to the question in your subject, the NOLOCK hint and the
READUNCOMMITTED hint are equivalent.
"
32570,"Isapi Rewrite Filter on CodePlex - actively developed, free (""DonationWare""), open source.
"
32640,"Using MoQ it looks something like this:
var request = new Mock<HttpRequestBase>();
request.Expect(r => r.HttpMethod).Returns(""GET"");
var mockHttpContext = new Mock<HttpContextBase>();
mockHttpContext.Expect(c => c.Request).Returns(request.Object);
var controllerContext = new ControllerContext(mockHttpContext.Object
, new RouteData(), new Mock<ControllerBase>().Object);

I think the Rhino Mocks syntax is similar.
"
32750,"Edit: The assumption below is not correct, I had a chance to fire up my IDE later and tested with and without Write and both populated the MemoryStream correctly.
I think you need to write to your MemeoryStream first.
As if my memory (no pun intended) serves me correctly this:
MemoryStream ms = new MemoryStream(byteArrayIn);

Creates a memory stream of that size.
You then need to write your byte array contents to the memory stream:
ms.Write(byteArrayIn, 0, byteArrayIn.Length);

See if that fixes it.
"
32780,"I assume that this server is behind a router? You should be able to block WAN connections to the server on the router and still leave it open to accepting LAN connection. Or you could restrict the IPs that can connect to the server to the development machines on the network.
"
32790,"The use of System.exit is frowned upon when the 'application' is really a sub-application (e.g. servlet, applet) of a larger Java application (server): in this case the System.exit could stop the JVM and hence also all other sub-applications. In this situation, throwing an appropriate exception, which could be caught and handled by the application framework/server is the best option.
If the java application is really meant to be run as a standalone application, there is nothing wrong with using System.exit. in this case, setting an exit value is probably the easiest (and also most used) way of communicating failure or success to the parent process.
"
32930,"I've used the code from the codeproject article and it works pretty well. It's a nice wrapper around the IMAPI2, so as longs as IMAPI2 supports what you need to do, the .NET wrapper will do it.
"
33080,"Try this simple, specific function:
function resizeElementHeight(element) {
  var height = 0;
  var body = window.document.body;
  if (window.innerHeight) {
      height = window.innerHeight;
  } else if (body.parentElement.clientHeight) {
      height = body.parentElement.clientHeight;
  } else if (body && body.clientHeight) {
      height = body.clientHeight;
  }
  element.style.height = ((height - element.offsetTop) + ""px"");
}

It does not depend on the current distance from the top of the body being specified (in case your 300px changes).

EDIT: By the way, you would want to call this on that div every time the user changed the browser's size, so you would need to wire up the event handler for that, of course.
"
33150,"If you want to be able to pass a method in the ASPX markup, you need to use the Browsable attribute in your code on the event.
VB.NET
<Browsable(True)> Public Event InitializeStuffCallback

C#
[Browsable(true)]
public event EventHandler InitializeStuffCallback;

Reference:
Design-Time Attributes for Components and BrowsableAttribute Class
All the events, properties, or whatever need to be in the code-behind of the control with the browsable attribute to make it so you can change it in the tag code.
"
33250,"In order to take control over the properties that you want to be cached you can call 'RefreshCache()' passing the properties that you want to hang around:
System.DirectoryServices.DirectoryEntry entry = new System.DirectoryServices.DirectoryEntry();               

// Push the property values from AD back to cache.

entry.RefreshCache(new string[] {""cn"", ""www"" });

"
33390,"You pretty much need to keep the same data context available throughout the lifetime of the operations you want to perform if you're ever going to be storing changes which are to be .SubmitChanges()'d later, as otherwise you will lose those changes.
If you're just querying stuff then it's fine to create them as needed, but then if later you want to .SubmitChanges() you'll have to refactor your code a lot, so you may as well adopt the pattern of effectively keeping the datacontext global throughout your app from the beginning.
Note the data context is disconnected. The connection is only made when the query data is enumerated (not when you first run the query, it's a 'lazy' data type so only provides data when it's needed), and then closed immediately afterwards. On .SubmitChanges() the connection is opened to submit the changes then closed immediately afterwards. So don't think keeping the datacontext around keeps a connection open, it doesn't (you can hook the StateChange event of the connection to confirm this for yourself, that's how I'm sure).
There is a great article over at Rick Strahl's Blog which covers this topic in depth, far more than my answer here provides!!
"
33510,"Are you planning a desktop or web application? 
Everyone around here seems to think that Mono is great, but I still do not think it is ready for industry use, I would equate mono to where wine is, great idea; when it works it works well, and when it doesn't...well your out of luck. mod_mono for Apache is extremely glitchy and is hard to get running correctly.
If your aiming for the desktop, nothing beats the eclipse RCP (Rich Client Platform) framework: http://wiki.eclipse.org/index.php/Rich_Client_Platform. 
You can build window, linux, mac all under the same code and all UI components are native to the OS. And RCP wins in modularity hands down, it has a plug-in architecture that is unrivaled (from what I have seen)
I have worked with RCP for 1.5 years now and I dunno what else could replace it, it is #1 in it's niche.
If your totally opposed to java I would look into wxWidgets with either python or C++ 
"
33550,"SAGE is definitely one you should consider since it actually includes the full version of Maxima within it (along with interfaces to various other mathematical packages).  To answer your questions:
1) SAGE can symbolically differentiate and integrate.
2) Programming in SAGE is done via Python.
3) The syntax is rather different to Mathematica's (which is essentially LISP-like) but here is a blog post written by a heavy user of Mathematica so you can see what he thinks: Walking Randomly: Interacting with SAGE
"
33590,"Okay... so no-one's tried Astra, or people just avoid Flash questions.
After a lot of guess work it turns out I needed to cast the series to a PieSeries and then work with those member functions, as the ISeries was useless on it's own.
myPieChart.dataTipFunction = 
  function (item:Object, index:int, series:ISeries):String {
    var oPieSeries:PieSeries = series as PieSeries;
    return oPieSeries.itemToCategory(item,index) + ""\n$"" + 
           oPieSeries.itemToData(item) + ""\n"" + 
           Number(oPieSeries.itemToPercentage(item)).toFixed(2) + ""%"";
  };

"
33630,"What version of windows? it differs from XP to vista and from home to business versions of vista, and I would guess again for server.
see here for more info on maximum ram for diffrent windows versions
for Windows Server 2008 Datacenter MS quote 2 TB of physical memory.
"
33720,"You wouldn't change the existing templates.  In other words, don't modify anything under the /Developer hierarchy (or wherever you installed your developer tools).
Instead, clone the templates you want to have customized variants of.  Then change their names and the information in them.  Finally, put them in the appropriate location in your account's Library/Application Support folder, specifically:

File templates: ~/Library/Application Support/Developer/Shared/Xcode/File Templates/
Target templates: ~/Library/Application Support/Developer/Shared/Xcode/Target Templates/
Project templates: ~/Library/Application Support/Developer/Shared/Xcode/Project Templates/

That way they won't be overwritten when you install new developer tools, and you can tweak them to your heart's content.
"
33790,"Just combine the two commands:
scp -r web/* web/.htaccess user@site.com:site.com/

If you want 0 entries of your password you can set up public key authentication for ssh/scp.
"
33860,"I realize this question is kind of old, but what the heck are you doing eval for?
document.getElementById('formId').onsubmit();
document.getElementById('formId').submit();

or
document.formName.onsubmit();
document.formName.submit();

When the DOM of a document is loaded, the events are not strings any more, they are functions.
alert(typeof document.formName.onsubmit); // function

So there's no reason to convert a function to a string just so you can eval it.
"
33960," java.net.NetworkInterface.getHardwareAddress (method added in Java 6)
It has to be called on the machine you are interested in - the MAC is not transferred across network boundaries (i.e. LAN and WAN). If you want to make use of it on a website server to interrogate the clients, you'd have to run an applet that would report the result back to you.
For Java 5 and older I found code parsing output of command line tools on various systems.
"
33990,"Try adding the repository first using the ""SVN Repository Exploring"" perspective (Window > Open Perspective > Other... > SVN Repository Exploring).
Make sure that the URL you are using points to the correct directory, which typically contains these default repository files:
conf/  dav/  db/  format  hooks/  locks/  README.txt

Hope this helps.
"
34020,"Python threads are good for concurrent I/O programming. Threads are swapped out of the CPU as soon as they block waiting for input from file, network, etc. This allows other Python threads to use the CPU while others wait. This would allow you to write a multi-threaded web server or web crawler, for example.
However, Python threads are serialized by the GIL when they enter interpreter core. This means that if two threads are crunching numbers, only one can run at any given moment. It also means that you can't take advantage of multi-core or multi-processor architectures.
There are solutions like running multiple Python interpreters concurrently, using a C based threading library. This is not for the faint of heart and the benefits might not be worth the trouble. Let's hope for an all Python solution in a future release.
"
34120,"I would recomend PHP Simple HTML DOM Parser after you have scraped the HTML from the page. It supports invalid HTML, and provides a very easy way to handle HTML elements. 
"
34270,"Having used Reflector to have a quick peak at the Directory Services code, it looks like your Active Directory Service Interfaces installation might be kaput.
You can download version 2.5 from Technet although I'm not sure if it's the latest version or if it works with Windows 2000.
"
34300,"Not yet, because the OS is still unmanaged.
If MS finally do what their labs have been talking about for years and produce a fully managed OS then it will.
That OS won't be backwards compatible though. They would have to produce managed versions of Office, IE, etc first. They will have to produce a virtual machine to run unmanaged apps.
The pain would be something similar to the move from Mac OS9 to OSX.
"
34390,"Here's what I did:
<link rel=""Stylesheet"" type=""text/css"" href=""Stylesheet.css"" id=""style"" runat=""server"" visible=""false"" />

It fools Visual Studio into thinking you've added a stylesheet to the page but it doesn't get rendered.

Here's an even more concise way to do this with multiple references;
<% if (false) { %>
    <link rel=""Stylesheet"" type=""text/css"" href=""Stylesheet.css"" />
    <script type=""text/javascript"" src=""js/jquery-1.2.6.js"" />
<% } %>

As seen in this blog post from Phil Haack.
"
34490,"require 'digest/sha1'
Digest::SHA1.hexdigest 'foo'

"
34510,"A race condition occurs when two or more threads can access shared data and they try to change it at the same time. Because the thread scheduling algorithm can swap between threads at any time, you don't know the order in which the threads will attempt to access the shared data. Therefore, the result of the change in data is dependent on the thread scheduling algorithm, i.e. both threads are ""racing"" to access/change the data. 
Problems often occur when one thread does a ""check-then-act"" (e.g. ""check"" if the value is X, then ""act"" to do something that depends on the value being X) and another thread does something to the value in between the ""check"" and the ""act"". E.g:
if (x == 5) // The ""Check""
{
   y = x * 2; // The ""Act""

   // If another thread changed x in between ""if (x == 5)"" and ""y = x * 2"" above,
   // y will not be equal to 10.
}

The point being, y could be 10, or it could be anything, depending on whether another thread changed x in between the check and act. You have no real way of knowing.
In order to prevent race conditions from occurring, you would typically put a lock around the shared data to ensure only one thread can access the data at a time. This would mean something like this:
// Obtain lock for x
if (x == 5)
{
   y = x * 2; // Now, nothing can change x until the lock is released. 
              // Therefore y = 10
}
// release lock for x

"
34570,"I loved Dive Into Python, especially if you're a quick study.  The beginning basics are all covered (and may move slowly for you), but the latter few chapters are great learning tools.
Plus, Pilgrim is a pretty good writer.
"
34600,"I've done quite a lot of pair-programming not only cross-site but cross-timezone.  I live in Israel and I work with people on the West Coast all the time.  The best way I've found is to use shared VNC session and skype.  You need some ""good behavior"" to ensure that only one of us types at a given time.  The VNC server that we use gives us two different pointers so we can move our respective mice without getting in the way, so long as we don't actually click.
The main problem is that the clipboard is shared, so if someone selects something it's automatically copied to the other's clipboard.
As a general rule, pair programming cross site, while not ideal, is certainly workable, and most definitely useful.
"
34790,"I use a CSS class instead:
<input type=""text"" id=""BeginDate"" class=""calendar"" />
<input type=""text"" id=""EndDate"" class=""calendar"" />

Then, in your document.ready function:
$('.calendar').datepicker();

Using it that way for multiple calendar fields works for me.
"
34920,"If you end up using flock, here's some code to do it:
use Fcntl ':flock'; # Import LOCK_* constants

# We will use this file path in error messages and function calls.
# Don't type it out more than once in your code.  Use a variable.
my $file = '/path/to/some/file';

# Open the file for appending.  Note the file path is quoted
# in the error message.  This helps debug situations where you
# have a stray space at the start or end of the path.
open(my $fh, '>>', $file) or die ""Could not open '$file' - $!"";

# Get exclusive lock (will block until it does)
flock($fh, LOCK_EX) or die ""Could not lock '$file' - $!"";

# Do something with the file here...

# Do NOT use flock() to unlock the file if you wrote to the
# file in the ""do something"" section above.  This could create
# a race condition.  The close() call below will unlock the
# file for you, but only after writing any buffered data.

# In a world of buffered i/o, some or all of your data may not 
# be written until close() completes.  Always, always, ALWAYS 
# check the return value of close() if you wrote to the file!
close($fh) or die ""Could not write '$file' - $!"";

Some useful links:

PerlMonks file locking tutorial (somewhat old)
flock() documentation

In response to your added question, I'd say either place the lock on the file or create a file that you call 'lock' whenever the file is locked and delete it when it is no longer locked (and then make sure your programs obey those semantics).
"
35050,"To answer B:
Comparison of JavaScript frameworks

EDIT: Although everyone and their mom is apparently riding the jQuery bandwagon (I use MochiKit), there are many libraries which provide the same functionality - the problem set which most libraries solve (async client-server communication, DOM manipulation, etc.) is the same, and there are few that don't have what you will need to get the job done. 
The important thing to determine for yourself is whether or not a library will fit your particular style and sensibilities. Wide-spread ignorance about how JavaScript, the language, actually works, coupled with the negative press resulting thereby, coupled with the now-immense popularity of jQuery leads most people down that road. Thankfully, it isn't a bad road to be on as there are a lot of travellers to keep you company when the abstractions leak and you need help. You probably can't go wrong choosing jQuery.
"
35070,"It is possible to remove registry keys using a .reg file, although I'm not sure how well it's documented.  Here's how:
REGEDIT4

[-HKEY_CURRENT_USER\Software\<otherpath>]

The - in front of the key name tells Regedit that you want to remove the key.
To run this silently, type:
regedit /s ""myfile.reg""

"
35120,"Well, you can actually do local image processing in Silverlight 2... But there are no built in classes to help you. But you can load any image into a byte array, and start manipulating it, or implement your own image encoder.
Joe Stegman got lots of great information about ""editable images"" in Silverlight over at http://blogs.msdn.com/jstegman/.  He does things like applying filters to images, generating mandlebrots and more.
This blog discuss a JPEG Silverilght Encoder (FJCore) you can use to resize and recompress photos client size: http://fluxcapacity.net/2008/07/14/fjcore-to-the-rescue/
Another tool is ""Fluxify"" which lets you resize and upload photos using Silverilght 2. Can be found over at http://fluxtools.net/
So yes, client side image processing can definetly be done in Silverilght 2. Happy hacking!
"
35170,"""automatic"" does in fact mean ""re-entrant"".  The term itself is stolen from software languages -- for example, C has the ""auto"" keyword for declaring variables as being allocated on the stack when the scope it's in is executed, and deallocated afterwards, so that multiple invocations of the same scope do not see persistent values of that variable.  The reason you may not have heard of this keyword in C is that it is the default storage class for all types :-)  The alternatives are ""static"", which means ""allocate this variable statically (to a single global location in memory), and refer to this same memory location throughout the execution of the program, regardless of how many times the function is invoked"", and ""volatile"", which means ""this is a register elsewhere on my SoC or something on another device which I have no control over; compiler, please don't optimize reads to me away, even when you think you know my value from previous reads with no intermediate writes in the code"".
""automatic"" is intended for recursive functions, but also for running the same function in different threads of execution concurrently.  For instance, if you ""fork"" off N different blocks (using Verilog's fork->join statement), and have them all call the same function at the same time, the same problems arise as a function calling itself recursively.
In many cases, your code will be just fine without declaring the task or function as ""automatic"", but it's good practice to put it in there unless you specifically need it to be otherwise.
"
35240,"You can't get page headers by JS, but you can distinguish error from success:
Try something like this:
<script type=""text/javascript"">

    var uploadStarted = false;
    function OnUploadStart(){            
        uploadStarted = true;
    }

    function OnUploadComplete(state,message){       

       if(state == 1)
        alert(""Success: ""+message); 	
       else
         if(state == 0 && uploadStarted)
            alert(""Error:""+( message ? message : ""unknow"" ));
    }   

</script>


<iframe id=""uploader"" name=""uploader"" onload=""OnUploadComplete(0)"" style=""width:0px;height:0px;border:none;""></iframe>

<form id=""sender"" action=""/upload.php"" method=""post"" target=""uploader"" enctype=""multipart/form-data"" onsubmit=""OnUploadStart()"">
<input type=""file"" name=""files[upload]""/>
<input type=""submit"" value=""Upload""/>
</form>

On server side:
/*
  file: upload.php
*/
<?php 

   // do some stuff with file       

  print '<script type=""text/javascript"">';
  if(success)
     print 'window.parent.OnUploadComplete(1,""File uploaded!"");';
  else
     print 'window.parent.OnUploadComplete(0, ""File too large!"");';
  print  '</script>';
?>

"
35320,"If you just want want the highest recursion depth couldn't you do something like this?Then, when you actually query the CTE just look for the row with max(Depth)?  Like so:
DECLARE @LookupID int

--Our test value
SET @LookupID = 1;

WITH cteLevelOne (ParentID, CustID, Depth) AS
(
        SELECT   a.ParentID, a.CustID, 1
        FROM     tblCustomer AS a
        WHERE    a.CustID = @LookupID
    UNION ALL
        SELECT   a.ParentID, a.CustID, c.Depth + 1
        FROM     tblCustomer AS a
        INNER JOIN cteLevelOne AS c ON a.CustID = c.ParentID 
        WHERE c.CustID <> a.CustID
)
select * from CTELevelone where Depth = (select max(Depth) from CTELevelone)

or, adapting what trevor suggests, this could be used with the same CTE:  
select top 1 * from CTELevelone order by Depth desc

I don't think CustomerID was necessarily what you wanted to order by in the case you described, but I wasn't perfectly clear on the question either.
"
35380,"It would probably be more beneficial for you provide what you have so far and explain what doesn't work as expected but here is what I came up with:
#include <stdio.h>
#include <sys/types.h>
#include <unistd.h>
#include <signal.h>
#include <stdlib.h>

#define READY_SIGNAL SIGUSR1

/* The ready flag is set when READY_SIGNAL is received.
 * It is needed so that when we wake up from sigsuspend
 * we know whether or not the signal received was READY_SIGNAL. */
volatile sig_atomic_t ready;
void make_ready(int i) { ready = 1; }

int
main (int argc, char *argv[])
{
  pid_t cpid, ppid;  /* pids of the child and parent */
  /* Signal masks for sigprocmask and sigsuspend */
  sigset_t block_mask, wait_mask;
  unsigned long c = 1;   /* The counter */
  unsigned long n = 100; /* The default max count value */
  struct sigaction act;

  /* Override the default max count if provided */
  if (argv[1])
    n = strtoul(argv[1], NULL, 10);

  /* Prepare signal masks */
  sigemptyset(&wait_mask);
  sigemptyset(&block_mask);
  sigaddset(&block_mask, READY_SIGNAL);

  /* Set the signal mask for the parent to ignore READY_SIGNAL until
   * we are ready to receive it, the mask will be inherited by the child,
   * needed to avoid race conditions */
  sigprocmask(SIG_BLOCK, &block_mask, NULL);

  /* Register the signal handler, will be inherited by the child */
  act.sa_flags = 0;
  act.sa_handler = make_ready;
  sigemptyset(&act.sa_mask);
  sigaction(READY_SIGNAL, &act, NULL);

  /* Get the parent's process id, needed for the child to send signals
   * to the parent process, could alternatively use getppid in the child */
  ppid = getpid();

  /* Call fork, storing the child's process id needed for the parent to
   * send signals to the child */
  cpid = fork();

  if (cpid < 0) {
    perror(""Fork failed"");
    exit(EXIT_FAILURE);
  }

  if (cpid == 0) {
    /* Child */
    c = 2;  /* Child's first number will always be 2 */
    if (c > n) exit(0); /* If c > n we have nothing to do */

    do {
      /* Suspend until we receive READY_SIGNAL */
      while (!ready) sigsuspend(&wait_mask);

      /* Print out number, flush for proper output sequencing when output
         is not a terminal. */
      printf(""Child: %lu\n"", c);
      fflush(stdout);

      ready = 0; /* Reset ready flag */
      c += 2; /* Increment counter */

      /* Wake up parent process */
      kill(ppid, READY_SIGNAL);
    } while (c <= n);  
  } else {
    /* Parent */
    for (;;) {
      /* Print out number, flush for proper output sequencing when output
         is not a terminal. */
      printf(""Parent: %lu\n"", c);
      fflush(stdout);

      c += 2; /* Increment counter */

      kill(cpid, READY_SIGNAL); /* Wake up child process */

      if (c > n) break; /* Don't go back to sleep if we are done */

      ready = 0; /* Reset ready flag */

      /* Suspend until we receive READY_SIGNAL */
      while (!ready) sigsuspend(&wait_mask);
    };

    wait4(cpid, NULL, 0); /* Don't exist before child finishes */
  }

  return 0;
}

This passes these basic tests:
./print_with_signals 100000|sort -n -k 2 -c && echo ""Success""

./print_with_signals 100001|sort -n -k 2 -c && echo ""Success""
"
35420,"To monitor the servers we use the free tools from Maatkit ... simple, yet efficient.
The binary replication is available in 5.1, so I guess you've got some balls. We still use 5.0 and it works OK, but of course we had our share of issues with it.
We use a Master-Master replication with a MySql Proxy as a load-balancer in front, and to prevent it from having errors:

we removed all unique indexes
for the few cases where we really needed unique constraints we made sure we used REPLACE instead of INSERT (MySql Proxy can be used to guard for proper usage ... it can even rewrite your queries)
scheduled scripts doing intensive reports are always accessing the same server (not the load-balancer) ... so that dangerous operations are replicated safely

Yeah, I know it sounds simple and stupid, but it solved 95% of all the problems we had.
"
35470,"pylint is the best such tool I've found. Due to Python's nature it's difficult to statically analyze it, but it will catch undefined variables, basic type errors, unused code, etc. You'll want to tweak the configuration file, as by default it outputs many warnings I consider useless or harmful.
Here's part of my .pylintrc dealing with warning silencing:
[MESSAGES CONTROL]

# Brain-dead errors regarding standard language features
#   W0142 = *args and **kwargs support
#   W0403 = Relative imports

# Pointless whinging
#   R0201 = Method could be a function
#   W0212 = Accessing protected attribute of client class
#   W0613 = Unused argument
#   W0232 = Class has no __init__ method
#   R0903 = Too few public methods
#   C0301 = Line too long
#   R0913 = Too many arguments
#   C0103 = Invalid name
#   R0914 = Too many local variables

# PyLint's module importation is unreliable
#   F0401 = Unable to import module
#   W0402 = Uses of a deprecated module

# Already an error when wildcard imports are used
#   W0614 = Unused import from wildcard

# Sometimes disabled depending on how bad a module is
#   C0111 = Missing docstring

# Disable the message(s) with the given id(s).
disable=W0142,W0403,R0201,W0212,W0613,W0232,R0903,W0614,C0111,C0301,R0913,C0103,F0401,W0402,R0914

"
35480,"The ""common problems"" page on the Class::DBI wiki has a section on this subject.  The simplest solution is to disable the live object index entirely using:
$Class::DBI::Weaken_Is_Available = 0;

"
35490,"MPI was deisgned tightly-coupled compute clusters with fast, reliable networks.  Spread and ÃMQ are designed for large distributed systems.  If you're designing a parallel scientific application, go with MPI, but if you are designing a persistent distributed system that needs to be resilient to faults and network instability, use one of the others.
MPI has very limited facilities for fault tolerance; the default error handling behavior in most implementations is a system-wide fail.  Also, the semantics of MPI require that all messages sent eventually be consumed.  This makes a lot of sense for simulations on a  cluster, but not for a distributed application.
"
35530,"Here is how you implement a low-pass filter using convolution:
double[] signal = (some 1d signal);
double[] filter = [0.25 0.25 0.25 0.25]; // box-car filter
double[] result = new double[signal.Length + filter.Length + 1];

// Set result to zero:
for (int i=0; i < result.Length; i++) result[i] = 0;

// Do convolution:
for (int i=0; i < signal.Length; i++) 
  for (int j=0; j < filter.Length; j++)
    result[i+j] = result[i+j] + signal[i] * filter[j];

Note that the example is extremely simplified. It does not do range checks and does not handle the edges properly. The filter used (box-car) is a particularly bad lowpass filter, because it will cause a lot of artifacts (ringing). Read up on filter design.
You can also implement the filters in the frequency domain. Here is how you implement a high-pass filter using FFT:
double[] signal = (some 1d signal);
// Do FFT:
double[] real;
double[] imag;
[real, imag] = fft(signal)

// Set the first quarter of the real part to zero to attenuate the low frequencies
for (int i=0; i < real.Length / 4; i++) 
  real[i] = 0;

// Do inverse FFT:
double[] highfrequencysignal = inversefft(real, imag);

Again, this is simplified, but you get the idea. The code does not look as complicated as the math.
"
35560,"Don't do lazy loading over a service interface.  Define explicit DTO's and consume those as your data contracts in WCF.
You can use NHibernate (or other ORMs) to properly fetch the objects you need to construct the DTOs.
"
35670,"Eric Sink has an excellent series on source code control aimed at beginners. For Subversion specifics, including setting up and administering a server, the Subversion book is a great resource, and includes a section with examples of a typical session with Subversion (checkout, commit, merging and updating basics).
Update: I forgot to mention that for beginners, I'd also recommend messing around in a graphical client, which removes the command-line hassle from the learning experience. RapidSVN is a reasonable cross-platform client. You'll also find that common IDEs either come with Subversion support, or have plugins which can be installed, which allow most version control operations to be performed within that environment.
@John Millikin: While setting up a Subversion server can be complicated, depending on one's general admin experience, don't forget that you don't need to do that just to mess about with a repository and get to grips with the basics - the client can interact with a repository in the local filesystem.
"
35700,"I maintained for a number of years an ANSI C networking library that was ported to close to 30 different OS's and compilers.  The library didn't have any GUI components, which made it easier.  We ended up abstracting out into dedicated source files any routine that was not consistent across platforms, and used #defines where appropriate in those source files.  This kept the code that was adjusted per platform isolated away from the main business logic of the library.  We also made extensive use of typedefs and our own dedicated types so that we could easily change them per platform if needed.  This made the port to 64-bit platforms fairly easy.
If you are looking to have GUI components, I would suggest looking at GUI toolkits such as WxWindows or Qt (which are both C++ libraries).
"
35870,"I did this once for a web site.  I.e. find the dealer within 50 miles of your zip code.  I used the great circle calculation to find the coordinates that were 50 miles north, 50 miles east, 50 miles south, and 50 miles west.  That gave me a min and max lat and a min and max long.  From there then I did a database query: 
select *
    from dealers
    where latitude  >= minlat
      and latitude  <= maxlat
      and longitude >= minlong
      and longitude <= maxlong

Since some of those results will still be more than 50 miles away, then I used the great circle formula once more on that small list of coordinates.  Then I printed out the list along with the distance from the target.
Of course, if you wanted to search for points near the international date line or the poles, than this won't work.  But it works great for searches inside North America!
"
35940,"My favorite is recursively listing all files under a folder in a four-line sequence expression:
open System.IO

let rec filesUnderFolder basePath =
    seq {
        for file in Directory.GetFiles(basePath) do
            yield file
        for subDir in Directory.GetDirectories(basePath) do
            yield! filesUnderFolder subDir
        }

"
35950,"You've asked for the canonical reason why Boost::MultiIndex was made:  list insertion order with fast lookup by key.  Boost MultiIndex tutorial: list fast lookup
"
36260,"Recursive definitions need to appear in the same file. If you want to separate definitions, statements, and expressions into separate modules, you can do so using recursive modules, but they will still need to appear in the same file. DAG-ifying inter-file dependencies is one of the annoyances of OCaml.
"
36350,"A simple typecast will ensure the compiler knows what you mean in this case.
Foo((object)new object[]{ (object)""1"", (object)""2"" }));

As an array is a subtype of object, this all works out. Bit of an odd solution though, I'll agree.
Edit: Woops, typoed my example code.
"
36430,"By Ruby commands you probably mean the command line programs for Ruby.  These are also called Ruby Helper programs.  Here are a few:

ruby - The interpreter itself.  Run Ruby scripts or statements.
gem - Ruby Package Manager.  Great for automatically downloading or updating small Ruby modules like XML libraries, web servers, or even whole Ruby programs.
irb - Interactive Ruby Prompt.  This is an entire Ruby shell that will let you execute any Ruby code you want.  You can load libraries, test code directly, anything you can do with Ruby you can do in this shell.  Believe me, there is quite a lot that you can do with it to improve your Ruby development workflow [1].
ri - Quick shell access to Ruby documentation.  You can find the RDoc information on nearly any Ruby Class or method.  The same kind of documentation that you would find on the online ruby-docs.
erb - Evaluates embedded Ruby in Ruby Templated documents.  Embedded Ruby is just like embedding php into a document, and this is an interpreter for that kind of document.  This is really more for the rails crowd.  An alternative would be haml.
rdoc - Generate the standard Ruby documentation for one of your Ruby classes.  Its like Javadocs.  It parses the Ruby source files and generates the standard documentation from special comments.
testrb and rake.  I'm not familiar enough with these.  I'd love it if someone could fill these in!

Hopefully this was what you were looking for!
"
36600,"I think you can still use all of the normal D3D tools, but you won't be able to render to a surface associated with the screen. You'll have to render to a DIB (or some such) and Blt it with GDI to a normal window HDC. RDC/VNC/Citrix should all work with this technique.
Performance will definitely suffer - but that's going to be the case over remote desktop anyway. In fact, if I were you, I would mock up a VERY simple prototype and demonstrate the performance before committing to it. 
Good luck!
"
36760,"Change your ""inner join"" to a ""left outer join"", which means ""get me all the rows on the left of the join, even if there isn't a matching row on the right.""
select page.name, count(page-attachment.id) as attachmentsnumber 
from page 
    left outer join page-attachment on page.id=page-id 
group by page.name

"
36820,"@lomaxx:

Subversion has built in support for word documents 

More specifically, TortoiseSVN does. If you use the TortoiseSVN context menu in explorer to, e.g., bring up a diff, Tortoise will call a script that uses Word's built-in comparison feature to do the actual diff'ing.
"
36890,"Recompilation of clients is not required (and should not be, regardless of the ORB that you use). As Adam indicated, lookups are done by operation name (a straight text comparison).
I've done what you're describing with our ACE/TAO-based system, and encountered no issues (servers were in ACE/TAO C++, clients were ACE/TAO C++, C# using Borland's Janeva, and OmniORBPy).
"
37030,"There's now a Windows port of Sparkle, see http://winsparkle.org.
"
37070,"Non-Temporal SSE instructions (MOVNTI, MOVNTQ, etc.), don't follow the normal cache-coherency rules. Therefore non-temporal stores must be followed by an SFENCE instruction in order for their results to be seen by other processors in a timely fashion.
When data is produced and not (immediately) consumed again, the fact that memory store operations read a full cache line first and then modify the cached data is detrimental to performance. This operation pushes data out of the caches which might be needed again in favor of data which will not be used soon. This is especially true for large data structures, like matrices, which are filled and then used later. Before the last element of the matrix is filled the sheer size evicts the first elements, making caching of the writes ineffective.
For this and similar situations, processors provide support for non-temporal write operations. Non-temporal in this context means the data will not be reused soon, so there is no reason to cache it. These non-temporal write operations do not read a cache line and then modify it; instead, the new content is directly written to memory. 
Source: http://lwn.net/Articles/255364/
"
37310,"Since I don't know how your factory method looks like, all I can advise right now is to 

Check to see the object is the correct concrete implementation you were looking for:
IMyInterface fromFactory = factory.create(...);  
Assert.assertTrue(fromFactory instanceof MyInterfaceImpl1);

You can check if the factory setup the concrete instances with valid instance variables.

"
37590,"Google has an ico to png converter, I saw it on reddit the other day.
http://www.google.com/s2/favicons?domain=stackoverflow.com
"
37640," SQL Doc 
Document SQL Server 2000, 2005 and 2008 databases

Demo Video
Apex SQL Doc

"
37650,"Does this help:
http://www.west-wind.com/weblog/posts/76293.aspx
Response.ContentType = ""application/octet-stream"";
Response.AppendHeader(""Content-Disposition"",""attachment; filename=logfile.txt"");
Response.TransmitFile( Server.MapPath(""~/logfile.txt"") );
Response.End();

Response.TransmitFile is the accepted way of sending large files, instead of Response.WriteFile.
"
37830,"You'll pretty much have to roll your own Close button, but you can hide the window chrome completely using the WindowStyle attribute, like this:
<Window WindowStyle=""None"">

That will still have a resize border. If you want to make the window non-resizable then add ResizeMode=""NoResize"" to the declaration.
"
37920,"Are you using a parent for the Dialog? e.g.
MyDialog dialog(pParent);
dialog.DoModal();

If you are, try removing the parent. Especially if the parent is the desktop window.
"
38010,"If you create new strings, they will not automatically be put into the intern pool, unless you concatenate constants compile-time, in which case the compiler will create one string result and intern that as part of the JIT process.
"
38070,"I always check CodePlex.com
http://www.codeplex.com/googlemap
http://www.codeplex.com/YahooMap
The GoogleMaps project above has a lot of good examples on the project leader's website.
"
38090,"Ran across this old question, which now has a better answer. Postgres 9.1 introduced ""Unlogged Tables"", which are tables that don't log their DML changes to WAL. See the docs for more info, but at least now there is a solution for this problem. 
See Waiting for 9.1 - UNLOGGED tables by depesz, and the 9.1 docs.
"
38160,"Depending on what you want to do xargs also can help (here: converting documents with pdf2ps):
cpus=$( ls -d /sys/devices/system/cpu/cpu[[:digit:]]* | wc -w )

find . -name \*.pdf | xargs --max-args=1 --max-procs=$cpus  pdf2ps

From the docs:
--max-procs=max-procs
-P max-procs
       Run up to max-procs processes at a time; the default is 1.
       If max-procs is 0, xargs will run as many processes as  possible  at  a
       time.  Use the -n option with -P; otherwise chances are that only one
       exec will be done.

"
38190,"Cool, thank you Mark, I had forgotten that CreateFile opens things too.  I was looking at the volume management API and not seeing how to open things.  
Here is a little class that wraps things up.  It might also be possible/correct to just pass the SafeFileHandle into a FileStream.
using System;
using System.Runtime.InteropServices;
using System.IO;
using Microsoft.Win32.SafeHandles;

namespace ReadFromDevice
{
    public class DeviceStream : Stream, IDisposable
    {
        public const short FILE_ATTRIBUTE_NORMAL = 0x80;
        public const short INVALID_HANDLE_VALUE = -1;
        public const uint GENERIC_READ = 0x80000000;
        public const uint GENERIC_WRITE = 0x40000000;
        public const uint CREATE_NEW = 1;
        public const uint CREATE_ALWAYS = 2;
        public const uint OPEN_EXISTING = 3;

        // Use interop to call the CreateFile function.
        // For more information about CreateFile,
        // see the unmanaged MSDN reference library.
        [DllImport(""kernel32.dll"", SetLastError = true, CharSet = CharSet.Unicode)]
        private static extern IntPtr CreateFile(string lpFileName, uint dwDesiredAccess,
          uint dwShareMode, IntPtr lpSecurityAttributes, uint dwCreationDisposition,
          uint dwFlagsAndAttributes, IntPtr hTemplateFile);

        [DllImport(""kernel32.dll"", SetLastError = true)]
        private static extern bool ReadFile(
            IntPtr hFile,                        // handle to file
            byte[] lpBuffer,                // data buffer
            int nNumberOfBytesToRead,        // number of bytes to read
            ref int lpNumberOfBytesRead,    // number of bytes read
            IntPtr lpOverlapped
            //
            // ref OVERLAPPED lpOverlapped        // overlapped buffer
            );

        private SafeFileHandle handleValue = null;
        private FileStream _fs = null;

        public DeviceStream(string device)
        {
            Load(device);
        }

        private void Load(string Path)
        {
            if (string.IsNullOrEmpty(Path))
            {
                throw new ArgumentNullException(""Path"");
            }

            // Try to open the file.
            IntPtr ptr = CreateFile(Path, GENERIC_READ, 0, IntPtr.Zero, OPEN_EXISTING, 0, IntPtr.Zero);

            handleValue = new SafeFileHandle(ptr, true);
            _fs = new FileStream(handleValue, FileAccess.Read);

            // If the handle is invalid,
            // get the last Win32 error 
            // and throw a Win32Exception.
            if (handleValue.IsInvalid)
            {
                Marshal.ThrowExceptionForHR(Marshal.GetHRForLastWin32Error());
            }
        }

        public override bool CanRead
        {
            get { return true; }
        }

        public override bool CanSeek
        {
            get { return false; }
        }

        public override bool CanWrite
        {
            get { return false; }
        }

        public override void Flush()
        {
            return;
        }

        public override long Length
        {
            get { return -1; }
        }

        public override long Position
        {
            get
            {
                throw new NotImplementedException();
            }
            set
            {
                throw new NotImplementedException();
            }
        }
        /// <summary>
        /// </summary>
        /// <param name=""buffer"">An array of bytes. When this method returns, the buffer contains the specified byte array with the values between offset and 
        /// (offset + count - 1) replaced by the bytes read from the current source. </param>
        /// <param name=""offset"">The zero-based byte offset in buffer at which to begin storing the data read from the current stream. </param>
        /// <param name=""count"">The maximum number of bytes to be read from the current stream.</param>
        /// <returns></returns>
        public override int Read(byte[] buffer, int offset, int count)
        {
            int BytesRead =0;
            var BufBytes = new byte[count];
            if (!ReadFile(handleValue.DangerousGetHandle(), BufBytes, count, ref BytesRead, IntPtr.Zero))
            {
                Marshal.ThrowExceptionForHR(Marshal.GetHRForLastWin32Error());
            }
            for (int i = 0; i < BytesRead; i++)
            {
                buffer[offset + i] = BufBytes[i];
            }
            return BytesRead;
        }
        public override int ReadByte()
        {
            int BytesRead = 0;
            var lpBuffer = new byte[1];
            if (!ReadFile(
            handleValue.DangerousGetHandle(),                        // handle to file
            lpBuffer,                // data buffer
            1,        // number of bytes to read
            ref BytesRead,    // number of bytes read
            IntPtr.Zero
            ))
            { Marshal.ThrowExceptionForHR(Marshal.GetHRForLastWin32Error()); ;}
            return lpBuffer[0];
        }

        public override long Seek(long offset, SeekOrigin origin)
        {
            throw new NotImplementedException();
        }

        public override void SetLength(long value)
        {
            throw new NotImplementedException();
        }

        public override void Write(byte[] buffer, int offset, int count)
        {
            throw new NotImplementedException();
        }

        public override void Close()
        {
            handleValue.Close();
            handleValue.Dispose();
            handleValue = null;
            base.Close();
        }
        private bool disposed = false;

        new void Dispose()
        {
            Dispose(true);
            base.Dispose();
            GC.SuppressFinalize(this);
        }

        private new void Dispose(bool disposing)
        {
            // Check to see if Dispose has already been called.
            if (!this.disposed)
            {
                if (disposing)
                {
                    if (handleValue != null)
                    {
                        _fs.Dispose();
                        handleValue.Close();
                        handleValue.Dispose();
                        handleValue = null;
                    }
                }
                // Note disposing has been done.
                disposed = true;

            }
        }

    }
}

And an example of using the class
static void Main(string[] args)
        {
            var reader = new BinaryReader(new DeviceStream(@""\\.\PhysicalDrive3""));
            var writer = new BinaryWriter(new FileStream(@""g:\test.dat"", FileMode.Create));
            var buffer = new byte[MB];
            int count;
            int loopcount=0;
            try{
                while((count=reader.Read(buffer,0,MB))>0)
                {
                    writer.Write(buffer,0,count);
                    System.Console.Write('.');
                    if(loopcount%100==0)
                    {
                        System.Console.WriteLine();
                        System.Console.WriteLine(""100MB written"");
                        writer.Flush();
                    }
                    loopcount++;
                }
            }
            catch(Exception e)
            {
                Console.WriteLine(e.Message);
            }
            reader.Close();
            writer.Flush();
            writer.Close();
        }

Standard disclaimers apply, this code may be hazardous to your health.
"
38210,"The Hitchhiker's Guide to the Galaxy
by Douglas Adams

Life, the universe, and everything
""See first, think later, then test. But always see first. Otherwise you will only see what you were expecting. Most scientists forget that."" -- Wonko the Sane
"
38280,"Mozilla Prism seems ideal for your purposes.
It shares code with Firefox but is designed to run web applications without the usual Browser interface to make them appear more like desktop applications.  So no back button or address bar to worry about.
Edit: Google Chrome has Application Shortcuts so that may now be a better option.
"
38370,"Sessions are tied to the server AND the domain. Using frameset across domain will cause all kind of breakage because that's just not how it was designed to do. 
Try using apache mod rewrite to create a ""passthrough redirection"", the ""proxy"" flag ([P]) in the rule is the magic flag that you need
Documentation at  http://httpd.apache.org/docs/1.3/mod/mod_rewrite.html
"
38510,"@Brian -1 is a good choice for the default value since no ""real"" rows are likely to have identities less than zero. If it defaulted to 0 or 1 then there'd be a chance that it'd clash with an existing row, causing a primary key violation.
For applications that stay offline and create multiple rows before saving, a common practice is to continue counting backwards (-2, -3, -4) for each new row's identity. Then when they're saved, the server can replace them with the true ""next"" value from the table.
"
38670,"The above fix (deleting the temp files) did not work for me.  I had to delete the PageName.aspx.designer.cs file, then right-click my page, and choose ""Convert to Web Application"" from the context menu.  
When Visual Studio attempted to rebuild the designer file, it encountered (and revealed to me) the source of the problem.  In my case, VS had lost a reference to a DLL needed by one of the controls on my page, so I had to clean out the generated bin folders in my project.
"
38680,"This can't be done an easy way. For instance, the ""Unanswered"" list here at stackoverflow is sorted by number of votes. So if you'd save the last ID of the page you're viewing (in a cookie, request, session, whereever) and someone upvotes a post while you're browsing page 2, page 3 isn't complete since the recently upvoted post could have been moved to page 1 or 2.
Only way to do it is to load the complete list in someones session. Please don't...
As already mentioned, let's hope people are used to this by now.
"
38820,"The question is simply answered by recognising that inheritance models an ""IS-A"" relationship, while membership models a ""HAS-A"" relationship.

An employee IS A user
An employee HAS A userinfo

Which one is correct? This is your answer.
"
38870,"You only have one primary key in either case. The second one is what's called a compound key. There's no good reason for introducing a new column. In practise, you will have to keep a unique index on all candidate keys. Adding a new column buys you nothing but maintenance overhead.
Go with option 2.
"
38890,"You could create an INSERT TRIGGER that checks that the conditions are met. That way all updates will go straight through.
CREATE TRIGGER employee_insupd
ON employee
FOR INSERT
AS
/* Get the range of level for this job type from the jobs table. */
DECLARE @min_lvl tinyint,
   @max_lvl tinyint,
   @emp_lvl tinyint,
   @job_id smallint
SELECT @min_lvl = min_lvl, 
   @max_lvl = max_lvl, 
   @emp_lvl = i.job_lvl,
   @job_id = i.job_id
FROM employee e INNER JOIN inserted i ON e.emp_id = i.emp_id 
   JOIN jobs j ON j.job_id = i.job_id
IF (@job_id = 1) and (@emp_lvl <> 10) 
BEGIN
   RAISERROR ('Job id 1 expects the default level of 10.', 16, 1)
   ROLLBACK TRANSACTION
END
ELSE
IF NOT (@emp_lvl BETWEEN @min_lvl AND @max_lvl)
BEGIN
   RAISERROR ('The level for job_id:%d should be between %d and %d.',
      16, 1, @job_id, @min_lvl, @max_lvl)
   ROLLBACK TRANSACTION
END

"
38920,"Try removing the IP restrictions for Relaying in the SMTP server, and opening it up to all relays. If it works when this is set, then you know that the problem has to do with the original restrictions. In this case, it may be a DNS issue, or perhaps you had the wrong IP address listed.
"
38940,"SELECT Field1, Field2, 'Value' Field3 FROM Table

or for clarity
SELECT Field1, Field2, 'Value' AS Field3 FROM Table

"
38960,"Use:
File.Exists(path)

MSDN: http://msdn.microsoft.com/en-us/library/system.io.file.exists.aspx
Edit: In System.IO
"
39070,"sharpssh implements sending files via scp.
"
39240,"Something like this might work, a kind of ranking system. You would probably have to split the string in your application to build a SQL string, but I have used similar to build an effective site search.
Select
Top 10
ArticleID,
ArticleTitle,
ArticleContent
From
Articles
Order By
(Case When ArticleTitle = 'Article Title' Then 1 Else 0 End) Desc,
(Case When ArticleTitle = 'Article' Then 1 Else 0 End) Desc,
(Case When ArticleTitle = 'Title' Then 1 Else 0 End) Desc,
(Case When Soundex('Article Title') = Soundex(ArticleTitle) Then 1 Else 0 End) Desc,
(Case When Soundex('Article') = Soundex(ArticleTitle) Then 1 Else 0 End) Desc,
(Case When Soundex('Title') = Soundex(ArticleTitle) Then 1 Else 0 End) Desc,
(Case When PatIndex('%Article%Title%', ArticleTitle) > 0 Then 1 Else 0 End) Desc,
(Case When PatIndex('%Article%', ArticleTitle) > 0 Then 1 Else 0 End) Desc,
(Case When PatIndex('%Title%', ArticleTitle) > 0 Then 1 Else 0 End) Desc,
(Case When PatIndex('%Article%Title%', ArticleContent) > 0 Then 1 Else 0 End) Desc,
(Case When PatIndex('%Article%', ArticleContent) > 0 Then 1 Else 0 End) Desc,
(Case When PatIndex('%Title%', ArticleContent) > 0 Then 1 Else 0 End) Desc

You can then add/remove case statements from the order by clause to improve the list based on your data.
"
39770,"Both Subversion and CVS call them Keywords.
Have a look in the SVN manual here (scroll down to svn:keywords) or here for CVS.
"
39780,"You may want to create a third package the runs packageA and then packageB.  The third package would only contain two execute package tasks.
http://msdn.microsoft.com/en-us/library/ms137609.aspx
@Craig
A status table is an option but you will have to keep monitoring it.
Here is an article about events in SSIS for you original question.
http://www.databasejournal.com/features/mssql/article.php/3558006
"
39910,"I'm not entirely sure I understand your question, especially the bit about displaying two SPField collections. Sorry if this turns out to be the answer to a completely different question!
Anyway here's a quick demo walkthrough of using the MultipleLookupField in a web part.
Create a team site. Add a few tasks to the task list. Also put a document in the Shared Documents library. Create a new column in the Shared Documents library; call it ""Related"", have it be a Lookup into the Title field of the Tasks list, and allow multiple values.
Now create a web part, do all the usual boilerplate and then add this:
Label l;
MultipleLookupField mlf;

protected override void CreateChildControls()
{
    base.CreateChildControls();
    SPList list = SPContext.Current.Web.Lists[""Shared Documents""];
    if (list != null && list.Items.Count > 0)
    {
        LiteralControl lit = new LiteralControl(""Associate tasks to "" + 
                             list.Items[0].Name);
        this.Controls.Add(lit);

        mlf = new MultipleLookupField();
        mlf.ControlMode = SPControlMode.Edit;
        mlf.FieldName = ""Related"";
        mlf.ItemId = list.Items[0].ID;
        mlf.ListId = list.ID;
        mlf.ID = ""Related"";
        this.Controls.Add(mlf);

        Button b = new Button();
        b.Text = ""Change"";
        b.Click += new EventHandler(bClick);
        this.Controls.Add(b);

        l = new Label();
        this.Controls.Add(l);
    }

}

void bClick(object sender, EventArgs e)
{
    l.Text = """";
    foreach (SPFieldLookupValue val in (SPFieldLookupValueCollection)mlf.Value)
    {
        l.Text += val.LookupValue.ToString() + "" "";
    }
    SPListItem listitem = mlf.List.Items[0];
    listitem[""Related""] = mlf.Value;
    listitem.Update();
    mlf.Value = listitem[""Related""];
}

protected override void OnInit(EventArgs e)
{
    base.OnInit(e);
    EnsureChildControls();
}

Granted, this is borderline ridiculous -- everything is hard-coded, there is no error-handling at all, and it serves no useful purpose -- but it's only meant as a quick demo. Now build and deploy this web part and add an instance of it to your team site's homepage; it should allow you to get and set the tasks which are associated with the first document in the library.
The strange bit towards the end of the button Click handler, where we read a value from mlf.Value and then write it back again, appears to be required if you want the UI to stay in sync with the actual list values. Try omitting the last line of bClick to see what I mean. This has been driving me nuts for the last hour or so, and I'm hoping another commenter can come up with a better approach...
"
39960,"
locals() - No. 
globals() - Yes.

window is a reference to the global scope, like globals() in python.
globals()[""foo""]

is the same as:
window[""foo""]

"
40090,"Just to satisfy some curiosity:
From Why doesn't C# support default parameters?:

In languages such as C++, a default value can be included as part of the method declaration:
void Process(Employee employee, bool bonus = false)
This method can be called either with:
a.Process(employee, true);
or
a.Process(employee);
in the second case, the parameter bonus is set to false.
C# doesn't have this feature.
One reason we don't have this feature is related to a specific implementation of the feature. In the C++ world, when the user writes:
a.Process(employee);
the compiler generates
a.process(employee, false);
In other words, the compiler takes the default value that is specified in the method prototype and puts it into the method call - it's just as if the user wrote 'false' as the second parameter. There's no way to change that default value without forcing the user of the class to recompile, which is unfortunate.
The overloading model works better in this respect. The framework author just defines two separate methods, and the single-parameter one calls the two-parameter method. This keeps the default value in the framework, where it can be modified if necessary.
It would be possible for a compiler to take something like the C++ definition and produce the overloads, but there are a few issues with that approach.
The first one is that the correlation between the code that the user writes and the code the compiler generates is less obvious. We generally try to limit magic when possible, as it makes it harder for programmers. The second issue has to do with things like XML doc comments and intellisense. The compiler would have to have special rules for how it generates doc comments for the overloaded methods, and intellisense would need to have smarts to collapse the overloaded methods into a single method.
Writing overloads yourself is a bit less convenient, but we think it's an acceptable solution. 

"
40230,"Using Guids as primary keys is acceptable and is considered a fairly standard practice for the same reasons that you are considering them.  They can be overused which can make things a bit tedious to debug and manage, so try to keep them out of code tables and other reference data if at all possible.
The thing that you have to concern yourself with is the human readable identifier.  Guids cannot be exchanged by people - can you imagine trying to confirm your order number over the phone if it is a guid?  So in an offline scenario you may still have to generate something - like a publisher (workstation/user) id and some sequence number, so the order number may be 123-5678 -.  
However this may not satisfy business requirements of having a sequential number.  In fact regulatory requirements can be and influence - some regulations (SOX maybe) require that invoice numbers are sequential.  In such cases it may be neccessary to generate a sort of proforma number which is fixed up later when the systems synchronise.  You may land up with tables having OrderId (Guid), OrderNo (int), ProformaOrderNo (varchar) - some complexity may creep in.
At least having guids as primary keys means that you don't have to do a whole lot of cascading updates when the sync does eventually happen - you simply update the human readable number.
"
40480,"Java is always pass-by-value. Unfortunately, they decided to call pointers references, thus confusing newbies. Because those references are passed by value.
It goes like this:
public static void main( String[] args ){
    Dog aDog = new Dog(""Max"");
    foo(aDog);

    if (aDog.getName().equals(""Max"")) { //true
        System.out.println( ""Java passes by value."" );

    } else if (aDog.getName().equals(""Fifi"")) {
        System.out.println( ""Java passes by reference."" );
    }
}

public static void foo(Dog d) {
    d.getName().equals(""Max""); // true

    d = new Dog(""Fifi"");
    d.getName().equals(""Fifi""); // true
}

In this example aDog.getName() will still return ""Max"". The value aDog within main is not overwritten in the function foo with the Dog ""Fifi"" as the object reference is passed by value. If it were passed by reference, then the aDog.getName() in main would return ""Fifi"" after the call to foo.
Likewise:
Dog aDog = new Dog(""Max"");
foo(aDog);
aDog.getName().equals(""Fifi""); // true
public void foo(Dog d) {
    d.getName().equals(""Max""); // true
    d.setName(""Fifi"");
}

In the above example, FiFi is the dog's name after call to foo(aDog). Any operations that foo performs on d are such that, for all practical purposes, they are performed on aDog itself (except d=new Dog(""Boxer"")).
"
40590,"Are you certain that currentPage is an integer? Try something like:
var currentPage = 5;
jQuery('li').eq(currentPage);

as a simple sanity check. If that works, you should try casting to Integer.
"
40680,"Here is a list I normally refer to for this type of information:
Request.ApplicationPath :   /virtual_dir
Request.CurrentExecutionFilePath :  /virtual_dir/webapp/page.aspx
Request.FilePath :  /virtual_dir/webapp/page.aspx
Request.Path :  /virtual_dir/webapp/page.aspx
Request.PhysicalApplicationPath :   d:\Inetpub\wwwroot\virtual_dir\
Request.QueryString :   /virtual_dir/webapp/page.aspx?q=qvalue
Request.Url.AbsolutePath :  /virtual_dir/webapp/page.aspx
Request.Url.AbsoluteUri :   http://localhost:2000/virtual_dir/webapp/page.aspx?q=qvalue
Request.Url.Host :  localhost
Request.Url.Authority : localhost:80
Request.Url.LocalPath : /virtual_dir/webapp/page.aspx
Request.Url.PathAndQuery :  /virtual_dir/webapp/page.aspx?q=qvalue
Request.Url.Port :  80
Request.Url.Query : ?q=qvalue
Request.Url.Scheme :    http
Request.Url.Segments :  /
    virtual_dir/
    webapp/
    page.aspx

Hopefully you will find this useful!
"
40730,"In C# 5 and earlier, to give auto implemented properties a default value, you have to do it in a constructor.
The ability to have auto property initializers is included since C# 6.0. The syntax is:
public int X { get; set; } = x; // C# 6 or higher

"
40840,"What OS is this? Is it on a 64-bit system?  What is the nature of the failure: silent or is an exception thrown?
You could try running ProcessMonitor and seeing if it sees the attempt to set the value.
"
41010,"Sorry to resurrect an old question - but none of the answers have been flagged as ""accepted"" yet.
There's a library called ""template"" that does a great job of allowing you to use just about any template parser you want:
Template CI Library - Parsers
The syntax is pretty easy for integrating into your CI application and the smarty integration spot on.
"
41050,"I wouldn't cache the connection object, that will defeat the built-in connection pooling -- ADO.NET will handle connections (assuming you instantiate and close them) efficiently by itself.
As far as the connection string itself, you shouldn't need to cache it if you load it from connection -- the connection manager object in the .NET 2.0 framework loads the config into memory when you first access it, so there are no repeat trips to the file system.
"
41220,"No offense, but the question is a little ""misguided"". There is no ""silver bullet"" solution. I would recommend to read up on cryptography in general and then do some threat modeling. Some questions (by no means a comprehensive list) you should ask yourself:

Is the module doing the encryption the one which needs to decrypt it (in this case use symmetric crypto) or will it send data to an other module (on an other machine) which will use it (in which case you should consider public-key crypto)
What do you want to protect against? Someone accessing the database but not having the sourcecode (in which case you can hardcode the encryption key directly into the source)? Someone sniffing your local network (you should consider transparent solutions like IPSec)? Someone stealing your server (it can happen even in data centers - in which case full disk encryption should be considered)?
Do you really need to keep the data? Can't you directly pass it to the credit card processor and erase it after you get the confirmation? Can't you store it locally at the client in a cookie or Flash LSO? If you store it at the client, make sure that you encrypt it at the server side before putting it in a cookie. Also, if you are using cookies, make sure that you make them http only.
Is it enough to compare the equality of the data (ie the data that the client has given me is the same data that I have)? If so, consider storing a hash of it. Because credit card numbers are relatively short and use a reduced set of symbols, a unique salt should be generated for each before hashing.

Later edit: note that standard encryption algorithms from the same category (for example 3DES and AES - both being symmetric block cyphers) are of comparable strength. Most (commercial) systems are not broken because somebody bruteforced their encryption, but because their threat modelling was not detailed enough (or flat out they didn't have any). For example you can encrypt all the data, but if you happen to have a public facing web interface which is vulnerable to SQL injection, it won't help you much.
"
41290,"Here is the code that I use to make sure a file is not locked by another process.  It's not 100% foolproof, but it gets the job done most of the time:
    /// <summary>
    /// Blocks until the file is not locked any more.
    /// </summary>
    /// <param name=""fullPath""></param>
    bool WaitForFile(string fullPath)
    {
        int numTries = 0;
        while (true)
        {
            ++numTries;
            try
            {
                // Attempt to open the file exclusively.
                using (FileStream fs = new FileStream(fullPath,
                    FileMode.Open, FileAccess.ReadWrite, 
                    FileShare.None, 100))
                {
                    fs.ReadByte();

                    // If we got this far the file is ready
                    break;
                }
            }
            catch (Exception ex)
            {
                Log.LogWarning(
                   ""WaitForFile {0} failed to get an exclusive lock: {1}"", 
                    fullPath, ex.ToString());

                if (numTries > 10)
                {
                    Log.LogWarning(
                        ""WaitForFile {0} giving up after 10 tries"", 
                        fullPath);
                    return false;
                }

                // Wait for the lock to be released
                System.Threading.Thread.Sleep(500);
            }
        }

        Log.LogTrace(""WaitForFile {0} returning true after {1} tries"",
            fullPath, numTries);
        return true;
    }

Obviously you can tweak the timeouts and retries to suit your application.  I use this to process huge FTP files that take a while to be written.
"
41300,"I use EmacsW32, it works great. EDIT: I now use regular GNU Emacs 24, see below.
See its EmacsWiki page for details.
To me, the biggest advantage is that:

it has a version of emacsclient that starts the Emacs server if no server is running (open all your files in the same Emacs window)
it includes several useful packages such as Nxml
it has a Windows installer or you can build it from sources

And concerning XEmacs, according to this post by Steve Yegge:

To summarize, I've argued that XEmacs has a much lower market share, poorer performance, more bugs, much lower stability, and at this point probably fewer features than GNU Emacs. When you add it all up, it's the weaker candidate by a large margin.

EDIT: I now use regular GNU Emacs 24. It also contains Nxml, can be installed or built from sources, and with this wrapper, the Emacs server starts if no server is running. Cheers!
"
41320,"What you need is source control.
You should definitely not open the same files over the network on multiple machines. For one thing, Visual Studio has safeguards in place to prevent you from modifying certain files during a build, but it has none of that that will prevent others from modifying the same files over the network.
By setting up source control, each developer will have a separate copy of the files locally on his or her developer machine, and periodically communicate with the source control system to check in/commit changes. After that, other developers can ask for the latest updates when they're ready to retrieve them.
"
41330,"Using the DirectX SDK, you can call DirectSoundCaptureEnumerate, which will call your DSEnumCallback function for each DirectSoundCapture device on the system.  The first parameter passed to your DSEnumCallback is an LPGUID, which is the ""Address of the GUID that identifies the device being enumerated, or NULL for the primary device"".
If all you need to do is find out if a recording device is present (I don't think this is good enough if you really need to know the default device), you can use waveInGetNumDevs:
#include <tchar.h>
#include <windows.h>
#include ""mmsystem.h""

int _tmain( int argc, wchar_t *argv[] )
{
    UINT deviceCount = waveInGetNumDevs();

    if ( deviceCount > 0 )
    {
        for ( int i = 0; i < deviceCount; i++ )
        {
            WAVEINCAPSW waveInCaps;

            waveInGetDevCapsW( i, &waveInCaps, sizeof( WAVEINCAPS ) );

            // do some stuff with waveInCaps...
        }
    }

    return 0;
}

"
41400,"the problem is that you cannot use 'printf' with va_args.  You must use vprintf if you are using variable argument lists.  vprint, vsprintf, vfprintf, etc.  (there are also 'safe' versions in Microsoft's C runtime that will prevent buffer overruns, etc.)
You sample works as follows:
void myprintf(char* fmt, ...)
{
    va_list args;
    va_start(args,fmt);
    vprintf(fmt,args);
    va_end(args);
}

int _tmain(int argc, _TCHAR* argv[])
{
    int a = 9;
    int b = 10;
    char v = 'C'; 
    myprintf(""This is a number: %d and \nthis is a character: %c and \n another number: %d\n"",a, v, b);
    return 0;
}

"
41460,"The page linked to in another answer is a good source, but a lot to read.  Here is a short list of some the major differences:

internationalization: they used new terminology, rather than using language tied to US legal concepts
patents: they specifically address patents (including the Microsoft/Novell issue noted in another answer)
âTivo-izationâ: they address the restrictions (like Tivoâs) in consumer products that take away, though hardware, the ability to modify the software
DRM: they address digital rights management (which they call digital restrictions management)
compatibility: they addressed compatibility with some other open source licenses
termination: they addressed specifically what happens if the license is violated and the cure of violations

I agree with the comment about consulting a lawyer (one who knows about software license issues, though). In doing these things (and more), they more than doubled the length of the GPL. Although GPLv3 is a complex legal document, it was designed to be read and reasonable understood by software developers. There is also a guide to understanding it and in depth discussion of the changes from v2 to v3 at http://copyleft.org/guide/.
"
41580,"If you stop testing it, how are you going to know when it's fixed, and more importantly, how are you going to know if it gets broken again?  I'm against taking out the test, because you're likely to forget to add it back in again.
"
41590,"Namespaces are packages essentially. They can be used like this:
namespace MyNamespace
{
  class MyClass
  {
  };
}

Then in code:
MyNamespace::MyClass* pClass = new MyNamespace::MyClass();

Hope that helps.
Or, if you want to always use a specific namespace, you can do this:
using namespace MyNamespace;

MyClass* pClass = new MyClass();

Edit: Following what bernhardrusch has said, I tend not to use the ""using namespace x"" syntax at all, I usually explicitly specify the namespace when instantiating my objects (i.e. the first example I showed).
And as you asked below, you can use as many namespaces as you like.
"
41630,"No, that will just concatenate the output from ls and the contents of directory.
But you can do this:
#!/usr/bin/env ruby
directory = '/home/paulgreg/'
`ls #{directory}`

"
41640,"I suggest using the built in Mixer in Vista...
Why do you want to use an 3rd party program?
"
41970,"Lucene is very scalable—which means its good for little applications too. You can create an index in memory very quickly if that's all you need.
For fuzzy searching, you really need to decide what algorithm you'd like to use. With information retrieval, I use an n-gram technique with Lucene successfully. But that's a special indexing technique, not a ""library"" in itself.
Without knowing more about your application, it won't be easy to recommend a suitable library. How much data are you searching? What format is the data? How often is the data updated?
"
42070,"Your NAME variable is being substituted like this:
printf ""Hello, %s\n"" George W. Bush

Use this:
#! /bin/sh
NAME=""George W. Bush""
printf ""Hello, %s\n"" ""$NAME""

"
42150,"I'd probably recommend designing your app so the ""OnStart"" and ""OnStop"" overrides in the Windows Service just call methods on a class library assembly.  That way you can automate unit tests against the class library methods, and the design also abstracts your business logic from the implementation of a Windows Service.
In this scenario, testing the ""OnStart"" and ""OnStop"" methods themselves in a Windows Service context would then be an integration test, not something you would automate.
"
42200,"Take advantage of the namespace settings. You can get to it in properties from clicking in the white space of the ORM.
This allows me to have a Users table and a User class for one set of business rules and a second (but the same data store) Users table and a User class for another set of business rules.
Or, break up the library, which should also have the affect of changing the namespacing depending on your company's naming conventions. I've never worked on an enterprise app where I needed access to every single table.
"
42460,"Here's an article with full code sample on how to use your own custom ""chrome"" for an application:
http://geekswithblogs.net/kobush/articles/CustomBorderForms3.aspx
This looks like some really good stuff. There are a total of 3 articles in it's series, and it runs great, and on Vista too!
"
42490,"@Ben
You can actually do a full delete in TFS, but it is highly not recommended unless you know what you are doing.  You have to do it from the command line with the command tf destroy
tf destroy [/keephistory] itemspec1 [;versionspec]
           [itemspec2...itemspecN] [/stopat:versionspec] [/preview]
           [/startcleanup] [/noprompt]

Versionspec:
    Date/Time         Dmm/dd/yyyy
                      or any .Net Framework-supported format
                      or any of the date formats of the local machine
    Changeset number  Cnnnnnn
    Label             Llabelname
    Latest version    T
    Workspace         Wworkspacename;workspaceowner

Just before you do this make sure you try it out with the /preview.  Also everybody has their own methodology for branching.  Mine is to branch releases, and do all development in the development or root folder.  Also it sounded like branching worked fine for you, just the solution file was screwed up, which may be because of a binding issue and the vssss file.
"
42550,"What type of address information are you referring to?
There are a couple FireFox plugins Operator & Tails that allow you to extract and view microformats from web pages.
"
42610,"Have you looked at Google Web Toolkit?  GWT allows you to write server side Java objects which get translated into Javascript for you.  This allows you to not deal with the browser quirks at all.
I'm not sure how well integrated the Gears and GWT projects are, however.  If it isn't integrated yet, I'm sure it will be in fairly short order.
Edit:  This is probably more of an alternate way of doing what you're looking for, rather than a suggestion for a meta language.
"
42620,"There are some very good uses for views; I have used them a lot for tuning and for exposing less normalized sets of information, or for UNION-ing results from multiple selects into a single result set.
Obviously any programming tool can be used incorrectly, but I can't think of any times in my experience where a poorly tuned view has caused any kind of drawbacks from a performance standpoint, and the value they can provide by providing explicitly tuned selects and avoiding duplication of complex SQL code can be significant.
Incidentally, I have never been a fan of architectural ""rules"" that are based on keeping developers from hurting themselves.  These rules often have unintended side-effects -- the last place I worked didn't allow using NULLs in the database, because developers might forget to check for null.  This ended up forcing us to work around ""1/1/1900"" dates and  integers defaulted to ""0"" in all the software built against the databases, and introducing a litany of bugs caused by devs working around places where NULL was the appropriate value.
"
42690,"Without getting into the relative merits of the languages (which would be an entire pissing contest in itself), IronPython (stable 1.1.1, beta 2.0) is further along in development than IronRuby (alpha)
"
42710,"What you have is fine.  A case statement would also work equally well.  It's just a matter of how expressive you wish to be.  
Your solution, indexing, works fine if the select encodings don't have any special meaning (a memory address selector for example).  If the select encodings do have some special semantic meaning to you the designer (and there aren't too many of them), then go with a case statement and enums.
Synthesis wise, it doesn't matter which one you use.  Any decent synthesis tool will produce the same result.
"
42740,"WCF - Windows Communication Framework - is Microsoft's framework to make inter-process communication easier. It let's you do this communication through various means, plain old asmx web services, Remoting, MS Message Queuing, and a couple more.
It let's you talk with other .NET apps, or non-Microsoft technologies (like J2EE). It's extensible enough to allow for newer stuff, like REST too (I don't think REST is built-in).
"
42770,"The code
r.cc :
#include ""t.h""

int main()
{
    f();
    return 0;
}

t.h :
void f();

t.cc :
#include<iostream>
#include ""t.h""    

void f()
{
    std::cout << ""OH HAI.  I'M F."" << std::endl;
}

But how, how, how?!
~$ g++ -fpic -c t.cc          # get t.o
~$ g++ -shared -o t.so t.o    # get t.so
~$ export LD_LIBRARY_PATH=""."" # make sure t.so is found when dynamically linked
~$ g++ r.cc t.so              # get an executable

The export step is not needed if you install the shared library somewhere along the global library path.
"
42830,"We had exactly the same problem.  What we had to do is write a script at the bottom of the page that quickly blurs then refocuses to the textbox.  You can have a look at the (terribly hacky) solution here: http://www.drive.com.au 
The textbox id is  MainSearchBox_SearchTextBox.  Have a look at about line 586 & you can see where I'm wiring up all the events (I'm actually using prototype for this bit.
Basically on the focus event of the textbox I set a global var called textBoxHasFocus to true and on the blur event I set it to false.  The on the load event of the page I call this script:
if (textBoxHasFocus) {
    $get(""MainSearchBox_SearchTextBox"").blur();
    $get(""MainSearchBox_SearchTextBox"").focus();
}

This resets the textbox.  It's really dodgy, but it's the only solution I could find
"
42950,"I didn't notice this earlier when I was looking at the documentation for the calendar module, but a method called monthrange provides this information:

monthrange(year, month)
      Returns weekday of first day of the month and number of days in month, for the specified year and month. 

>>> import calendar
>>> calendar.monthrange(2002,1)
(1, 31)
>>> calendar.monthrange(2008,2)
(4, 29)
>>> calendar.monthrange(2100,2)
(0, 28)

so:
calendar.monthrange(year, month)[1]

seems like the simplest way to go.
Just to be clear, monthrange supports leap years as well:
>>> from calendar import monthrange
>>> monthrange(2012, 2)
(2, 29)

My previous answer still works, but is clearly suboptimal.
"
42980,"Place this into your ~/.hgrc (or, optionally, your Mercurial.ini on Windows):
[merge-tools]
p4.priority = 100
p4.premerge = True  # change this to False if you're don't trust hg's internal merge
p4.executable = /Applications/p4merge.app/Contents/MacOS/p4merge
p4.gui = True
p4.args = $base $local $other $output

Requires Mercurial 1.0 or newer.  Clearly you'll need to update the path to that executable to reflect where you'd got p4merge installed.
"
42990,"I think in this case you want negative lookbehind, like so:
foo.*(?<!bar)

"
43180,"There are a lot of links after this brief overview of what is involved in writing an OS for the X86 platform.
The link that appears to be most promising (www.nondot.org/sabre/os/articles) is no longer available, so you'll need to poke through the Archive.org version to read it.
At the end of the day the bootloader takes the machine code of the kernel, puts it in memory, and jumps to it.  You can put any machine code in the kernel that you want, but most C programs expect an OS so you'll need to tell your compiler that it won't have all that, or the bootloader has to create some of it.
The kernel then does all the heavy lifting, and I suspect it's the example kernel you want.  But there's a long way to go between having a kernel that says, ""Hello world"" to having a kernel that loads a command interpretor, provides disk services, and loads and manages programs.
You might want to consider subscribing to ACM to get access to their older literature - there are lots of articles in the late 80's and early 90's in early computing magazines about how to create alternative OSs.  There are likely books that are out of print from this era as well.  You might be able to get the same information for free by looking up the indexes of those magazines (which are available on that site - click ""index"" near the magazine name) and then asking around for people with a copy.
Lastly, I know that usenet is dead (for so sayeth the prophets of internet doom) but you'll find that many of the craggy old experts from that era still live there.  You should search google groups (they have dejanews's old repository) and I expect you'll find many people asking the same questions a decade or 1.5 ago that you're asking now.  You may even run across Linus Torvalds' many queries for help as he was developing linux originally.  If searches don't bring anything up, ask in the appropriate newsgroup (probably starts with comp.arch, but search for ones with OS in the name).
"
43290,"If you need to use something similar to the {% url %} template tag in your code, Django provides the django.core.urlresolvers.reverse(). The reverse function has the following signature:
reverse(viewname, urlconf=None, args=None, kwargs=None)

https://docs.djangoproject.com/en/dev/ref/urlresolvers/
"
43320,"Briefly:

Always use transactions
Don't use Close(), instead wrap your calls on an ISession inside a using statement or manage the lifecycle of your ISession somewhere else.

From the documentation:

From time to time the ISession will execute the SQL statements needed to synchronize the ADO.NET connection's state with the state of objects held in memory. This process, flush, occurs by default at the following points

from some invocations of Find() or Enumerable()
from NHibernate.ITransaction.Commit()
from ISession.Flush() 

The SQL statements are issued in the following order

all entity insertions, in the same order the corresponding objects were saved using ISession.Save()
all entity updates
all collection deletions
all collection element deletions, updates and insertions
all collection insertions
all entity deletions, in the same order the corresponding objects were deleted using ISession.Delete()

(An exception is that objects using native ID generation are inserted when they are saved.)
Except when you explicity Flush(), there are absolutely no guarantees about when the Session executes the ADO.NET calls, only the order in which they are executed. However, NHibernate does guarantee that the ISession.Find(..) methods will never return stale data; nor will they return the wrong data.
It is possible to change the default behavior so that flush occurs less frequently. The FlushMode class defines three different modes: only flush at commit time (and only when the NHibernate ITransaction API is used), flush automatically using the explained routine, or never flush unless Flush() is called explicitly. The last mode is useful for long running units of work, where an ISession is kept open and disconnected for a long time.

...
Also refer to this section:

Ending a session involves four distinct phases:

flush the session
commit the transaction
close the session
handle exceptions 

Flushing the Session
If you happen to be using the ITransaction API, you don't need to worry about this step. It will be performed implicitly when the transaction is committed. Otherwise you should call ISession.Flush() to ensure that all changes are synchronized with the database.
Committing the database transaction
If you are using the NHibernate ITransaction API, this looks like:
tx.Commit(); // flush the session and commit the transaction

If you are managing ADO.NET transactions yourself you should manually Commit() the ADO.NET transaction.
sess.Flush();
currentTransaction.Commit();

If you decide not to commit your changes:
tx.Rollback();  // rollback the transaction

or:
currentTransaction.Rollback();

If you rollback the transaction you should immediately close and discard the current session to ensure that NHibernate's internal state is consistent.
Closing the ISession
A call to ISession.Close() marks the end of a session. The main implication of Close() is that the ADO.NET connection will be relinquished by the session.
tx.Commit();
sess.Close();

sess.Flush();
currentTransaction.Commit();
sess.Close();

If you provided your own connection, Close() returns a reference to it, so you can manually close it or return it to the pool. Otherwise Close() returns it to the pool. 

"
43400,"Check out the Grids framework from YUI. Particularly awesome is the Grid Builder. Also, they have a set of reset, base, and font CSS files that will give you a good baseline to build on.
"
43490,"Normally DestroyHandle is being called in Dispose method. So you need to make sure that all controls are disposed to avoid resource leaks.
"
43500,"Enumerable.SequenceEqual

Determines whether two sequences are equal by comparing their elements by using a specified IEqualityComparer(T).

You can't directly compare the list & the dictionary, but you could compare the list of values from the Dictionary with the list
"
43580,"The python-magic method suggested by toivotuo is outdated. Python-magic's current trunk is at Github and based on the readme there, finding the MIME-type, is done like this.
# For MIME types
>>> import magic
>>> mime = magic.Magic(mime=True)
>>> mime.from_file(""testdata/test.pdf"")
'application/pdf'
>>>

"
43870,"Update as of PostgreSQL 9.0:
Recent versions of Postgres (since late 2010) have the string_agg(expression, delimiter) function that will do exactly what the question asked for, even letting you specify the delimiter string:
SELECT company_id, string_agg(employee, ', ')
FROM mytable
GROUP BY company_id;

Update as of PostgreSQL 8.4:
PostgreSQL 8.4 (in 2009) introduced the aggregate function array_agg(expression) which concatenates the values into an array. Then array_to_string() can be used to give the desired result:
SELECT company_id, array_to_string(array_agg(employee), ', ')
FROM mytable
GROUP BY company_id;

Original Answer (for pre-8.4 PostgreSQL):
There is no built-in aggregate function to concatenate strings. It seems like this would be needed, but it's not part of the default set. A web search however reveals some manual implementations the same example:
CREATE AGGREGATE textcat_all(
  basetype    = text,
  sfunc       = textcat,
  stype       = text,
  initcond    = ''
);

Here is the CREATE AGGREGATE documentation.
In order to get the "", "" inserted in between them without having it at the end, you might want to make your own concatenation function and substitute it for the ""textcat"" above. Here is one I put together but haven't tested (update: tested on 8.3.12 and working fine):
CREATE FUNCTION commacat(acc text, instr text) RETURNS text AS $$
  BEGIN
    IF acc IS NULL OR acc = '' THEN
      RETURN instr;
    ELSE
      RETURN acc || ', ' || instr;
    END IF;
  END;
$$ LANGUAGE plpgsql;

Note: The function above will output a comma even if the value in the row is null/empty, which outputs:
a, b, c, , e, , g

If you would prefer to remove extra commas to output:
a, b, c, e, g

just add an ELSIF check to the function:
CREATE FUNCTION commacat_ignore_nulls(acc text, instr text) RETURNS text AS $$
  BEGIN
    IF acc IS NULL OR acc = '' THEN
      RETURN instr;
    ELSIF instr IS NULL OR instr = '' THEN
      RETURN acc;
    ELSE
      RETURN acc || ', ' || instr;
    END IF;
  END;
$$ LANGUAGE plpgsql;

"
43890,"I also recommend ffmpeg, but the command line suggested by John Boker has an unintended side effect: it re-encodes the file to the default bitrate (which is 64 kb/s in the version I have here at least). This might give your customers a false impression of the quality of your sound files, and it also takes longer to do.
Here's a command line that will slice to 30 seconds without transcoding:
ffmpeg -t 30 -i inputfile.mp3 -acodec copy outputfile.mp3

The -acodec switch tells ffmpeg to use the special ""copy"" codec which does not transcode.  It is lightning fast.
NOTE: the command was updated based on comment from Oben Sonne
"
43920,"We use CruiseControl.NET to automatically push source control checkins out to a dev server. This allows people to regression test their changes in real time.
We then use a series of scripts to robocopy the build to other environments. 
For Example:

Developer completes a change and checks into source control
CruiseControl detects the change and builds the new code and drops into Dev.
Developer is able to test the change in a enviroment that mirrors production.
This repeats until all changes are done and tested. 
A script is ran that copies Dev to Test.
Dev is now frozen while business owners UAT on the Test enviroment. If a defect is found, it is fixed in dev and then promoted back to Test.
Once UAT passes, a script is ran that copies the build to the final production farm.
At this point, developers are free to push code back to Dev for the next round of work.

"
43940,"SQL Server 2000 doesn't officially support custom aggregate functions.  However, I recently needed that functionality as well, and I found this article enlightening:
http://weblogs.sqlteam.com/jeffs/articles/1490.aspx
It's a bit hack-ish, though: it requires access to the sp_OA___ extended procedures.
The summary is that you can simulate an aggregate function with a series of four wrapper functions, each of which performs one of the following tasks:

Create an ActiveX object that can hold state within the query. Call this before running the query.
Do the actual aggregation using the ActiveX object.
Clear the ActiveX object state on GROUP BY boundries
Destroy the object.  Call this after running the query and during error handling.

You then include items 2 and 3 in the select list for your query, and item 2 must also be wrapped in an existing no-effect aggregate function like MAX() or MIN().  You can also use this technique for cumulative functions to do things like row numbers.
Some of the comments suggest that the optimizer may try to negate the aggregation effects by optimizing away the calls in some circumstances, though I expect that would be a very rare case indeed.  However, I found this question because I took those warnings seriously enough to continue searching for something better. 
"
43960,"You might also look into Moodle - it's a platform developed to supplement classroom teaching (or implement online learning courses) but should have all the major features you listed, and would support your needs reasonably well, as well as enhancing your event with an online component such as slide/presentation distribution only to registered users or users that took a particular class, etc)
"
43970,"@eli: modifying sendmail.cf directly is not usually recommended, since it is generated by the macro compiler. 
Edit /etc/mail/sendmail.mc to include the line:
  define(`SMART_HOST',`mailrelay.example.com')dnl

After changing the sendmail.mc macro configuration file, it must be recompiled
to produce the sendmail configuration file.
  # m4 /etc/mail/sendmail.mc > /etc/sendmail.cf

And restart the sendmail service (Linux):
  # /etc/init.d/sendmail restart

As well as setting the smarthost, you might want to also disable name resolution configuration and possibly shift your sendmail to non-standard port, or disable daemon mode.
Disable Name Resolution
Servers that are within fire-walled networks or using Network Address
Translation (NAT) may not have DNS or NIS services available. This creates
a problem for sendmail, since it will use DNS by default, and if it is not
available you will see messages like this in mailq:
  host map: lookup (mydomain.com): deferred)

Unless you are prepared to setup an appropriate DNS or NIS service that
sendmail can use, in this situation you will typically configure name
resolution to be done using the /etc/hosts file. This is done by enabling
a 'service.switch' file and specifying resolution by file, as follows:
1: Enable service.switch for sendmail
Edit /etc/mail/sendmail.mc to include the lines:
  define(`confSERVICE_SWITCH_FILE',`/etc/mail/service.switch')dnl

2: Configure service.switch for files
Create or modify /etc/mail/service.switch to refer only to /etc/hosts for name
resolution:
  # cat /etc/mail/service.switch
  hosts files

3: Recompile sendmail.mc and restart sendmail for this setting to take effect.
Shift sendmail to non-standard port, or disable daemon mode
By default, sendmail will listen on port 25. You may want to change this port
or disable the sendmail daemon mode altogether for various reasons:
- if there is a security policy prohibiting the use of well-known ports
- if another SMTP product/process is to be running on the same host on the standard port
- if you don't want to accept mail via smtp at all, just send it using sendmail
1: To shift sendmail to use non-standard port.
Edit /etc/mail/sendmail.mc and modify the ""Port"" setting in the line:
  DAEMON_OPTIONS(`Port=smtp,Addr=127.0.0.1, Name=MTA')

For example, to get sendmail to use port 125:
  DAEMON_OPTIONS(`Port=125,Addr=127.0.0.1, Name=MTA')

This will require sendmail.mc to be recompiled and sendmail to be restarted.
2: Alternatively, to disable sendmail daemon mode altogether (Linux)
Edit /etc/sysconfig/sendmail and modify the ""DAEMON"" setting to:
  DAEMON=no

This change will require sendmail to be restarted.
"
44080,"According to ASP.NET AJAX in Action, p. 257

Just before the old markup is replaced with the updated HTML, all the DOM elements in the panel are examined for Microsoft Ajax behaviours or controls attached to them. To avoid memory leaks, the components associated with DOM elements are disposed, and then destroyed when the HTMl is replaced.

So as far as I know, any asp.net ajax components within the update panel are disposed to prevent memory leaks, but anything else in there will just be replaced with the html received.
So if you don't have any asp.net ajax components in the target container for the response, it would be basically the same as an inner html replacement with any other js framework / ajax request, so i would say that it's just the how the browser handles this, rather than asp.net ajax causing this.
Also, while it may be ""leaking"", it may be by design, meaning that the browser might not have reclaimed the dom elements yet and released them. Also, drip might be causing those to leak, as it is attaching to those dom elements.
"
44100,"I like the second one purely because any avoidance of magic strings/numbers in code is a good thing.  IMO if you need to reference a number or string literal in code more than once, it should be a constant.  In most cases even if it's only used once it should be in a constant 
"
44190,"Here is a short pure-javascript example. Assume you have a div with the id ""maincontent"".
var newnode = document.createTextNode('Here is some text.');
document.getElementById('maincontent').appendChild(newnode);

Of course, things are a lot easier (especially when you want to do more complicated things) with jQuery.
"
44220,"foreach creates an instance of an enumerator (returned from GetEnumerator) and that enumerator also keeps state throughout the course of the foreach loop. It then repeatedly calls for the Next() object on the enumerator and runs your code for each object it returns.
They don't boil down to the same code in any way, really, which you'd see if you wrote your own enumerator.
"
44260,"You can retrieve this information through WMI.
See the Win32_Process class, in particular its command line property.  This Code Project article provides pointers on how to do this,
"
44270,"So if you have two arrays and they hold the same data just in different order then just do this:
A = B
I suspect that is not your situation so I think we need more info.
"
44350,"AutoHotkey is a reasonably good program for implementing windows key shortcuts.  You might instead define WIN + G to be ""open browser to google"" which gives you a better response time (don't have to wait for start menu to popup, etc)
There are macro programs that change the macros used based on the window that's in focus.  I've never needed that much control, but you might want to look into that.
-Adam
"
44470,"We use Team Foundation Server Team Build and have added a block to the TFSBuild.proj's AfterCompile target to trigger the ClickOnce publish with our preferred version number:
<MSBuild Projects=""$(SolutionRoot)\MyProject\Myproject.csproj""
         Properties=""PublishDir=$(OutDir)\myProjectPublish\;
                     ApplicationVersion=$(PublishApplicationVersion);
                     Configuration=$(Configuration);Platform=$(Platform)""
         Targets=""Publish"" />

The PublishApplicationVersion variable is generated by a custom MSBuild task to use the TFS Changeset number, but you could use your own custom task or an existing solution to get the version number from the AssemblyInfo file.
This could theoretically be done in your project file (which is just an MSBuild script anyway), but I'd recommend against deploying from a developer machine.
I'm sure other continuous integration (CI) solutions can handle this similarly.

Edit: Sorry, got your question backwards. Going from the ClickOnce version number to the AssemblyInfo file should be doable. I'm sure the MSBuild Community Tasks (link above) have a task for updating the AssemblyInfo file, so you'd just need a custom task to pull the version number from the ClickOnce configuration XML.
However, you may also consider changing your error reporting to include the ClickOnce publish version too:
if (System.Deployment.Application.ApplicationDeployment.IsNetworkDeployed)
{
    Debug.WriteLine(System.Deployment.Application.ApplicationDeployment.
                                                        CurrentDeployment.CurrentVersion);
}

"
44630,"You can use various ways to handle this situation, depending on your source control system. 
Private branches: Allow you to check in and work on code while you go, merging back and forth at appropriate times.
Shelvesets/pacakaged changesets: Allow you to store changesets and send them around for review - ensuring they're production ready before check in.
As to whether this is an appropriate way to work, we don't allow check-in to main branches without prior review. To pass review your code must pass various automated tools, and then must be acceptable to your peer reviewer. For some definitions of ""production ready"" - this is it. Therefore, we do something like what you do. However, we use private branches to ensure that check-ins can still be made while this is in progress, and that other check-ins don't have to interfere. 
If production ready means tested in an integration environment, then it sounds like you may need staging branches or something similar.
"
44660,"Use the Regex COM component built into Windows. You can find a step by step on referencing and using it in your project at: http://www.regular-expressions.info/vb.html
"
44760,"Dunno exactly what happens within eclipse, I presume it does some funky stuff in the .metadata directory of the workspace.  That said, I would recommend the following to get eclipse to learn about the svn settings of the project:

Delete the project from the workspace (keep ""Delete project contents on disk"" unchecked)
File > Import... > General > Existing Projects into Workspace
Browse to the folder containing the original project(s) of interest
Import the projects into your workspace

This seems to have the side effect of subclipse noticing the subversion settings when importing the ""new"" projects into your workspace.
"
44780,"I'm sure there is an easier way, but you could loop through the sysobjects table in the database and grant permissions to any user table objects that exist.  You could then run that multiple times whenever new tables are added.
"
44940,"The only CIL book on my shelf is Expert .NET 2.0 IL Assembler by Serge Lidin.  In terms of what the individual opcodes do or mean, the Microsoft documentation on System.Reflection.Emit has some pretty good information.  And it's always useful to look at existing IL with Reflector.
Edit: CIL (and indeed the CLR in general) has not changed at all between .NET 2.0 and .NET 3.5 -- the underlying runtime is basically the same, modulo fixes and performance improvements.  So there's nothing newer available on a CIL level than what would be in a book on 2.0
"
44980,"I hadn't found this before, but from any application you can hookup a SessionSwitchEventHandler. Obviously your application will need to be running, but so long as it is:
    Microsoft.Win32.SystemEvents.SessionSwitch += new Microsoft.Win32.SessionSwitchEventHandler(SystemEvents_SessionSwitch);

    void SystemEvents_SessionSwitch(object sender, Microsoft.Win32.SessionSwitchEventArgs e)
    {
        if (e.Reason == SessionSwitchReason.SessionLock)
        { 
            //I left my desk
        }
        else if (e.Reason == SessionSwitchReason.SessionUnlock)
        { 
            //I returned to my desk
        }
    }

"
45030,"int.TryParse is probably a tad easier:
public static int? ToNullableInt(this string s)
{
    int i;
    if (int.TryParse(s, out i)) return i;
    return null;
}

Edit @Glenn int.TryParse is ""built into the framework"". It and int.Parse are the way to parse strings to ints.
"
45180,"I'm assuming that you're referring to IIS 6.
Instead of disabling shutdown altogether, maybe you can just increase the amount of time it waits before killing the process.  The server is essentially conserving resources - if your server can stand the resource allocation for a process that mostly sits around doing nothing, then there isn't any harm in letting it be.
As you mentioned, setting the auto-recycling of the process on a memory limit would be a good idea, if the possibility of a memory leak is there.
"
45230,"Another way to go would be to use ssh tunneling (which happens on the client side).
You'd do an ssh command like this:
ssh -L 8022:myinsideserver:22 paul@myoutsideserver

That connects you to the machine that's accessible from the outside (myoutsideserver) and creates a tunnel through that ssh connection to port 22 (the standard ssh port) on the server that's only accessible from the inside.
Then you'd do another ssh command like this (leaving the first one still connected):
ssh -p 8022 paul@localhost

That connection to port 8022 on your localhost will then get tunneled through the first ssh connection taking you over myinsideserver.

There may be something you have to do on myoutsideserver to allow forwarding of the ssh port.  I'm double-checking that now.
Edit
Hmmm.  The ssh manpage says this:  **Only the superuser can forward privileged ports.  **
That sort of implies to me that the first ssh connection has to be as root.  Maybe somebody else can clarify that.
It looks like superuser privileges aren't required as long as the forwarded port (in this case, 8022) isn't a privileged port (like 22).  Thanks for the clarification Mike Stone.
"
45340,"This example uses ASP.NET Routing to implement friendly URLs.  
Examples of the mappings that the application handles are:  
http://samplesite/userid/1234 - http://samplesite/users.aspx?userid=1234
http://samplesite/userid/1235 - http://samplesite/users.aspx?userid=1235 
This example uses querystrings and avoids any requirement to modify the code on the aspx page.  
Step 1 - add the necessary entries to web.config
<system.web>
<compilation debug=""true"">
    	<assemblies>
    		â¦
    		<add assembly=""System.Web.Routing, Version=3.5.0.0,    Culture=neutral, PublicKeyToken=31BF3856AD364E35""/>
    	</assemblies>
    </compilation>
â¦
    <httpModules>
    â¦
        <add name=""UrlRoutingModule"" type=""System.Web.Routing.UrlRoutingModule, System.Web.Routing, Version=3.5.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35"" />
        </httpModules>
</system.web>
<system.webServer>
    â¦
    <modules>
    	â¦
    	<add name=""UrlRoutingModule"" type=""System.Web.Routing.UrlRoutingModule, System.Web.Routing, Version=3.5.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35""/>
    </modules>
    <handlers
â¦   
    	<add name=""UrlRoutingHandler"" preCondition=""integratedMode"" verb=""*"" path=""UrlRouting.axd"" type=""System.Web.HttpForbiddenHandler,                 System.Web, Version=2.0.0.0, Culture=neutral,              PublicKeyToken=b03f5f7f11d50a3a""/>
    </handlers>
</system.webServer>

Step 2 - add a routing table in global.asax
Define the mapping from the friendly URL to the aspx page, saving the requested userid for later use.  
void Application_Start(object sender, EventArgs e)
{
    RegisterRoutes(RouteTable.Routes);
}

public static void RegisterRoutes(RouteCollection routes)
{
    routes.Add(""UseridRoute"", new Route
    (
       ""userid/{userid}"",
       new CustomRouteHandler(""~/users.aspx"")
    ));
}

Step 3 - implement the route handler
Add the querystring to the current context before the routing takes place.  
using System.Web.Compilation;
using System.Web.UI;
using System.Web;
using System.Web.Routing;

public class CustomRouteHandler : IRouteHandler
{
    public CustomRouteHandler(string virtualPath)
    {
        this.VirtualPath = virtualPath;
    }

    public string VirtualPath { get; private set; }

    public IHttpHandler GetHttpHandler(RequestContext
          requestContext)
    {
        // Add the querystring to the URL in the current context
        string queryString = ""?userid="" + requestContext.RouteData.Values[""userid""];
        HttpContext.Current.RewritePath(
          string.Concat(
          VirtualPath,
          queryString)); 

        var page = BuildManager.CreateInstanceFromVirtualPath
             (VirtualPath, typeof(Page)) as IHttpHandler;
        return page;
    }
}

Code from users.aspx
The code on the aspx page for reference.  
protected void Page_Load(object sender, EventArgs e)
{
    string id = Page.Request.QueryString[""userid""];
    switch (id)
    {
        case ""1234"":
            lblUserId.Text = id;
            lblUserName.Text = ""Bill"";
            break;
        case ""1235"":
            lblUserId.Text = id;
            lblUserName.Text = ""Claire"";
            break;
        case ""1236"":
            lblUserId.Text = id;
            lblUserName.Text = ""David"";
            break;
        default:
            lblUserId.Text = ""0000"";
            lblUserName.Text = ""Unknown"";
            break;
}

"
45400,"I would use Subversion (in fact I use it) [update: Jul 2014 -- I use Git -- see end of the answer].
SVN is:

free,  
good enough (see disadvantages below),  
simple,  
works fine on Windows (and Linux too), 
a lot of people use it so it's easy to get help, 
can integrate with most of IDEs i.e. Visual Studio (i.e. ankhsvn or VisualSVN -- more info) or Eclipse (i.e. Subclipse -- here someone asked about that).

I would strongly recommended separate machine to source control server. At best somewhere on the cloud. Advantages:

You don't lost your source control repositories if your development box dies.
You don't have to worry about maintenance of one more box.

There are companies which host SVN repositories.
Here are links to SVN (client and server) packages for various operating systems.
Disadvantages of SVN
I am using SVN on Windows machine for about 5 years and found that SVN has a few disadvantages :).
It is slow on large repositories
SVN (or its client -- TortoiseSVN) has one big disadvantage -- it terrible slow (while updating or committing) on large (thousands of files) repositories unless you have SSD drive.
Merging can be difficult
Many people complain about how hard merging is with SVN.
I do merging for about 4 years (including about 2 years in CVS -- that was terrible, but doable) and about 2 years with SVN.
And personally I don't find it hard -- on the other hand -- any merge is easy after merging branches in CVS :).
I do merge of large repository (two repositories in fact) once a week and rarely I have conflicts which are hard to solve (most of conflicts are solved automatically with diff software which I use).
However in case of project of a few developers merging should not be problem at all if you keep a few simple rules:

merge changes often,
avoid active development in various branches simultaneously.

Added in July 2011
Many devs recommended Distributed Version Control like Git or Mercurial.
From single developer perspective there are only a few important advantages of DVCS over SVN:

DVCS can be faster.
You can commit to local repository without access to central one.
DVCS is hot thing and fancy to use/learn (if someone pay for your learning).

And I don't think merging is a problem in case of single developer.
Joel Spolsky wrote tutorial about Mercurial which is definitively worth to read.
So, despite of many advantages of DVCS I would stay with SVN if merging or speed is not a problem.
Or try Mercurial, which according to this and this SO questions, is better supported (in July 2011) on Windows.
Added in July 2014
For about a year I use Git (Git Bash mainly) for my pet-projects (i.e. solving Euler problems) and local branches for each Euler problem are really nice feature -- exactly as it is described as advantage of DVCS. 
Today Git tooling on Windows is much, much better then 2 or more years ago.
You can use remote repo (like GitHub or ProjectLocker and many others) to keep 
copy of your project away from your workstation with no extra effort/money.
However I use GUI client only to looks at diffs (and sometimes to choose files to commit),
so it's better to not afraid of command line -- it's really nice.
So as of today I would go with Git.
"
45470,"I'll tell you right now that Catalyst has by far the best reputation amongst Perl developers in terms of a rapid application development MVC framework. 
In terms of ""pure"" MVC I'm not sure there are even that many ""mature"" or at least production-ready alternatives.
If Catalyst doesn't seem right to you, then you could build upon the lightweight framework CGI::Application to suit your needs or take a look at some of the lesser known MVC frameworks like PageKit and Maypole.
"
45500,"You could perhaps take a look at the software described here. It is a gnome applet, written in Python.
From the web site:
""The gnome wacom applet is a small gnome panel applet that shows how much pressure is being applied to your wacom tablet by the current device. Clicking on the panel icon brings up a dialog allowing you to select a different device and check what pressure and tilt information is being recieved from it. This dialog also contains a small drawing test area to give your pen a quick test.""
Google is your friend
"
45510,"Intenta de esta manera (Try this way):
Var
 obj: Variant
 va: MyVariableType;
Begin
 //Starting
 ExtractTemporaryFile('MyDll.dll');
 RegisterServer(False, ExpandConstant('{tmp}\MyDll.dll'), False);
 obj := CreateOleObject('MyDll.MyClass');
 //Using
 va := obj.MyFunction();
 //Finishing
 UnregisterServer(False, ExpandConstant('{tmp}\MyDll.dll'), False);
 DeleteFile('{tmp}\MyDll.dll');
End;

Suerte (good luck)
"
45540,"I believe you want:
if 'normal' != root.state():
    tkMessageBox.showinfo(""Key you!"", "" "".join(sys.argv[1:]))

"
45600,"I think it is because you have the classes different.
<div id=""SERVICE03_DLG"" class=""flora"">  (flora)
<div id=""SERVICE03_DLG"" class=""ui-dialog""> (custom)
Even with the flora theme, you would still use the ui-dialog class to define it as a dialog.
I've done modals before and I've never even defined a class in the tag.  jQueryUI should take care of that for you.
Try getting rid of the class attribute or using the ""ui-dialog"" class.
"
45650,"Right click on a project, select Add->Existing Item->Add as link (press on small arrow on Add button)
"
45950,"If you use TextMate, there are plugins available such as http://ditchnet.org/xmlmate/
"
46030,"I also had trouble activating and bringing a window to the foreground. Here is the code that eventually worked for me. I'm not sure if it will solve your problem.
Basically, call ShowWindow() then SetForegroundWindow().
using System.Diagnostics;
using System.Runtime.InteropServices;

// Sets the window to be foreground
[DllImport(""User32"")]
private static extern int SetForegroundWindow(IntPtr hwnd);

// Activate or minimize a window
[DllImportAttribute(""User32.DLL"")]
private static extern bool ShowWindow(IntPtr hWnd, int nCmdShow);
private const int SW_SHOW = 5;
private const int SW_MINIMIZE = 6;
private const int SW_RESTORE = 9;

private void ActivateApplication(string briefAppName)
{
    Process[] procList = Process.GetProcessesByName(briefAppName);

    if (procList.Length > 0)
    {
        ShowWindow(procList[0].MainWindowHandle, SW_RESTORE);
        SetForegroundWindow(procList[0].MainWindowHandle);
    }
}

"
46080,"Check out section 5.14.2. Moving files and folders (or check out ""move"" in the Index of the help) of the TortoiseSVN help. You do a move via right-dragging. It also mentions that you need to commit from the parent folder to make it ""one"" revision. This works for doing the change in a working copy.
(Note that the SVN items in the following image will only show up if the destination folder has already been added to the repository.)

You can also do the move via the Repo Browser (section 5.23. The Repository Browser
 of the help).
"
46130,"var q = from x in list
        group x by x.Bar into g
        select g;

foreach (var group in q)
{
    Console.WriteLine(""Group "" + group.Key);
    foreach (var item in group)
    {
        Console.WriteLine(item.Bar);
    }
}

"
46160,"Unless your string is limited in length, you can't avoid collisions. 
There are 4294967296 possible values for an integer (2^32). If you have a string of more than 4 ASCII characters, or more than two unicode characters, then there are more possible string values than possible integer values. You can't have a unique integer value for every possible 5 character string. Long values have more possible values, but they would only provide a unique value for every possible string of 8 ASCII characters.
Hash codes are useful as a two step process: first see if the hash code matches, then check the whole string. For most strings that don't match, you only need to do the first step, and it's really fast.
"
46220,"(This isn't really iPhone specific - the same thing will happen in regular Cocoa).
NSUnknownKeyException is a common error when using Key-Value Coding to access a key that the object doesn't have.
The properties of most Cocoa objects can be accessing directly:
[@""hello world"" length]    // Objective-C 1.0
@""hello world"".length      // Objective-C 2.0

Or via Key-Value Coding:
[@""hello world"" valueForKey:@""length""]

I would get an NSUnknownKeyException if I used the following line:
[@""hello world"" valueForKey:@""purpleMonkeyDishwasher""]

because NSString does not have a property (key) called 'purpleMonkeyDishwasher'.
Something in your code is trying to set a value for the key 'kramerImage' on an UIView, which (apparently) doesn't support that key.  If you're using Interface Builder, it might be something in your nib.
Find where 'kramerImage' is being used, and try to track it down from there.
"
46280,"I guess it depends on the technology you select. For web projects in general I've always employed (Web-)MVC for the past two years or so. The advantage being a clear seperation of frontend and backend in order to create a managable code base.
But that's as vague as a recommendation could be. :)
Aside from using a framework to build your site from scratch, you might also want to look into using what's already out there (in terms of open source). I'd recommend any kind of ""community software"" that's semi-established, well documented, not too often in the news because of security issues and offers API to extend its base. That could indeed jump start you on your facebook-esque site. ;)
"
46350,"@Jason, yep, <center> works. Good times. I'll propose the following, though:
  <!DOCTYPE html PUBLIC ""-//W3C//DTD HTML 4.01//EN"">
  <html>
     <head>
        <style type=""text/css"">
           body
           {
              text-align: center;
           }

           div.my-centered-content
           {
              margin: 0 auto; /* Centering */
              display: inline;
           }
        </style>
        <title></title>
     </head>
     <body>
        <div class=""my-centered-content"">
           <p>test</p>
           <p>test</p>
        </div>
     </body>
  </html>

EDIT @Santi, a block-level element will fill the width of the parent container, so it will effectively be width:100% and the text will flow on the left, leaving you with useless markup and an uncentered element. You might want to try display: inline-block;. Firefox might complain, but it's right. Also, try adding a border: solid red 1px; to the CSS of the .my-centered-content DIV to see what's happening as you try these things out.
"
46380,"SQL*Plus does tell you the table that doesn't exist. For example:
SQL> select
  2     *
  3  from
  4     user_tables a,
  5     non_existent_table b
  6  where
  7     a.table_name = b.table_name;
   non_existent_table b
   *
ERROR at line 5:
ORA-00942: table or view does not exist

Here it shows that the name of the missing table and the line number in the SQL statement where the error occurs.
Similarly, in a one-line SQL statement you can see the asterisk highlighting the name of the unknown table:
SQL> select * from user_tables a, non_existent_table b where a.table_name = b.table_name;
select * from user_tables a, non_existent_table b where a.table_name = b.table_name
                             *
ERROR at line 1:
ORA-00942: table or view does not exist

In terms of your question, I guess the reason the error message doesn't include the name of the table is that the error message itself needs to be static text. The line number and location in the line of the error is clearly passed back to SQL*Plus (somehow).
"
46860,"You will need to use some P/Inovke interop code to do this. Look for the Win32 API SendMessage function and the EM_SETCUEBANNER message.
"
46930,"It will take some training and some time to learn the style needed to develop maintainable code.
Coming from Java/C#/C++, you probably have a good idea of good software architecture. Now you just need to learn the peculiarities of LabView and the common pitfalls.
For the basics, National Instruments offers training courses. See if your new employer can send you to a Basics I/II class to get your feet wet.  They offer some online classes as well.  Following classes, you can sign up to take tests for certification.
Get an evaluation copy of Labview from National Instruments;  they have a well maintained help file that you can dive right into, with example code included.  Look at ""Getting Started"" and ""LabVIEW Environment"".  You should be able to jump right in and become familiar with the dev environment pretty quickly.
LabVIEW, being graphical is nice, but don't throw out your best practices from an application design point of view.  It is common to end up with code looking like rainbow sphaghetti, or code that stretches several screens wide.  Use subvi's and keep each vi with a specific purpose and function.   
The official NI support forums and knowledgebase are probably the best resources out there at the moment.
Unofficial sites like Tutorials in G have a subset of the information found on the official site and documentation, but still may be useful for cross reference if you get stuck.
Edit: Basics I/II are designed to be accessible to users without prior software development experience.  Depending on how you feel after using the evaluation version, you may be able to move directly into Intermediate I/II.  NI has the course outlines available on their website as well, so you know what you're going to cover in each.
"
47210,"The official answer is no, there is not a dedicated Mac client, other than Safari :)
There's a command line version that runs on Linux, Windows, and Mac.
There are also plans for an iPhone version although I'm not technically supposed to announce features before they are done or even spec'd so pretend I didn't say that.
"
47340,"SVN doesn't require any prerequisites on end user machine. You can embed SVN right into you app. To learn more on subversion integration, visit ""Application Integration/Embedding"" thread on SVN forum.
"
47400,"I appreciated knox's and david's answers. My answer will be somewhere between theirs: just make forms that do not need to be debugged!
I think that forms should be exclusively used as what they are basically, meaning graphic interface only, meaning here that they do not have to be debugged! The debugging job is then limited to your VBA modules and objects, which is a lot easier to handle. 
There is of course a natural tendency to add VBA code to forms and/or controls, specially when Access offers you these great ""after Update"" and ""on change"" events, but I definitely advise you not to put any form or control specific code in the form's module. This makes further maintenance and upgrade very costy, where your code is split between VBA modules and forms/controls modules.
This does not mean you cannot use anymore this AfterUpdate event! Just put standard code in the event, like this:
Private Sub myControl_AfterUpdate()  
    CTLAfterUpdate myControl
    On Error Resume Next
    Eval (""CTLAfterUpdate_MyForm()"")
    On Error GoTo 0  
End sub

Where:

CTLAfterUpdate is a standard procedure run each time a control is updated in a form
CTLAfterUpdateMyForm is a specific procedure run each time a control is updated on MyForm

I have then 2 modules. The first one is 

utilityFormEvents
 where I will have my CTLAfterUpdate generic event

The second one is 

MyAppFormEvents
 containing the specific code of all specific forms of the MyApp application
 and including the CTLAfterUpdateMyForm procedure. Of course, CTLAfterUpdateMyForm
 might not exist if there are no specific code to run. This is why we turn the 
 ""On error"" to ""resume next"" ...

Choosing such a generic solution means a lot. It means you are reaching a high level of code normalization (meaning painless maintenance of code). And when you say that you do not have any form-specific code,  it also means that form modules are fully standardized, and their production can be automated: just say which events you want to manage at the form/control level, and define your generic/specific procedures terminology.
Write your automation code, once for all.
It takes a few  days of work but it give exciting results. I have been using this solution for the last 2 years and it is clearly the right one: my forms are fully and automatically created from scratch with a ""Forms Table"", linked to a ""Controls Table"".
I can then spend my time working on the specific procedures of the form, if any.
Code normalization, even with MS Access, is a long process. But it is really worth the pain!
"
47420,"You want to break when there's any exception thrown or just uncaught exceptions?  Because I think the latter is already the default behavior.
You probably know this, but you get the stack trace by typing 'us' (unwind stack) at the prompt.  Just trying to eliminate the obvious.
Anyway, I've never had to use onex.  Never even heard of it.  Another thing you could try is forcing execution to stop by putting in asserts.
"
47780,"You might try using the nm tool.  Given the right options, it will look at a binary (archive or linked image) and tell you what objects were linked into it.
Actually, here's a one-liner I use at work:
#!/bin/sh

nm -Ag $* | sed 's/^.*\/\(.*\.a\):/\1/' | sort -k 3 | grep -v ' U '

to find the culprits for undefined symbols.  Just chop off the last grep expression and it should pretty much give you what you want.
"
47960,"There's plenty of code snippets within Visual Studio for basic programming structure but I wouldn't necessarily rate one higher than another. 
I would definitely say the best ones are the custom snippets you define yourself to accomplish more specific tasks that you may find yourself using on a regular basis. Definitely a big time saver. 
A fairly basic intro to creating custom snippets can be found at http://www.15seconds.com/issue/080724.htm to help with this.
"
47980,"You can try the following tool to make things more sane:
http://www.bdsoft.com/tools/stlfilt.html
"
48070,"How do you handle Session State?  There is a built-in ""store the viewstate in the session state"" provider.  If you are storing the session state in some fast, out of proc system, that might be the best option for the viewstate.
edit: to do this add the following code to the your Page classes / global page base class
    protected override PageStatePersister PageStatePersister {
        get { return new SessionPageStatePersister(this); }
    }

Also... this is by no means a perfect (or even good) solution to a large viewstate.  As always, minimize the size of the viewstate as much as possible.  However, the SessionPageStatePersister is relatively intelligent and avoids storing an unbounded number of viewstates per session as well as avoids storing only a single viewstate per session.
"
48110,"You can generally twist a code coverage tool's arm and get a report that shows the paths that have been executed during a given run.  This report should show the code itself, with the first few columns marked up according to the coverage tool's particular notation on whether a given path was executed.
You might be able to use this straight up, or you might have to preprocess it and either remove the code that was not executed, or add a new notation on each line that tells whether it was executed (most tools will only show path information at control points):
So from a coverage tool you might get a report like this:
T- if(sometest)
   {
x     somecode;
   }
   else
   {
-     someother_code;
   }

The notation T- indicates that the if statement only ever evaluated to true, and so only the first part of the code executed.  The later notation 'x' indicates that this line was executed.
You should be able to form a regex that matches only when the first column contains a T, F, or x so you can capture all the control statements executed and lines executed.
Sometimes you'll only get coverage information at each control point, which then requires you to parse the C file and mark the execute lines yourself.  Not as easy, but not impossible either.
Still, this sounds like an interesting question where the solution is probably more work than it's worth...
"
48240,"If I get it right, you (should) have 2 models. A Route model, and a Stop model.
Here's how I would define these models:
class Route < ActiveRecord::Base
  has_and_belongs_to_many :stops
  belongs_to :stop, :foreign_key => 'destination_id'
end

class Stop < ActiveRecorde::Base
  has_and_belongs_to_many :routes
end

And here's how I would set up my tables:
create_table :routes do |t|
  t.integer :destination_id
  # Any other information you want to store about routes
end

create_table :stops do |t|
  # Any other information you want to store about stops
end

create_table :routes_stops, :primary_key => [:route_id, :stop_id] do |t|
  t.integer :route_id
  t.integer :stop_id
end

Finally, here's the code I'd use:
# First, find all the relevant routes, just for caching.
Route.find(numbers)

r = Route.find(number)
r.destination_id = destination
r.stops << stop

This should use only a few SQL queries.
"
48250,"The Eclipse Web Tools Platform Project includes a JSP debugger. I have only ever needed to use it with Tomcat so I cannot say how well it works with other servlet containers.
"
48320,"It depends what your priorities are.
If you really want to learn RoR, do it all from scratch. Seriously. Roll your own. It's the best way to learn, far better than hacking through someone else's code. If you do that, sometimes you'll be learning Rails, but sometimes you'll just be learning that specific social network framework. And you won't know which is which...
The type of site you're suggesting sounds perfect for a Rails project. If you get stuck, then go browse the repositories of these frameworks. Who cares if you're reinventing the wheel? It's your site, your vision, your rules.
If you just want a site up and running, then I would pick Insoshi or LovdbyLess simply because they're out of the box apps so you'll have to do less to do get running. I suggest trying to install them both, and introducing yourself in the Google Groups. That'll give you a good indication of wether you're going to get along.
"
48340,"Are you consuming the WCF service from Silverlight? If so, a special configuration is needed to make the service return a HTTP 200 code instead of 500 in case of error. The details are here: http://msdn.microsoft.com/en-us/library/dd470096%28VS.96%29.aspx
"
48390,"The CDT version of Ganymede apparently shipped improperly configured.  After playing around for a while, I have come up with the following steps that fix the problem.

Export your Eclipse preferences (File > Export > General > Preferences).
Open the exported file in a text editor.
Find the line that says
/instance/org.eclipse.ui.editors/spellingEngine=org.eclipse.jdt.internal.ui.text.spelling.DefaultSpellingEngine
Change it to
/instance/org.eclipse.ui.editors/spellingEngine=org.eclipse.cdt.internal.ui.text.spelling.CSpellingEngine
Save the preferences file.
Import the preferences back into Eclipse (File > Import > General > Preferences).

You should now be able to access the Spelling configuration page as seen above.
Note: if you want to add a custom dictionary, Eclipse must be able to access and open the file (i.e. it must exist - an empty file will work)
"
48470,"This will disable the pop up:
For Visual Studio 2008:
HKEY_CURRENT_USER\Software\Microsoft\VisualStudio\8.0
DWORD DontShowMacrosBalloon=6
For Visual Studio 2010 (the DWORD won't be there by default, use New | DWORD value to create it):
HKEY_CURRENT_USER\Software\Microsoft\VisualStudio\10.0
DWORD DontShowMacrosBalloon=6
Delete the same key to re-enable it.
"
48550,"The ""Publish"" target you are trying to invoke is for ""OneClick"" deployment, not for publishing a website...  This is why you are getting the seemingly bizarre message. 
You would want to use the AspNetCompiler task, rather than the MSBuild task.  See http://msdn2.microsoft.com/en-us/library/ms164291.aspx for more info on this task.  Your ""PublishDir"" would correspond to the TargetPath property of the task. 
Source
"
48570,"(Apart from the observer pattern) you can also use call_user_func() or call_user_func_array().
If you pass an array(obj, methodname) as first parameter it will invoked as $obj->methodname().

<?php
class Foo {
    public function bar($x) {
        echo $x;
    }
}

function xyz($cb) {
    $value = rand(1,100);
    call_user_func($cb, $value);
}

$foo = new Foo;
xyz( array($foo, 'bar') );

"
48680,"The following is the solution:
private void frmMainLoad(object sender, EventArgs e)
{
    ActiveControl = textBox1;
}

The better question would however be why... I'm not entirely sure what the answer to that one is.
Edit: I suspect it is something to do with the fact that both the form, and the TabControl are containers, but I'm not sure.
"
49080,"Third post under visualstudio tag
"
49110,"See: this site
    for i in $(seq 1 10);
    do
            echo $i
    done

"
49220,"The type of collection to use in your mapping depends on how you want to represent the collection in code. The settings map like so:

The <list> maps directly to an
IList.
The <map> maps directly to an IDictionary.
The <bag> maps to an IList. A  does not completely comply
with the IList interface because the
Add() method is not guaranteed to
return the correct index. An object
can be added to a <bag> without
initializing the IList. Make sure to
either hide the IList from the
consumers of your API or make it
well documented.
The <set> maps to an Iesi.Collections.ISet. That
interface is part of the
Iesi.Collections assembly
distributed with NHibernate.

so if you want an IList to be returned, then you would use the <list> mapping. In your case, I'd probably map using the <list> mapping.
"
49260,"If I understand your problem correctly, you simply change the database's connection string in your app.config / web.config.
Edit, post clarification: You have the connection strings stored somewhere. They might be in the app.config of your server. Still, you get them from somewhere and that somewhere may be in an app.config. Use that then :)
"
49330,"VS2005 and VS2008 use different STL implementations. When the VS2005 code returns a vector, the object has memory layout different from what VS2008 expects. That should be the reason for the broken values you see in the returned date.
As a rule of thumb, you should always compile all C++ modules of a project with the same compiler and all settings/#defines equal.
One particular #define that causes similar behaviour is the SECURE_SCL #define of VS2008. Two modules compiled with different settings will create exactly your problems, because #defining SECURE_SCL introduces more member variables to various C++ library classes.
"
49350,"From http://www.webmonkey.com/codelibrary/Center_a_DIV
#horizon        
    {
    text-align: center;
    position: absolute;
    top: 50%;
    left: 0px;
    width: 100%;
    height: 1px;
    overflow: visible;
    display: block
    }

#content    
    {
    width: 250px;
    height: 70px;
    margin-left: -125px;
    position: absolute;
    top: -35px;
    left: 50%;
    visibility: visible
    }

<div id=""horizon"">
   <div id=""content"">
      <p>This text is<br><emphasis>DEAD CENTRE</emphasis ><br>and stays there!</p>
   </div><!-- closes content-->
</div><!-- closes horizon-->

"
49430,"The flow you are seeing is something like this:

Click on button
AnimationExtender catches action and call clickOn callback
linkPostback starts asynchronous request for page and then returns flow to AnimationExtender
Animation begins
pageRequest returns and calls playAnimation, which starts the animation again

I think there are at least two ways around this issue.  It seems you have almost all the javascript you need, you just need to work around AnimationExtender starting the animation on a click.
Option 1: Hide the AnimationExtender button and add a new button of your own that plays the animation.  This should be as simple as setting the AE button's style to ""display: none;"" and having your own button call linkPostback().
Option 2: Re-disable the Animation Extender once the animation has finished with.  This should work, as long as the playAnimation call is blocking, which it probably is:
function linkPostback() {

    var prm = Sys.WebForms.PageRequestManager.getInstance();
    prm.add_endRequest(playAnimation)
}

function playAnimation() {

    AnimationExtender.Enabled = true;
    var onclkBehavior = $find(""ctl00_btnOpenList"").get_OnClickBehavior().get_animation();
    onclkBehavior.play();
    AnimationExtender.Enabled = false;
}

As an aside, it seems your general approach may face issues if there is a delay in receiving the pageRequest.  It may be a bit weird to click a button and several seconds later have the animation happen.  It may be better to either pre-load the data, or to pre-fill the div with some ""Loading..."" thing, make it about the right size, and then populate the actual contents when it arrives.
"
49450,"If you want to move the repository and keep history, you'll probably need filesystem access on both hosts.  The simplest solution, if your backend is FSFS (the default on recent versions), is to make a filesystem copy of the entire repository folder.
If you have a Berkley DB backend, if you're not sure of what your backend is, or if you're changing SVN version numbers, you're going to want to use svnadmin to dump your old repository and load it into your new repository.  Using svnadmin dump will give you a single file backup that you can copy to the new system.  Then you can create the new (empty) repository and use svnadmin load, which will essentially replay all the commits along with its metadata (author, timestamp, etc).
You can read more about the dump/load process here:
http://svnbook.red-bean.com/en/1.8/svn.reposadmin.maint.html#svn.reposadmin.maint.migrate
Also, if you do svnadmin load, make sure you use the --force-uuid option, or otherwise people are going to have problems switching to the new repository.  Subversion uses a UUID to identify the repository internally, and it won't let you switch a working copy to a different repository.
If you don't have filesystem access, there may be other third party options out there (or you can write something) to help you migrate: essentially you'd have to use the svn log to replay each revision on the new repository, and then fix up the metadata afterwards.  You'll need the pre-revprop-change and post-revprop-change hook scripts in place to do this, which sort of assumes filesystem access, so YMMV.  Or, if you don't want to keep the history, you can use your working copy to import into the new repository.  But hopefully this isn't the case.
"
49500,"You should have a look at the URL Rewriting Guide from the apache documentation.
The following is untested, but it should to the trick:
RewriteCond %{HTTP_HOST} ^([^.]+)\.blah\.domain\.com$
RewriteRule ^/(.*)$           http://blah.domain.com/%1/$1 [L,R] 

This only works if the subdomain contains no dots. Otherwise, you'd have to alter the Regexp in RewriteCond to match any character which should still work due to the anchoring, but this certainly feels safer.
"
49510,"There are four steps to making an app that can act as the default web browser. The first three steps allow your app to act as a role handler for the relevant URL schemes (HTTP and HTTPS) and the final step makes it the default role handler for those schemes.
1) Add the URL schemes your app can handle to your application's info.plist file
To add support for http:// and https:// you'd need to add the following to your application's info.plist file. This tells the OS that your application is capable of handling HTTP and HTTP URLs.
<key>CFBundleURLTypes</key>
<array>
    <dict>
        <key>CFBundleURLName</key>
        <string>http URL</string>
        <key>CFBundleURLSchemes</key>
        <array>
            <string>http</string>
        </array>
    </dict>
    <dict>
        <key>CFBundleURLName</key>
        <string>Secure http URL</string>
        <key>CFBundleURLSchemes</key>
        <array>
            <string>https</string>
        </array>
    </dict>
</array>

2) Write an URL handler method
This method will be called by the OS when it wants to use your application to open a URL. It doesn't matter which object you add this method to, that'll be explicitly passed to the Event Manager in the next step. The URL handler method should look something like this:
- (void)getUrl:(NSAppleEventDescriptor *)event 
    withReplyEvent:(NSAppleEventDescriptor *)replyEvent
{
  // Get the URL
  NSString *urlStr = [[event paramDescriptorForKeyword:keyDirectObject] 
    stringValue];

  //TODO: Your custom URL handling code here
}

3) Register the URL handler method
Next, tell the event manager which object and method to call when it wants to use your app to load an URL. In the code here I'm passed self as the event handler, assuming that we're calling setEventHandler from the same object that defines the getUrl:withReplyEvent: method.
You should add this code somewhere in your application's initialisation code.
NSAppleEventManager *em = [NSAppleEventManager sharedAppleEventManager];
[em 
  setEventHandler:self 
  andSelector:@selector(getUrl:withReplyEvent:) 
  forEventClass:kInternetEventClass 
  andEventID:kAEGetURL];

Some applications, including early versions of Adobe AIR, use the alternative WWW!/OURL AppleEvent to request that an application opens URLs, so to be compatible with those applications you should also add the following:
[em
  setEventHandler:self 
  andSelector:@selector(getUrl:withReplyEvent:) 
  forEventClass:'WWW!' 
  andEventID:'OURL'];

4) Set your app as the default browser
Everything we've done so far as told the OS that your application is a browser, now we need to make it the default browser.
We've got to use the Launch Services API to do this. In this case we're setting our app to be the default role handler for HTTP and HTTPS links:
CFStringRef bundleID = (CFStringRef)[[NSBundle mainBundle] bundleIdentifier];
OSStatus httpResult = LSSetDefaultHandlerForURLScheme(CFSTR(""http""), bundleID);
OSStatus httpsResult = LSSetDefaultHandlerForURLScheme(CFSTR(""https""), bundleID);
//TODO: Check httpResult and httpsResult for errors

(It's probably best to ask the user's permission before changing their default browser.)
Custom URL schemes
It's worth noting that you can also use these same steps to handle your own custom URL schemes. If you're creating a custom URL scheme it's a good idea to base it on your app's bundle identifier to avoid clashes with other apps. So if your bundle ID is com.example.MyApp you should consider using x-com-example-myapp:// URLs.
"
49610,"Viva64 (http://www.viva64.com/viva64-tool/) tool provides detection of errors typical of 64-bit Windows applications. Viva64 is a lint-like static analyzer of C/C++ code. Viva64 integrates into Visual Studio 2005/2008 environment and provides user-friendly interface to test your software projects.
"
49630,"I'd give the container div:
position: relative;

and add a third div in the container (should be the last child of the container) with:
position: absolute;
top: 0;
bottom: 0;
left: 0;
right: 0;

and catch the mouseover and mouseout events on this div instead.
Because it has no child elements, you shouldn't get spurious mouseover and mouseout events propagating to it.
Edit:
What I believe happens, is that when the cursor moves from a parent element onto a child element, a mouseout event occurs on the parent element, and a mouseover event occurs on the child element. However, if the mouseover handler on the child element does not catch the event and stop it propagating, the parent element will also receive the mouseover event.
"
49790,"The HTML specs are a bit vague (ie. completely lacking) with regard to this odd combination. They do say that a form element with the disabled attribute set should not be successful, so it really can't be selected.
The browser may well render it so that it looks selected, but it shouldn't show up in the POSTed data. Looks like Opera's got it right to me.
"
49870,"This is a great free resource by Joseph Albahari. Threading in C#
"
49900,"I would suggest to work with macros over subant/antcall because the main advantage I found with macros is that you're in complete control over the properties that are passed to the macro (especially if you want to add new properties).
You simply refactor your Ant script starting with your target:
<target name=""vss.check"">
    <vssadd localpath=""D:\build\build.00012.zip"" 
        comment=""Added by automatic build""/>
</target>

creating a macro (notice the copy/paste and replacement with the @{file}):
<macrodef name=""private-vssadd"">
    <attribute name=""file""/>
    <sequential>
        <vssadd localpath=""@{file}"" 
            comment=""Added by automatic build""/>
    </sequential>
</macrodef>

and invoke the macros with your files:
<target name=""vss.check"">
    <private-vssadd file=""D:\build\File1.zip""/>
    <private-vssadd file=""D:\build\File2.zip""/>
</target>

Refactoring, ""the Ant way""
"
49950,"If a class has a Dispose method the best practice is to call it. the reason
behind that is that Dispose runs when called, whereas setting the object to
null simply adds a entry to the Finalize queue in GC, and we cannot
determine when GC will run.
There is no performance benefit in implementing the Dispose method on types that use only managed resources (such as arrays) because they are automatically reclaimed by the garbage collector. Use the Dispose method primarily on managed objects that use native resources and on COM objects that are exposed to the .NET Framework. Managed objects that use native resources (such as the FileStream class) implement the IDisposable interface.
An elegant means of inoking Dispose that have adopted is using the ""using"" construct. For those of you who may not be familiar with the construct, it provide a means to implicity invoke Dispose() on an instance that implements IDisposable even if an exception is thrown durring the operation. The following is an example of the using construct: 
using(DisposableClass dc = new DisposableClass()) 
{ 
   dc.PerformActionOnUmanagedResources(); 
   dc.PerformAnotherActionOnUmanagedResources(); 
}

In the previous example, if an exception was thrown in the PerformActionOnUmanagedResources() method, although the PerformAnotherActionOnUmanagedResources() method would not be processed, the using block will still implicity invoke the Dispose method on dc ensuring the realese of any unmanaged resources.
"
50120,"
Microsoft ODBC.
The MFC ODBC classes such as CDatabase.
OleDB (via COM).
And you can always go through the per-RDBMS native libraries (for example, the SQL Server native library)
DAO (don't).
3rd party ORM providers.

I would recommend going through ODBC or OleDB by default. Native libraries really restrict you, DAO is no fun, there aren't a lot of great 3rd-party ORM for C++/Windows.
"
50140,"Getting out of control? I think it's already out of control!
Can you not categorise the cases into 'x' general areas and split down into helper routines?
"
50170,"Apparently marker was introduced as a value in CSS 2 but did not make it to CSS 2.1 because of lacking browser support.
I suppose that didnât help its popularity â¦
Source: http://de.selfhtml.org/css/eigenschaften/positionierung.htm#display (German)
"
50280,"Have you tried floating the #right_content div to the right?
#right_content{
  float: right;
  margin-top: 20px;
  width: 400px;
}

"
50310,"In ATL these attributes were a compiler trick. They were not a core part of the platform like attributes in C#. They were also more confusing to debug than macros's and the method of dumping generated attribute code was a hassle.
I suspect another issue is likely to have been C++ compiler compatibility and standards-adherence. Attributes didn't make for more beautiful C++ code, and perhaps this syntax may be used in a future version of a real C++ standard.
"
50330,"You should be able to do both if you implement the IScriptControl interface while also deriving from BaseValidator:
public class YourControl : IScriptControl, BaseValidator

To implement the IScriptControl interface means your control will also have to have the GetScriptReferences and GetScriptDescriptors methods.
"
50430,"The attributes...
position: fixed;
left: 0;
bottom: 0;

...should do the job in every browser except IE. If supporting IE users is important for your site, you need to add some ugly Javascript.
"
50450,"Because there is no '2' or '3' dimension.  Should be .GetLength(1) instead of .GetLength(y)
Also:  in VB.Net array declarations work a little differently.  The subscript you specify in the declaration is the last index, not the number of items created like with C# or C++.   But the array is still 0-indexed like C# or C++, instead of 1-indexed like VB6.  That means that if you move to VB.Net from a different language your array instincts are probably wrong, no matter which language it is.  In VB.Net, Dim arr(3,3) As Integer actually creates a 4x4 array. 
"
50470,"
...I'm worried about the possibility of someone being able to paste some script in and run it there and then, without even sending it back to the server for processing.  
Am I worrying over nothing?

Firefox has a plug-in called Greasemonkey that allows users to arbitrarily run JavaScript against any page that loads into their browser, and there is nothing you can do about it. Firebug allows you to modify web pages as well as run arbitrary JavaScript.
AFAIK, you really only need to worry once it gets to your server, and then potentially hits other users.
"
50650,"The best way is to not get so technical with ""non techical"" people.  Just build it into the delivery time without going into details.  
On the flipside, it sounds like the project deadlines were not realistic to actually build it.
"
50890,"Speedtest.net has a lot of stats broken down by country, region, city and ISP. Not sure about accuracy, since it's only based on the people using their ""bandwidth measurement"" service.
"
50900,"Specifically, like this in C#:
#if (DEBUG)
   Debug Stuff
#endif

C# has the following preprocessor directives:
#if 
#else 
#elif // Else If
#endif
#define
#undef // Undefine
#warning // Causes the preprocessor to fire warning
#error // Causes the preprocessor to fire a fatal error
#line // Lets the preprocessor know where this source line came from
#region // Codefolding
#endregion

"
51010,"Also a little silly, but you could try picking an arbitrary day and embedding each time in it, using datetime.datetime.combine, then subtracting:
>>> import datetime
>>> t1 = datetime.time(2,3,4)
>>> t2 = datetime.time(18,20,59)
>>> dummydate = datetime.date(2000,1,1)
>>> datetime.datetime.combine(dummydate,t2) - datetime.datetime.combine(dummydate,t1)
datetime.timedelta(0, 58675)

"
51050,"
Source: http://stuffthathappens.com/blog/wp-content/uploads/2008/03/simplicity.png
"
51110,"If you can't use the fileinfo extension, and you don't want to use mime_content_type, your options are limited.
Most likely you'll need to do a lookup based on the file extension.  mime_content_type did something a bit more intelligent and actually looked for special data in the file to determine the mime type.
"
51130,"I think nowadays developers are kind of ""dropping out of the demo scene"". In the good old days demos were all about ""what could you technically squeeze out of the machine"". You needed to be a good developer/coder/hacker to achieve the best. Today the development seems to be more like basic technical stuff. Most effects are already provided by the graphics adapter. It's not so much about the code, so as a coder ""you can't show off"". It's more about design, graphics, more design, music and even more design. That's in most cases not the developers' domain :)
However my guess would be that most good and experienced developers today have an history in demo scene, even if it's just a small one (just being interested and astonished).
Wow... PC-GPE still exists? :D
"
51150,"I know this is very old now, but I just stumbled across it, and I know the answer.
In the applications you've seen (and written) where bringing the dialog box to the foreground did not bring the main window up along with it, the developer has simply neglected to specify the owner of the dialog box.
This applies to both modal windows, like dialog boxes and message boxes, as well as to modeless windows.  Setting the owner of a modeless popup also keeps the popup above its owner at all times.
In the Win32 API, the functions to bring up a dialog box or a message box take the owner window as a parameter:
INT_PTR DialogBox(
    HINSTANCE hInstance,
    LPCTSTR lpTemplate,
    HWND hWndParent,      /* this is the owner */
    DLGPROC lpDialogFunc
);

int MessageBox(
    HWND hWnd,            /* this is the owner */
    LPCTSTR lpText,
    LPCTSTR lpCaption,
    UINT uType
);

Similary, in .NET WinForms, the owner can be specified:
public DialogResult ShowDialog(
    IWin32Window owner
)

public static DialogResult Show(
    IWin32Window owner,
    string text
) /* ...and other overloads that include this first parameter */

Additionally, in WinForms, it's easy to set the owner of a modeless window:
public void Show(
    IWin32Window owner,
)

or, equivalently:
form.Owner = this;
form.Show();

In straight WinAPI code, the owner of a modeless window can be set when the window is created:
HWND CreateWindow(
    LPCTSTR lpClassName,
    LPCTSTR lpWindowName,
    DWORD dwStyle,
    int x,
    int y,
    int nWidth,
    int nHeight,
    HWND hWndParent, /* this is the owner if dwStyle does not contain WS_CHILD */
    HMENU hMenu,
    HINSTANCE hInstance,
    LPVOID lpParam
);

or afterwards:
SetWindowLong(hWndPopup, GWL_HWNDPARENT, (LONG)hWndOwner);

or (64-bit compatible)
SetWindowLongPtr(hWndPopup, GWLP_HWNDPARENT, (LONG_PTR)hWndOwner);

Note that MSDN has the following to say about SetWindowLong[Ptr]:

Do not call SetWindowLongPtr with the GWLP_HWNDPARENT index to change the parent of a child window. Instead, use the SetParent function. 

This is somewhat misleading, as it seems to imply that the last two snippets above are wrong.  This isn't so.  Calling SetParent will turn the intended popup into a child of the parent window (setting its WS_CHILD bit), rather than making it an owned window.  The code above is the correct way to make an existing popup an owned window.
"
51180,"This post addresses your question. The gist of it is:
Text Editor > C# > Advanced > Generate XML documentation comments for ///

"
51210,"Nooooo!!! Don't implement method_missing on your controller! And please try to avoid action_missing as well.
The frequently touted pattern is to add a route:
map.connect '*', :controller => 'error', :action => 'not_found'

Where you can show an appropriate error.
Rails also has a mechanism called rescue_action_in_public where you can write your own error handling logic -- we really should clean it up and encourage people to use it. PDI! :-)
"
51320,"http://docs.oracle.com/javase/7/docs/api/java/io/File.html#listRoots()
File[] roots = File.listRoots();
for(int i = 0; i < roots.length ; i++)
    System.out.println(""Root[""+i+""]:"" + roots[i]);

google: list drives java, first hit:-)
"
51380,"1) There might not be that much data available to read (the other end of the pipe might not have sent that much data yet), and the implementing class might be non-blocking (i.e. it will just return what it can, rather than waiting for enough data to fulfil the request).
I don't know if any implementations actually behave in this way, however, but the interface is designed to permit it.
Another option is simply that the file gets closed part-way through the read.
2) Either readFully() (which will always wait for enough input or else fail) or call skipBytes() in a loop.  I think the former is probably better, unless the array is truly vast.
"
51390,"I think Java applets were overshadowed by Flash and ActionScript (pun unintended), being much easier to use for what Java Applets were being used at the time (animations + stateful applications). 
Flash's success in this respect in turn owes to its much smaller file sizes, as well as benefiting from the Sun vs. Microsoft suit that resulted in Microsoft removing the MSJVM from Internet Explorer, at a time of Netscape's demise and IE's heavy dominance.
"
51420,"There is  
Math::log10 (n)

And there is also a property of logarithms that logx(y) = log(y)/log(x) 
"
51470,"Here is a good procedure for resetting any sequence to 0 from Oracle guru Tom Kyte.  Great discussion on the pros and cons in the links below too.
tkyte@TKYTE901.US.ORACLE.COM> 
create or replace
procedure reset_seq( p_seq_name in varchar2 )
is
    l_val number;
begin
    execute immediate
    'select ' || p_seq_name || '.nextval from dual' INTO l_val;

    execute immediate
    'alter sequence ' || p_seq_name || ' increment by -' || l_val || 
                                                          ' minvalue 0';

    execute immediate
    'select ' || p_seq_name || '.nextval from dual' INTO l_val;

    execute immediate
    'alter sequence ' || p_seq_name || ' increment by 1 minvalue 0';
end;
/

From this page: Dynamic SQL to reset sequence value
Another good discussion is also here: How to reset sequences?
"
51500,"Developed ""gut feeling"" is what distinguish beginners from professionals. After you gain some experience ""gut feeling"" becomes one of the main contributors to final decision. It doesn't matter whether you're reviewing somebody's code or creating system architecture, gut feeling guides you. However pragmatic developer must not be too self-assured. There is always a place for check-lists and other means.
As for metrics, I totally agree with you. Metrics is meaningless if it doesn't contribute to code quality.
"
51520,">>> import os
>>> os.path.abspath(""mydir/myfile.txt"")

"
51530,"All code becomes 'legacy' one day, why seperate it at all? Source control is by project/branch or project/platform/branch and that type of hierarchy. Who cares how long in the tooth it is?
"
51540,"I've only recently started looking into this type of thing, but i have found that memory profilers can give quite detailed information regarding instances of objects within your application.
Here are a couple that are worth trying:

ANTS Profiler
.NET Memory Profiler

"
51660,"Your question is simply too broad for a single answer - due to many aspects.
First, meta-modelling is not a set term, but rather a very fuzzy thing, including modelling models of models and reaching out to terms like MDA.
Second, there are numerous options to developing diagram editors - going the Eclipse way is surely a nice option.
To get you at least started in the Eclipse department:

have a look at MOF, that is architecture for ""meta-modelling"" from the OMG (the guys, that maintain UML)
from there approach EMOF, a sub set which is supported by the Eclipse Modelling Framework in the incarnation of Ecore.
building something on top of GMF might be indeed a good idea, because that's the way existing diagram editors for the Eclipse platform take (e.g. Omondo's EclipseUML)
there are a lot of tools existing in the Eclipse environment, that can utilize Ecore - I simply hope, that GMF builts on top of Ecore itself.

"
51680,"OK, here's what I came up with for one of our applications. Note that it doesn't deal with the ""optional value"" scenario you mention, since our optional value is always 0, but it shouldn't be hard for you to modify.
Data is continually added to the series so we just keep the range of y values up to date by inspecting each data point as its added; this is very inexpensive and easy to keep track of. Equal minimum and maximum values are special cased: a spacing of 0 indicates that no markers should be drawn.
This solution isn't dissimilar to Andrew's suggestion above, except that it deals, in a slightly kludgy way with some arbitrary fractions of the exponent multiplier.
Lastly, this sample is in C#. Hope it helps.
    private float GetYMarkerSpacing()
	{
		YValueRange	range	= m_ScrollableCanvas.
                    TimelineCanvas.DataModel.CurrentYRange;
		if ( range.RealMinimum == range.RealMaximum )
		{
			return 0;
		}

		float	absolute	= Math.Max(
                    Math.Abs( range.RealMinimum ),
                    Math.Abs( range.RealMaximum ) ),
			spacing		= 0;
		for ( int power = 0; power < 39; ++power )
		{
			float	temp	= ( float ) Math.Pow( 10, power );
			if ( temp <= absolute )
			{
				spacing	= temp;
			}
			else if ( temp / 2 <= absolute )
			{
				spacing	= temp / 2;
				break;
			}
			else if ( temp / 2.5 <= absolute )
			{
				spacing = temp / 2.5F;
				break;
			}
			else if ( temp / 4 <= absolute )
			{
				spacing	= temp / 4;
				break;
			}
			else if ( temp / 5 <= absolute )
			{
				spacing	= temp / 5;
				break;
			}
			else
			{
				break;
			}
		}

		return spacing;
	}

"
51690,"BEX=Buffer overflow exception. See http://technet.microsoft.com/en-us/library/cc738483.aspx for details. However, c000000d is STATUS_INVALID_PARAMETER; the technet article talks primarily about status c0000005 or c0000409 (access violation/DEP)
"
51700,"At some point, something, somewhere is going to have to use Xml Deserialization, whether it is you or a wrapper inside the settings class. You could always abstract it away in a method to remove the ""ugly"" code from your business logic.
public static T FromXml<T>(string xml)
{
    XmlSerializer xmlser = new XmlSerializer(typeof(T));
    using (System.IO.StringReader sr = new System.IO.StringReader(xml))
    {
        return (T)xmlser.Deserialize(sr);
    }
}

http://www.vonsharp.net/PutDownTheXmlNodeAndStepAwayFromTheStringBuilder.aspx
"
51870,"my #1 way to do this, add white space to the top of the web config file, after the xml declaration tag.
It forces the node to re-cache and recompile. We even have a page deep in the admin called Flush.aspx that does it for us.
"
51950,"InternalsVisibleTo attribute to the rescue!
Just add:  
[assembly:InternalsVisibleToAttribute(""UnitTestAssemblyName"")]

to your Core classes AssemblyInfo.cs file
See Friend Assemblies (C# Programming Guide) for best practices.
"
52080,"For loops
for (i = startValue; i <= endValue; i++) {
    // Before the loop: i is set to startValue
    // After each iteration of the loop: i++ is executed
    // The loop continues as long as i <= endValue is true
}

For...in loops
for (i in things) {
    // If things is an array, i will usually contain the array keys *not advised*
    // If things is an object, i will contain the member names
    // Either way, access values using: things[i]
}

It is bad practice to use for...in loops to itterate over arrays. It goes against the ECMA 262 standard and can cause problems when non-standard attributes or methods are added to the Array object, e.g. by Prototype.
(Thanks to Chase Seibert for pointing this out in the comments)
While loops
while (myCondition) {
    // The loop will continue until myCondition is false
}

"
52140,"In addition to what others have said, Flash is constrained in the ""rectangle"" and cannot be added to a normal html page in an un-obtrusive manner.
@Gulzar I think when more browsers will support the video tag like mozilla 3.1 does we'll see even more adoption of ajax/js over flash.
"
52160,"I think what you are looking for is TypeName rather than TypeOf.
If TypeName(foobar) = ""CommandButton"" Then
   DoSomething
End If

Edit: What do you mean Dynamic Objects?  Do you mean objects created with
CreateObject(""""), cause that should still work.
Edit: 
Private Sub Command1_Click()
    Dim oObject As Object
    Set oObject = CreateObject(""Scripting.FileSystemObject"")
    Debug.Print ""Object Type: "" & TypeName(oObject)
End Sub

Outputs
Object Type: FileSystemObject
"
52290,"On general tips;
We are implementing a process of 
1) Business Requirements Statement (BRS)
2) Functional Specification
3) Technical specification
The BRS covers what the business problems are, and what the requirements are around solutions, testing, security, reliability and delivery. This defines what would make a successful solution.
The functional spec details what is needed, how it should look, how long fields should be, etc.
The technical spec details where the data comes from, any tricky code that may need to be considered.
The customer owns the requirements. The developers own the tech specs, and the functional spec is a middle ground. Testing is done against the tech specs (usually unit testing) then against the functional specs (usually system testing) and then against the requirements (UAT).
The important part of this (and we are struggling with) is that the developers still need to deliver to the functional spec, and the original business requirements. In reality the functional and tech specs are just there for clarity.
In short, my main tip is to first work out the process you wish to implement. Then seek agreement from all parties involved in your proposed process, then work on the templates to fit. The templates themselves are only are a small part of the change you want to make.
"
52360,"Directly from the source:
How to determine which versions and service pack levels of the Microsoft .NET Framework are installed
"
52400,"Table driven designs can be effective. 
Steve Maguire had few nice examples in Writing Solid Code .
They are also a great way to capture tests, see fit .
In your case something like:
Field1ReadonlyRules = {
    'user class 1' : True,
    'user class 2' : False
}

field1.readOnly = Field1ReadonlyRules[ someUser.userClass ]

As an aside you probably want to model both users and user classes/roles/groups instead of combining them.
A user typically captures who (authentication) while groups/roles capture what (permissions, capabilities)
"
52430,"Here is example SQL.  If you have an Identity column, you can use this instead of ""ActivityDate"".
SELECT DATEDIFF(HOUR, prev.ActivityDate, curr.ActivityDate)
  FROM MyTable curr
  JOIN MyTable prev
    ON prev.ObjectID = curr.ObjectID
  WHERE prev.ActivityDate =
     (SELECT MAX(maxtbl.ActivityDate)
        FROM MyTable maxtbl
        WHERE maxtbl.ObjectID = curr.ObjectID
          AND maxtbl.ActivityDate < curr.ActivityDate)

I could remove ""prev"", but have it there assuming you need IDs from it for deleting.
"
52460,"The Microsoft forum has the following code snipit to delete the certificates:
use msdb   
BEGIN TRANSACTION
declare @sp sysname
declare @exec_str nvarchar(1024)    
declare ms_crs_sps cursor global for select object_name(crypts.major_id) from sys.crypt_properties crypts, sys.certificates certs where crypts.thumbprint = certs.thumbprint and crypts.class = 1 and certs.name = '##MS_AgentSigningCertificate##'    
open ms_crs_sps    
fetch next from ms_crs_sps into @sp    
while @@fetch_status = 0  
begin    
if exists(select * from sys.objects where name = @sp) begin print 'Dropping signature from: ' + @sp set @exec_str = N'drop signature from ' + quotename(@sp) + N' by certificate [##MS_AgentSigningCertificate##]'   
Execute(@exec_str)
if (@@error <> 0)
begin
declare @err_str nvarchar(1024)
set @err_str = 'Cannot drop signature from ' + quotename(@sp) + '. Terminating.'
close ms_crs_sps
deallocate ms_crs_sps
ROLLBACK TRANSACTION
RAISERROR(@err_str, 20, 127) WITH LOG
return
end
end
fetch next from ms_crs_sps into @sp
end
close ms_crs_sps
deallocate ms_crs_sps
COMMIT TRANSACTION
go

http://forums.microsoft.com/TechNet/ShowPost.aspx?PostID=3876484&SiteID=17
I have not tried the script, so please backup your data and system before attempting and update here with results.
"
52520,"10 years or more ago this would have been, ""Are non-internet applications dead?""
There's things the cloud does better than desktop applications, and in those places I'm sure non-cloud applications will become increasingly rare.  But there's plenty of applications where you might not want to use the cloud, the benefits don't outweigh the costs, or the complexity just isn't worth it.
It's a new tool, and it's a better tool than desktop applications for many things.  However, you don't throw away a hammer when you buy a screwdriver, you simply reserve it for when a nail needs to be driven.
"
52550,"The expression:
(expression1,  expression2)

First expression1 is evaluated, then expression2 is evaluated, and the value of expression2 is returned for the whole expression.
"
52600,"To confirm if you're using the provided PDB, CorporateComponent.pdb, during debugging within the Visual Studio IDE review the output window and locate the line indicating that the CorporateComponent.dll is loaded and followed by the string Symbols loaded.
To illustrate from a project of mine:
The thread 0x6a0 has exited with code 0 (0x0).
The thread 0x1f78 has exited with code 0 (0x0).
'AvayaConfigurationService.vshost.exe' (Managed): Loaded 'C:\Development\Src\trunk\ntity\AvayaConfigurationService\AvayaConfigurationService\bin\Debug  \AvayaConfigurationService.exe', Symbols loaded.
'AvayaConfigurationService.vshost.exe' (Managed): Loaded 'C:\Development\Src\trunk\ntity\AvayaConfigurationService\AvayaConfigurationService\bin\Debug\IPOConfigService.dll', No symbols loaded.


Loaded 'C:\Development\src...\bin\Debug\AvayaConfigurationService.exe', Symbols loaded.

This indicates that the PDB was found and loaded by the IDE debugger.
As indicated by others When examining stack frames within your application you should be able to see the symbols from the CorporateComponent.pdb. If you don't then perhaps the third-party did not include symbol information in the release PDB build.
"
52730,"Take a look at XmlPreProcess. We use it for producing different config files for our testing and live deployment packages. 
We execute it from a nant script as part of a continuous build but, since it's a console app, I see no reason why you coudn't add a call in your project's post-build event instead
"
52830,"I would say that surprising people by suddenly penetration-testing their software may bother people if simply for the fact that they didn't know ahead of time. I would say if you're going to do this (and I believe it's a good thing to do), inform your clients ahead of time that you're going to do this. If they seem a little distraught by this, tell them the benefits of checking for human error from the attacker's point of view in a controlled environment. After all, even the most securely minded make mistakes: the Debian PRNG vulnerability is a good example of this.
"
52880,"This URL will give you a count of unread posts per feed.  You can then iterate over the feeds and sum up the counts.
http://www.google.com/reader/api/0/unread-count?all=true
Here is a minimalist example in Python...parsing the xml/json and summing the counts is left as an exercise for the reader:
import urllib
import urllib2

username = 'username@gmail.com'
password = '******'

# Authenticate to obtain SID
auth_url = 'https://www.google.com/accounts/ClientLogin'
auth_req_data = urllib.urlencode({'Email': username,
                                  'Passwd': password,
                                  'service': 'reader'})
auth_req = urllib2.Request(auth_url, data=auth_req_data)
auth_resp = urllib2.urlopen(auth_req)
auth_resp_content = auth_resp.read()
auth_resp_dict = dict(x.split('=') for x in auth_resp_content.split('\n') if x)
auth_token = auth_resp_dict[""Auth""]

# Create a cookie in the header using the SID 
header = {}
header['Authorization'] = 'GoogleLogin auth=%s' % auth_token

reader_base_url = 'http://www.google.com/reader/api/0/unread-count?%s'
reader_req_data = urllib.urlencode({'all': 'true',
                                    'output': 'xml'})
reader_url = reader_base_url % (reader_req_data)
reader_req = urllib2.Request(reader_url, None, header)
reader_resp = urllib2.urlopen(reader_req)
reader_resp_content = reader_resp.read()

print reader_resp_content

And some additional links on the topic:

http://code.google.com/p/pyrfeed/wiki/GoogleReaderAPI
How do you access an authenticated Google App Engine service from a (non-web) python client?
http://blog.gpowered.net/2007/08/google-reader-api-functions.html

"
52950,"Since version 1.5.6 there is an ignorecase option available in the [core] section of .git/config
e.g. add ignorecase = true
To change it for just one repo, from that folder run:
git config core.ignorecase true

To change it globally: 
git config --global core.ignorecase true

"
53070,"Found this article by Rick Strahl recently http://www.west-wind.com/presentations/PayPalIntegration/PayPalIntegration.asp.  
Have not implemeted anything from it yet, Rick has quite a few articles around the web on ecommerce in aspnet, and he seems to show up everytime I'm searching for it.
"
53220,"Repeaters don't do this by default.
However, GridViews do.
Personally, I hate GridViews, so I wrote a Paging/Sorting Repeater control.
Basic Steps:

Subclass the Repeater Control
Add a private PagedDataSource to it
Add a public PageSize property
Override Control.DataBind

Store the Control.DataSource in the PagedDataSource.
Bind the Control.DataSource to PagedDataSource

Override Control.Render

Call Base.Render()
Render your paging links.


For a walkthrough, you could try this link:
http://aspnet.4guysfromrolla.com/articles/081804-1.aspx
"
53260,"This is one good place where Ajax techniques might be helpful. When the user clicks the submit button, show the login dialog on client side and validate with the server before you actually submit the page.
Another way I can think of is showing or hiding the login controls in a DIV tag dynamically in the main page itself.
"
53290,"This page should provide a workaround for your problem. 
http://code.google.com/p/support/wiki/ImportingFromGit
Basically, you create a read-only clone of your Git repository in the SVN repository format, exporting updates as you go. An SVN hook could be written that fires after each update to copy the new files where you need them.
"
53370,"You can get many different AJAX loading animations in any colour you want here: ajaxload.info
"
53450,"Ahh.. ScottGu says it doesn't matter, but .ashx is slightly better because there's less chance of a conflict with things like trace.axd and others. That's why the flag went up in my head that .ashx might be better.
http://forums.asp.net/t/964074.aspx
"
53480,"Kind of old, but It might be useful to future visitors. If you're already using the Levenshtein algorithm and you need to go a little better, I describe some very effective heuristics in this solution:
Getting the closest string match
The key is that you come up with 3 or 4 (or more) methods of gauging the similarity between your phrases (Levenshtein distance is just one method) - and then using real examples of strings you want to match as similar, you adjust the weightings and combinations of those heuristics until you get something that maximizes the number of positive matches. Then you use that formula for all future matches and you should see great results.
If a user is involved in the process, it's also best if you provide an interface which allows the user to see additional matches that rank highly in similarity in case they disagree with the first choice.
Here's an excerpt from the linked answer. If you end up wanting to use any of this code as is, I apologize in advance for having to convert VBA into C#.

Simple, speedy, and a very useful metric. Using this, I created two separate metrics for evaluating the similarity of two strings. One I call ""valuePhrase"" and one I call ""valueWords"". valuePhrase is just the Levenshtein distance between the two phrases, and valueWords splits the string into individual words, based on delimiters such as spaces, dashes, and anything else you'd like, and compares each word to each other word, summing up the shortest Levenshtein distance connecting any two words. Essentially, it measures whether the information in one 'phrase' is really contained in another, just as a word-wise permutation. I spent a few days as a side project coming up with the most efficient way possible of splitting a string based on delimiters.
valueWords, valuePhrase, and Split function:
Public Function valuePhrase#(ByRef S1$, ByRef S2$)
    valuePhrase = LevenshteinDistance(S1, S2)
End Function

Public Function valueWords#(ByRef S1$, ByRef S2$)
    Dim wordsS1$(), wordsS2$()
    wordsS1 = SplitMultiDelims(S1, "" _-"")
    wordsS2 = SplitMultiDelims(S2, "" _-"")
    Dim word1%, word2%, thisD#, wordbest#
    Dim wordsTotal#
    For word1 = LBound(wordsS1) To UBound(wordsS1)
        wordbest = Len(S2)
        For word2 = LBound(wordsS2) To UBound(wordsS2)
            thisD = LevenshteinDistance(wordsS1(word1), wordsS2(word2))
            If thisD < wordbest Then wordbest = thisD
            If thisD = 0 Then GoTo foundbest
        Next word2
foundbest:
        wordsTotal = wordsTotal + wordbest
    Next word1
    valueWords = wordsTotal
End Function

''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
' SplitMultiDelims
' This function splits Text into an array of substrings, each substring
' delimited by any character in DelimChars. Only a single character
' may be a delimiter between two substrings, but DelimChars may
' contain any number of delimiter characters. It returns a single element
' array containing all of text if DelimChars is empty, or a 1 or greater
' element array if the Text is successfully split into substrings.
' If IgnoreConsecutiveDelimiters is true, empty array elements will not occur.
' If Limit greater than 0, the function will only split Text into 'Limit'
' array elements or less. The last element will contain the rest of Text.
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Function SplitMultiDelims(ByRef Text As String, ByRef DelimChars As String, _
        Optional ByVal IgnoreConsecutiveDelimiters As Boolean = False, _
        Optional ByVal Limit As Long = -1) As String()
    Dim ElemStart As Long, N As Long, M As Long, Elements As Long
    Dim lDelims As Long, lText As Long
    Dim Arr() As String

    lText = Len(Text)
    lDelims = Len(DelimChars)
    If lDelims = 0 Or lText = 0 Or Limit = 1 Then
        ReDim Arr(0 To 0)
        Arr(0) = Text
        SplitMultiDelims = Arr
        Exit Function
    End If
    ReDim Arr(0 To IIf(Limit = -1, lText - 1, Limit))

    Elements = 0: ElemStart = 1
    For N = 1 To lText
        If InStr(DelimChars, Mid(Text, N, 1)) Then
            Arr(Elements) = Mid(Text, ElemStart, N - ElemStart)
            If IgnoreConsecutiveDelimiters Then
                If Len(Arr(Elements)) > 0 Then Elements = Elements + 1
            Else
                Elements = Elements + 1
            End If
            ElemStart = N + 1
            If Elements + 1 = Limit Then Exit For
        End If
    Next N
    'Get the last token terminated by the end of the string into the array
    If ElemStart <= lText Then Arr(Elements) = Mid(Text, ElemStart)
    'Since the end of string counts as the terminating delimiter, if the last character
    'was also a delimiter, we treat the two as consecutive, and so ignore the last elemnent
    If IgnoreConsecutiveDelimiters Then If Len(Arr(Elements)) = 0 Then Elements = Elements - 1

    ReDim Preserve Arr(0 To Elements) 'Chop off unused array elements
    SplitMultiDelims = Arr
End Function

Measures of Similarity
Using these two metrics, and a third which simply computes the distance between two strings, I have a series of variables which I can run an optimization algorithm to achieve the greatest number of matches. Fuzzy string matching is, itself, a fuzzy science, and so by creating linearly independent metrics for measuring string similarity, and having a known set of strings we wish to match to each other, we can find the parameters that, for our specific styles of strings, give the best fuzzy match results.
Initially, the goal of the metric was to have a low search value for for an exact match, and increasing search values for increasingly permuted measures. In an impractical case, this was fairly easy to define using a set of well defined permutations, and engineering the final formula such that they had increasing search values results as desired.

As you can see, the last two metrics, which are fuzzy string matching metrics, already have a natural tendency to give low scores to strings that are meant to match (down the diagonal). This is very good. 
Application
To allow the optimization of fuzzy matching, I weight each metric. As such, every application of fuzzy string match can weight the parameters differently. The formula that defines the final score is a simply combination of the metrics and their weights:
value = Min(phraseWeight*phraseValue, wordsWeight*wordsValue)*minWeight + 
        Max(phraseWeight*phraseValue, wordsWeight*wordsValue)*maxWeight + lengthWeight*lengthValue

Using an optimization algorithm (neural network is best here because it is a discrete, multi-dimentional problem), the goal is now to maximize the number of matches. I created a function that detects the number of correct matches of each set to each other, as can be seen in this final screenshot. A column or row gets a point if the lowest score is assigned the the string that was meant to be matched, and partial points are given if there is a tie for the lowest score, and the correct match is among the tied matched strings. I then optimized it. You can see that a green cell is the column that best matches the current row, and a blue square around the cell is the row that best matches the current column. The score in the bottom corner is roughly the number of successful matches and this is what we tell our optimization problem to maximize. 

"
53610,"The microsoft official way is just to copy them into the relevant folders (as seen by downloading their template packs).  However, you could also create your own site definition and add the items to the correct libraries and lists in the same way that the master pages are added.
If you are going to deploy CSS and Master Pages through features remember you will have to activate your the publishing infrastructure on the site collection and the publishing feature on the site.
To deploy a master page/page layout as a feature you should follow the steps at the site  below, you can use the ""fileurl"" element to specify your CSS and place it into the correct folder (style library, for example):
http://www.sharepointnutsandbolts.com/2007/04/deploying-master-pages-and-page-layouts.html
"
53670,"See similar post
"
53820,"Usually when an application is in ""full screen"" mode it will take over the entire desktop.  For a user to get to another window they would have to alt-tab to it.  At that point windows would minimize the full screen app so that the other application could come to the front. 
This sounds like it may be a bug (undocumented feature...) in windows.  It should probably not be doing this for a dual screen setup.  
One option to fix this is rather than setting it to be ""full screen"" just make the window the same size as the screen with location (0,0).  You can get screen information from the GraphicsConfigurations on the GraphicsDevice.  
"
54010,"
scala> val list = List((""A"", ""B"", 1), (""C"", ""D"", 1), (""E"", ""F"", 1), (""C"", ""D"", 2), (""G"", ""H"", 1))
list: List[(java.lang.String, java.lang.String, Int)] = List((A,B,1), (C,D,1), (E,F,1), (C,D,2), (G,H,1))

scala> list find {e => e._1 == ""C"" && e._2 == ""D""}
res0: Option[(java.lang.String, java.lang.String, Int)] = Some((C,D,1))

"
54050,"using System.Security.Principal;
...
WindowsPrincipal wp = (WindowsPrincipal)HttpContext.Current.User;

to get the current domain user. Of course you have to make sure that the IIS is set up to handle Windows Authentication.
"
54200,"
Encrypting and Decrypting Configuration Sections (ASP.NET) on MSDN
Encrypting Web.Config Values in ASP.NET 2.0 on ScottGu's blog
Encrypting Custom Configuration Sections on K. Scott Allen's blog

EDIT:
If you can't use asp utility, you can encrypt config file using SectionInformation.ProtectSection method.
Sample on codeproject:
Encryption of Connection Strings inside the Web.config in ASP.Net 2.0 
"
54230,"CakePHP's built-in ACL system is really powerful, but poorly documented in terms of actual implementation details. A system that we've used with some success in a number of CakePHP-based projects is as follows.
It's a modification of some group-level access systems that have been documented elsewhere. Our system's aims are to have a simple system where users are authorised on a group-level, but they can have specific additional rights on items that were created by them, or on a per-user basis. We wanted to avoid having to create a specific entry for each user (or, more specifically for each ARO) in the aros_acos table.
We have a Users table, and a Roles table.
Users
user_id, user_name, role_id
Roles
id, role_name
Create the ARO tree for each role (we usually have 4 roles - Unauthorised Guest (id 1), Authorised User (id 2), Site Moderator (id 3) and Administrator (id 4)) :
cake acl create aro / Role.1
cake acl create aro 1 Role.2  ... etc ...
After this, you have to use SQL or phpMyAdmin or similar to add aliases for all of these, as the cake command line tool doesn't do it. We use 'Role-{id}' and 'User-{id}' for all of ours.
We then create a ROOT ACO - 
cake acl create aco / 'ROOT'
and then create ACOs for all the controllers under this ROOT one:
cake acl create aco 'ROOT' 'MyController' ... etc ...
So far so normal. We add an additional field in the aros_acos table called _editown  which we can use as an additional action in the ACL component's actionMap.
CREATE TABLE IF NOT EXISTS `aros_acos` (
`id` int(11) NOT NULL auto_increment,
`aro_id` int(11) default NULL,
`aco_id` int(11) default NULL,
`_create` int(11) NOT NULL default '0',
`_read` int(11) NOT NULL default '0',
`_update` int(11) NOT NULL default '0',
`_delete` int(11) NOT NULL default '0',
`_editown` int(11) NOT NULL default '0',
PRIMARY KEY  (`id`),
KEY `acl` (`aro_id`,`aco_id`)
) ENGINE=InnoDB  DEFAULT CHARSET=utf8;

We can then setup the Auth component to use the 'crud' method, which validates the requested controller/action against an AclComponent::check(). In the app_controller we have something along the lines of:
private function setupAuth() {
    if(isset($this->Auth)) {
        ....
        $this->Auth->authorize = 'crud';
        $this->Auth->actionMap = array( 'index'     => 'read',
                        'add'       => 'create',
                        'edit'      => 'update'
                        'editMine'  => 'editown',
                        'view'      => 'read'
                        ... etc ...
                        );
        ... etc ...
    }
}

Again, this is fairly standard CakePHP stuff. We then have a checkAccess method in the AppController that adds in the group-level stuff to check whether to check a group ARO or a user ARO for access:
private function checkAccess() {
    if(!$user = $this->Auth->user()) {
        $role_alias = 'Role-1';
        $user_alias = null;
    } else {
        $role_alias = 'Role-' . $user['User']['role_id'];
        $user_alias = 'User-' . $user['User']['id'];
    }

    // do we have an aro for this user?
    if($user_alias && ($user_aro = $this->User->Aro->findByAlias($user_alias))) {
        $aro_alias = $user_alias;
    } else {
        $aro_alias = $role_alias;
    }

    if ('editown' == $this->Auth->actionMap[$this->action]) {
        if($this->Acl->check($aro_alias, $this->name, 'editown') and $this->isMine()) {
            $this->Auth->allow();
        } else {
            $this->Auth->authorize = 'controller';
            $this->Auth->deny('*');
        }
    } else {
        // check this user-level aro for access
        if($this->Acl->check($aro_alias, $this->name, $this->Auth->actionMap[$this->action])) {
            $this->Auth->allow();
        } else {
            $this->Auth->authorize = 'controller';
            $this->Auth->deny('*');
        }
    }
}

The setupAuth() and checkAccess() methods are called in the AppController's beforeFilter() callback. There's an isMine method in the AppControler too (see below) that just checks that the user_id of the requested item is the same as the currently authenticated user. I've left this out for clarity.
That's really all there is to it. You can then allow / deny particular groups access to specific acos - 
cake acl grant 'Role-2' 'MyController' 'read'
cake acl grant 'Role-2' 'MyController' 'editown'
cake acl deny 'Role-2' 'MyController' 'update'
cake acl deny 'Role-2' 'MyController' 'delete'
I'm sure you get the picture.
Anyway, this answer's way longer than I intended it to be, and it probably makes next to no sense, but I hope it's some help to you ...
-- edit --
As requested, here's an edited (purely for clarity - there's a lot of stuff in our boilerplate code that's meaningless here) isMine() method that we have in our AppController. I've removed a lot of error checking stuff too, but this is the essence of it:
function isMine($model=null, $id=null, $usermodel='User', $foreignkey='user_id') {
    if(empty($model)) {
        // default model is first item in $this->uses array
        $model = $this->uses[0];
    }

    if(empty($id)) {
        if(!empty($this->passedArgs['id'])) {
        $id = $this->passedArgs['id'];
        } elseif(!empty($this->passedArgs[0])) {
            $id = $this->passedArgs[0];
        }
    }

    if(is_array($id)) {
        foreach($id as $i) {
            if(!$this->_isMine($model, $i, $usermodel, $foreignkey)) {
                return false;
            }
        }

        return true;
    }

    return $this->_isMine($model, $id, $usermodel, $foreignkey);
}


function _isMine($model, $id, $usermodel='User', $foreignkey='user_id') {
    $user = Configure::read('curr.loggedinuser'); // this is set in the UsersController on successful login

    if(isset($this->$model)) {
        $model = $this->$model;
    } else {
        $model = ClassRegistry::init($model);
    }

    //read model
    if(!($record = $model->read(null, $id))) {
        return false;
    }

    //get foreign key
    if($usermodel == $model->alias) {
        if($record[$model->alias][$model->primaryKey] == $user['User']['id']) {
            return true;
        }
    } elseif($record[$model->alias][$foreignkey] == $user['User']['id']) {
        return true;
    }

    return false;
}

"
54380,"In order to verbosely display the errors resulting from your data service you can place the following tag above your dataservice definition:
[System.ServiceModel.ServiceBehavior(IncludeExceptionDetailInFaults = true)]

This will then display the error in your browser window as well as a stack trace.
In addition to this dataservices throws all exceptions to the HandleException method so if you implement this method on your dataservice class you can put a break point on it and see the exception:
protected override void HandleException(HandleExceptionArgs e)
{
  try
  {
    e.UseVerboseErrors = true;
  }
  catch (Exception ex)
  {
    Console.WriteLine(ex.Message);
  }
}

"
54440,"You can bind to an element using ElementName, so if you wanted to bind the selected tree item to the ItemsSource of a ListBox:
ItemsSource=""{Binding SelectedItem, ElementName=treeView1}""

"
54500,"Re jcoby's answer:
bytea being a ""normal"" column also means the value being read completely into memory when you fetch it. Blobs, in contrast, you can stream into stdout. That helps in reducing the server memory footprint. Especially, when you store 4-6 MPix images.
No problem with backing up blobs. pg_dump provides ""-b"" option to include the large objects into the backup.
So, I prefer using pg_lo_*, you may guess.
Re Kris Erickson's answer:
I'd say the opposite :). When images are not the only data you store, don't store them on the file system unless you absolutely have to. It's such a benefit to be always sure about your data consistency, and to have the data ""in one piece"" (the DB). BTW, PostgreSQL is great in preserving consistency.
However, true, reality is often too performance-demanding ;-), and it pushes you to serve the binary files from the file system. But even then I tend to use the DB as the ""master"" storage for binaries, with all the other relations consistently linked, while providing some file system-based caching mechanism for performance optimization.  
"
54760,"-[NSPasteboard types] will return all the available types for the data on the clipboard, but it should return them ""in the order they were declared.""
The documentation for -[NSPasteboard declareTypes:owner:] says that ""the types should be ordered according to the preference of the source application.""
A properly implemented pasteboard owner should, therefore, declare the richest representation of the content (probably the original content) as the first type; so a reasonable single representation should be:
[pb dataForType:[[pb types] objectAtIndex:0]]

"
54770,"Do you know which version of MS Office you are targeting? These PIAs are very specific to the version of Office. I remember when we were building a smart client application, we used to have Build VM machines, each one targeting a specific version of Outlook.
Another hurdle was not being able to specify these PIAs as pre-requisites or bundle them with the app. These PIAs needs to be installed on the client using Office CD (at least for 2003 version).
"
54790,"Current status (Mono 2.10, 2011): xbuild is now able to build all versions of Visual Studio / MSBuild projects, including .sln files. Simply run xbuild just as you would execute msbuild on Microsoft .Net Framework. You don't need Monodevelop installed, xbuild comes with the standard Mono installation.
If your build uses custom tasks, they should still work if they don't depend on Windows executables (such as rmdir or xcopy).
When you are editing project files, use standard Windows path syntax - they will be converted by xbuild, if necessary. One important caveat to this rule is case sensitivity - don't mix different casings of the same file name. If you have a project that does this, you can enable compatibility mode by invoking MONO_IOMAP=case xbuild foo.sln (or try MONO_IOMAP=all). Mono has a page describing more advanced MSBuild project porting techniques.
Mono 2.0 answer (2008): xbuild is not yet complete (it works quite well with VS2005 .csproj files, has problems with VS2008 .csproj and does not handle .sln). Mono 2.1 plans to merge the code base of mdtool (MonoDevelop command line build engine) into it, but currently mdtool is a better choice. mdtool build -f:project.sln or man mdtool if you have MonoDevelop installed.
"
54980,"From what I understand, prepared statements will reuse the generated SQL plan if it is the same statement, so the database will see the same prepared statement and not have to do the work to figure out how to query the database. I would say the extra work of saving the prepared statement in Product::getPrice_A is not typically very helpful, more because it can obscure the code rather than an issue of performance.  When dealing with performance, I feel it's always best to focus on code clarity and then performance when you have real statistics that indicate a problem.
I would say ""yes, the extra work is unnecessary"" (regardless of if it really boosts performance).  Also, I am not a very big DB expert, but the performance gain of prepared statements is something I heard from others, and it is at the database level, not the code level (so if the code is actually invoking a parameterized statement on the actual DB, then the DB can do these execution plan caching... though depending on the database, you may get the benefit even without the parameterized statement).
Anyways, if you are really worried about (and seeing) database performance issues, you should look into a caching solution... of which I would highly recommend memcached.  With such a solution, you can cache your query results and not even hit the database for things you access frequently.
"
55010,"If you're running Apache, you can put a RewriteRule in your .htaccess, like so:
RewriteCond %{HTTPS} ""off""
RewriteRule /mypage.html https://example.com/mypage.html

"
55060,"Summing up, the proper answer is no, you shouldn't (see caveat below). 
There are workarounds already mentioned by many people in this thread, like using reference variables or isset() or empty() in conditions and suppressing notices in PHP configuration. That in addition to the obvious workaround, using @, which you don't want.
Summarizing an interesting comment discussion with Gerry: Passing the variable by reference is indeed valid if you check for the value of the variable inside the function and handle undefined or null cases properly. Just don't use reference passing as a way of shutting PHP up (this is where my original shouldn't points to).
"
55130,"You sure that one of the properties trying to be accessed on the l_Monitor instance isn't null?
"
55140,"Also take a look at SQLite for Windows CE.  There are also .NET bindings available to use it from the Compact Framework.
"
55180,"Do you mean that you need the values sorted by the value of the key?
In that case, this should do it:
for key in sorted(d):
    print d[key]

EDIT: changed to use sorted(d) instead of sorted(d.keys()), thanks Eli!
"
55210,"Most of these answers are horribly inefficient and/or will only give one-word solutions (no spaces).  My solution will handle any number of words and is very efficient.
What you want is a trie data structure.  Here's a complete Python implementation.  You just need a word list saved in a file named words.txt  You can try the Scrabble dictionary word list here:
http://www.isc.ro/lists/twl06.zip
MIN_WORD_SIZE = 4 # min size of a word in the output

class Node(object):
    def __init__(self, letter='', final=False, depth=0):
        self.letter = letter
        self.final = final
        self.depth = depth
        self.children = {}
    def add(self, letters):
        node = self
        for index, letter in enumerate(letters):
            if letter not in node.children:
                node.children[letter] = Node(letter, index==len(letters)-1, index+1)
            node = node.children[letter]
    def anagram(self, letters):
        tiles = {}
        for letter in letters:
            tiles[letter] = tiles.get(letter, 0) + 1
        min_length = len(letters)
        return self._anagram(tiles, [], self, min_length)
    def _anagram(self, tiles, path, root, min_length):
        if self.final and self.depth >= MIN_WORD_SIZE:
            word = ''.join(path)
            length = len(word.replace(' ', ''))
            if length >= min_length:
                yield word
            path.append(' ')
            for word in root._anagram(tiles, path, root, min_length):
                yield word
            path.pop()
        for letter, node in self.children.iteritems():
            count = tiles.get(letter, 0)
            if count == 0:
                continue
            tiles[letter] = count - 1
            path.append(letter)
            for word in node._anagram(tiles, path, root, min_length):
                yield word
            path.pop()
            tiles[letter] = count

def load_dictionary(path):
    result = Node()
    for line in open(path, 'r'):
        word = line.strip().lower()
        result.add(word)
    return result

def main():
    print 'Loading word list.'
    words = load_dictionary('words.txt')
    while True:
        letters = raw_input('Enter letters: ')
        letters = letters.lower()
        letters = letters.replace(' ', '')
        if not letters:
            break
        count = 0
        for word in words.anagram(letters):
            print word
            count += 1
        print '%d results.' % count

if __name__ == '__main__':
    main()

When you run the program, the words are loaded into a trie in memory.  After that, just type in the letters you want to search with and it will print the results.  It will only show results that use all of the input letters, nothing shorter.
It filters short words from the output, otherwise the number of results is huge.  Feel free to tweak the MIN_WORD_SIZE setting.  Keep in mind, just using ""astronomers"" as input gives 233,549 results if MIN_WORD_SIZE is 1.  Perhaps you can find a shorter word list that only contains more common English words.
Also, the contraction ""I'm"" (from one of your examples) won't show up in the results unless you add ""im"" to the dictionary and set MIN_WORD_SIZE to 2.
The trick to getting multiple words is to jump back to the root node in the trie whenever you encounter a complete word in the search.  Then you keep traversing the trie until all letters have been used.
"
55270,"What about registering a PostBackTrigger (instead of an AsyncPostBackTrigger) that will refresh every panel when a specific event fires.  
Or add the trigger that already refreshes some UpdatePanels to the other UpdatePanels as well.
"
55330,"Rather than storing the position information in a hidden field, store it in a cookie.  The information is small, so it will have minimal effect on the page load performance.
"
55340,"Seeing as it's SQL Server 2005, any reason not to use a CLR stored procedure? You could use your CLR language of choice then and it'd probably be a relatively direct port of your existing Delphi code.
"
55350,"This is possible to do but very difficult.  There are several steps you'll have to take.
First off, this only works on Palm OS 5 and is sketchy on some of the early Palm OS 5 devices.  The latest devices are better but not perfect.
Next, you will need to create an alarm for your application using AlmSetAlarm.  This is how you accomplish the ""every X minutes or hours"" part.
When the alarm fires, your application will get a sysAppLaunchCmdAlarmTriggered launch code, even if it's not already running.  If you only want to do something simple and quick, you can do it in response to the launch code and you're done.
After you do your stuff in the alarm launch code, be sure to set up the next alarm so that you continue to be called.
Important notes: You cannot access global variables when responding this launch code!  Depending on the setup in your compiler, you probably also won't be able to access certain C++ features, like virtual functions (which internally use global variables).  There is a setting you can set in Codewarrior that will help with this, but I'm not too familiar with it.  You should architect your code so that it doesn't need globals; for example, you can use FtrSet and FtrGet to store bits of global data that you might need.  Finally, you will only be able to access a single 64KB code segment of 68000 machine code.  Inter-segment jumps don't work properly without globals set up.
You can get around a lot of these restrictions by moving the majority of your code to a PNOlet, but that's an entirely different and more complicated topic.
If you want to do something more complicated that could take a while (e.g. load a web page or download email), it is strongly recommended not to do it during the alarm launch code.  You could do something in the sysAppLaunchCmdDisplayAlarm launch code and display a form to the user allowing them to cancel.  But this is bound to get annoying quickly.
Better for the user experience (but much more complicated) is to become a background application.  This is a bit of black magic and is not really well supported, but it is possible.  There are basically three steps to becoming a background application:

Protect your application database using DmDatabaseProtect.  This will ensure that your application is locked down so it can't be deleted.
Lock your code segment using MemHandleLock and MemHandleSetOwner (set the owner to 0).  This will ensure that your code is loaded into memory and won't be moved.
Register for some notifications.  For example, the sysNotifyIdleTimeEvent is a great notification to use to do some periodic background processing.

Once you set this up, you can exit from the alarm launch code and then wait for your notifications to fire.  You will then do all of your background processing when your notification handlers are called.
Also make sure that if you allocate any system objects (memory, handles, file handles, etc.), you set their owner to 0 (system) if you expect them to persist after you return from your notification handler.  Otherwise the system will clean them up.  If you do this, be super careful to avoid memory and resource leaks!!  They will never get cleaned up when the owner is set to 0!
To leave background mode, simply do the reverse: unregister for notifications, unlock your code segment, and unprotect your application database.
If you do any network operations in the background, be sure that you set the sockets to non-blocking mode and deal correctly with that!  Otherwise you will block the foreground application and cause problems.
"
55360,"Check your User Agent string. This same thing happened to me one time and I realized it was because I was testing out some pages as ""googlebot"". The JavaScript that is generated depends on knowing what the user agent is.
From http://support.mozilla.com/tiki-view_forum_thread.php?locale=tr&comments_parentId=160492&forumId=1:

To reset your user agent string type about:config into the location bar and press enter. This brings up a list of preferences. Enter general.useragent into the filter box, this should show a few preferences (probably 4 of them). If any have the status user set, right-click on the preference and choose Reset

"
55440,"It's verbose, but you can do it like this:
#include <boost/utility/enable_if.hpp>
#include <boost/type_traits/is_base_of.hpp>

struct base {};

template <typename ImplementationClass, class Enable = void>
class WrapperClass;

template <typename ImplementationClass>
class WrapperClass<ImplementationClass,
      typename boost::enable_if<
        boost::is_base_of<base,ImplementationClass> >::type>
{};

struct derived : base {};
struct not_derived {};

int main() {
    WrapperClass<derived> x;

    // Compile error here:
    WrapperClass<not_derived> y;
}

This requires a compiler with good support for the standard (most recent compilers should be fine but old versions of Visual C++ won't be). For more information, see the Boost.Enable_If documentation.
As Ferruccio said, a simpler but less powerful implementation:
#include <boost/static_assert.hpp>
#include <boost/type_traits/is_base_of.hpp>

struct base {};

template <typename ImplementationClass>
class WrapperClass
{
    BOOST_STATIC_ASSERT((
        boost::is_base_of<base, ImplementationClass>::value));
};

"
55460,"Your question assumes that mail clients follow the RFC standards for MIME encoding, which they don't. I'd advise you collect a bunch of mail from sources and try and process it as-it-exists. The problem you are facing is extremely difficult (perhaps impossible) to solve 100%.
"
55510,"I was curious about this so I wrote the following test program and compiled it with g++ version 4.1.2.
include <iostream>
#include <string>

using namespace std;

class test
{
public:
        test(const char *name)
                : _name(name)
        {
                cout << _name << "" created"" << endl;
        }

        ~test()
        {
                cout << _name << "" destroyed"" << endl;
        }

        string _name;
};

test t(""global variable"");

void f()
{
        static test t(""static variable"");

        test t2(""Local variable"");

        cout << ""Function executed"" << endl;
}


int main()
{
        test t(""local to main"");

        cout << ""Program start"" << endl;

        f();

        cout << ""Program end"" << endl;
        return 0;
}

The results were not what I expected. The constructor for the static object was not called until the first time the function was called. Here is the output:
global variable created
local to main created
Program start
static variable created
Local variable created
Function executed
Local variable destroyed
Program end
local to main destroyed
static variable destroyed
global variable destroyed

"
55670,"Not sure if they have an API, but you should check out http://albumart.org. Also check out http://www.freecovers.net/api, a similar service.
"
55720,"I've used XDebug profiling recently in a similiar situation. It outputs a full profile report that can be read with many common profiling apps ( Can't give you a list though, I just used the one that came with slackware ). 
"
55860,"you have to delete your cookie at the same path where you created it.
so create your cookie with path=/ and delte it with path=/ as well..
"
56070,"One piece of information missing is the number of indices on the table you are deleting the data from. As SQL Server uses the Primary Key as a pointer in every index, any change to the primary index requires updating every index. Though, unless we are talking a high number, this shouldn't be an issue.
I am guessing, from your description, that this is a primary table in the database, referenced by many other tables in FK relationships.  This would account for the large number of locks as it checks the rest of the tables for references. And, if you have cascading deletes turned on, this could lead to a delete in table a requiring checks several tables deep.
"
56090,"TortoiseSVN can show revision graph - visual representation of branching \ merging history and more.
"
56430,"Nelson:
""That's how foxpro does it and there is no way around it""?
I'm using FOX since FoxPro 2.5 to Visual FoxPro 9, and you are NEVER forced in any way to hard-code a path, you can use SET PATH TO (sYourPath), you can embed the icons and bitmaps in your EXE / APP file and therefore there's no need of including this resources externally.
You say that you have a ""Foxpro App"": which version? Old MS-DOS FoxPro o Visual FoxPro?
If you're using VFP 8+, you can use SYS(2450, 1):
Specifies how an application searches for data and resources such as functions, procedures, executable files, and so on. 

You can use SYS(2450) to specify that Visual FoxPro searches within an application for a specific procedure or user-defined function (UDF) before it searches along the SET DEFAULT and SET PATH locations. Setting SYS(2450) can help improve performance for applications that run on a local or wide area network.


SYS(2450 [, 0 | 1 ])



Parameters
0 
Search along path and default locations before searching in the application. (Default)

1 
Search within the application for the specified procedure or UDF before searching the path and default locations.

One quick workaround could be assign another letter to your USB via the Disk Manager.
"
56500,"you must link against the lib generated after compiling the DLL. In the linker options of the project, you must add the .lib file. And yes, you should also declare the variable as:
extern ""C"" { declspec(dllimport) char MyNewVariable; }

"
56630,"Okay, I figured it out.  I will post it here in case it help anyone else.  This solution uses prototype, and an internal library that gives me the registerEvent, getElementX and getElementY functions, which do what you would think.
var MenuManager = Class.create({
    initialize: function initialize(menuElt) {
    	this.menu = $(menuElt);
    	this.homePosn = { x: getElementX(this.menu), y: getElementY(this.menu) };
    	registerEvent(document, 'scroll', this.handleScroll.bind(this));
    	this.handleScroll();
    },
    handleScroll: function handleScroll() {
    	this.scrollOffset = document.viewport.getScrollOffsets().top;
    	if (this.scrollOffset > this.homePosn.y) {
    		this.menu.style.position = 'fixed';
    		this.menu.style.top = 0;
    		this.menu.style.left = this.homePosn.x;
    	} else {
    		this.menu.style.position = 'absolute';
    		this.menu.style.top = null;
    		this.menu.style.left = null;
    	}
    }
});

Just call the constructor with the id of your menu, and the class will take it from there.
"
56680,"A debugger called fdb is included in the Flex SDK. Here's some documentation on how to use it:

Adobe DevCenter: Debugging Client-Side Code in Flex Applications
Flex 3 Help: Using the Command-Line Debugger

"
56770,"You might consider inserting placeholders like <my:contact-us-form/> in the database on specific pages; that way the database can describe all the static text content instead of completely replacing that database-driven content with an .ascx control.
"
56810,"Since you mentioned fork() I assume you're on a Unix-like system, in which case POSIX threads (usually referred to as pthreads) are what you want to use.
Specifically, pthread_create() is the function you need to create a new thread. Its arguments are:
int  pthread_create(pthread_t  *  thread, pthread_attr_t * attr, void *
   (*start_routine)(void *), void * arg);

The first argument is the returned pointer to the thread id. The second argument is the thread arguments, which can be NULL unless you want to start the thread with a specific priority. The third argument is the function executed by the thread. The fourth argument is the single argument passed to the thread function when it is executed.
"
56820,"Formatting works correctly even without having to round:
""%.1f"" % n

"
56860,"A great example illustrating LSP (given by Uncle Bob in a podcast I heard recently) was how sometimes something that sounds right in natural language doesn't quite work in code.
In mathematics, a Square is a Rectangle. Indeed it is a specialization of a rectangle. The ""is a"" makes you want to model this with inheritance. However if in code you made Square derive from Rectangle, then a Square should be usable anywhere you expect a Rectangle. This makes for some strange behavior. 
Imagine you had SetWidth and SetHeight methods on your Rectangle base class; this seems perfectly logical. However if your Rectangle reference pointed to a Square, then SetWidth and SetHeight doesn't make sense because setting one would change the other to match it. In this case Square fails the Liskov Substitution Test with Rectangle and the abstraction of having Square inherit from Rectangle is a bad one.

Y'all should check out the other priceless SOLID Principles Motivational Posters.
"
56950,"The STR function has an optional length argument as well as a number-of-decimals one.
SELECT STR(123.45, 6, 1)

------
 123.5

(1 row(s) affected)

"
57010,"EDIT: made some changes and new suggestions
What about a sliding window...
REMOVE LENGTH 2: (no other length has other matches)
//the lower case letters are the matches
ABCBAbabaBBCbcbcbVbvBCbcbcAB  
__ABCBABABABBCBCBCBVBVBCBCBCAB

REMOVE LENGTH 1 (duplicate characters):
//* denote that a string was removed to prevent continual contraction
//of the string, unless this is what you want.
ABCBA*BbC*V*BC*AB
_ABCBA*BBC*V*BC*AB

RESULT:
ABCBA*B*C*V*BC*AB == ABCBABCVBCAB

This is of course starting with length=2, increase it to L/2 and iterate down. 
I'm also thinking of two other approaches:

digraph - Set a stateful digraph with the data and iterate over it with the string, if a cycle is found you'll have a duplication. I'm not sure how easy it is check check for these cycles... possibly some dynamic programming, so it could be equivlent to method 2 below. I'm going to have to think about this one as well longer.
distance matrix - using a levenstein distance matrix you might be able to detect duplication from diagonal movement (off the diagonal) with cost 0. This could indicate duplication of data. I will have to think about this more.

"
57020,"It seems that the INotifyCollectionChanged interface allows for updating when multiple items were added, so I'm not sure why ObservableCollection<T> doesn't have an AddRange.  You could make an extension method for AddRange, but that would cause an event for every item that is added.  If that isn't acceptable you should be able to inherit from ObservableCollection<T> as follows:
public class MyObservableCollection<T> : ObservableCollection<T>
{
    // matching constructors ...

    bool isInAddRange = false;

    protected override void OnCollectionChanged(NotifyCollectionChangedEventArgs e)
    {
        // intercept this when it gets called inside the AddRange method.
        if (!isInAddRange) 
            base.OnCollectionChanged(e);
    }


    public void AddRange(IEnumerable<T> items)
    {
         isInAddRange = true;
         foreach (T item in items)
            Add(item);
         isInAddRange = false;

         var e = new NotifyCollectionChangedEventArgs(
             NotifyCollectionChangedAction.Add,
             items.ToList());
         base.OnCollectionChanged(e);
    }
}

"
57140,"I think as a general policy, it simply doesn't make sense. Method chaining in this manner works with a properly defined interface but it's only appropriate if it makes semantic sense. 
Your example is a prime one where it's not appropriate, because it makes no semantic sense.
Similarly, your syntactic sugar is unnecessary with a properly designed fluent interface.
Fluent interfaces or method chaining can work very well, but need to be designed carefully.
"
57170,"Basecamp is a joy to use, and its primary focus is project management through collaboration.
"
57350,"How about this, for example:
String appData = 
    Environment.GetFolderPath(Environment.SpecialFolder.LocalApplicationData);

I don't see an enum for just the Local Settings folder.
http://web.archive.org/web/20080303235606/http://dotnetjunkies.com/WebLog/nenoloje/archive/2007/07/07/259223.aspx has a list with examples.
"
57380,"This question covers making sure a webpage is not cached.  It seems you have to set several properties to ensure a web page is not cached across all browsers.
"
57530,"We are thinking about migrating from vault to git. I wrote vault2git converter that takes care of history and removes vault bindings from *.sln, *.csproj files.
Once you have git repo, there is git2svn.
I know it sounds like going rounds, but it might be faster than writing vault2svn from scratch.
"
57560,"Use WMI and inspect the Win32_QuickFixEngineering enumeration.
From TechNet:
strComputer = "".""
Set objWMIService = GetObject(""winmgmts:"" _
    & ""{impersonationLevel=impersonate}!\\"" & strComputer & ""\root\cimv2"")
Set colQuickFixes = objWMIService.ExecQuery _
    (""Select * from Win32_QuickFixEngineering"")
For Each objQuickFix in colQuickFixes
    Wscript.Echo ""Computer: "" & objQuickFix.CSName
    Wscript.Echo ""Description: "" & objQuickFix.Description
    Wscript.Echo ""Hot Fix ID: "" & objQuickFix.HotFixID
    Wscript.Echo ""Installation Date: "" & objQuickFix.InstallDate
    Wscript.Echo ""Installed By: "" & objQuickFix.InstalledBy
Next

The HotFixID is what you want to examine.
Here's the output on my system:

    Hot Fix ID: KB941569
    Description: Security Update for Windows XP (KB941569)
    Hot Fix ID: KB937143-IE7
    Description: Security Update for Windows Internet Explorer 7 (KB937143)
    Hot Fix ID: KB938127-IE7
    Description: Security Update for Windows Internet Explorer 7 (KB938127)
    Hot Fix ID: KB939653-IE7
    Description: Security Update for Windows Internet Explorer 7 (KB939653)
    Hot Fix ID: KB942615-IE7
    Description: Security Update for Windows Internet Explorer 7 (KB942615)
    Hot Fix ID: KB944533-IE7
    Description: Security Update for Windows Internet Explorer 7 (KB944533)
    Hot Fix ID: KB947864-IE7
    Description: Hotfix for Windows Internet Explorer 7 (KB947864)
    Hot Fix ID: KB950759-IE7
    Description: Security Update for Windows Internet Explorer 7 (KB950759)
    Hot Fix ID: KB953838-IE7
    Description: Security Update for Windows Internet Explorer 7 (KB953838)
    Hot Fix ID: MSCompPackV1
    Description: Microsoft Compression Client Pack 1.0 for Windows XP
    Hot Fix ID: KB873339
    Description: Windows XP Hotfix - KB873339
    Hot Fix ID: KB885835
    Description: Windows XP Hotfix - KB885835
    Hot Fix ID: KB885836
    Description: Windows XP Hotfix - KB885836
    Hot Fix ID: KB886185
    Description: Windows XP Hotfix - KB886185
    Hot Fix ID: KB887472
    Description: Windows XP Hotfix - KB887472
    Hot Fix ID: KB888302
    Description: Windows XP Hotfix - KB888302
    Hot Fix ID: KB890046
    Description: Security Update for Windows XP (KB890046)

"
57600,"I think there should be more use of continue!
Too often I come across code like:
for (...)
{
   if (!cond1)
   {
      if (!cond2)
      {
          ... highly indented lines ...
      }
   }
}

instead of 
for (...)
{
   if (cond1 || cond2)
   {
      continue;
   }

   ...
}

Use it to make the code more readable!
"
57730,"Your scheme is sound and achievable in VSS (although I would suggest you consider an alternative, VSS is really an outdated product).
For your ""CI"" Build - you would do the Versioning take a look at MSBuild Community Tasks Project which has a ""Version"" tasks.  Typically you will have a ""Version.txt"" in your source tree and the MSBuild task will increment the ""Release"" number while the developers control the Major.Minor.Release.Revision numbers (that's how a client of mine wanted it).  You can use revision if you prefer.
You then would have a ""FileUpdate"" tasks to edit the AssemblyInfo.cs file with that version, and your EXE's and ""DLL's"" will have the desired version.
Finally the VSSLabel task will label all your files appropriately.
For your ""Rebuild"" Build - you would modify your ""Get"" to get files from that Label, obviously not execute the ""Version"" task (as you are SELECTING a version to build) and then the FileUpdate tasks would use that version number.
Bonus question:
These are all ""how you want to use them"" - I would use build number for, well the build number, that is what I'd increment.  If you are using CI you'll have very many builds - the vast majority with no intention of ever deploying anywhere.
The major and minor are self evident - but revision I've always used for a ""Hotfix"" indicator.  I intend to have a ""1.3"" release - which would in reality be a product with say 1.3.1234.0 version.  While working on 1.4 - I find a bug - and need a hot fix as 1.3.2400.1. Then when 1.4 is ready - it would be say 1.4.3500.0
"
57790,"Right click on the file, select 'Open With' and choose ""Web Form Editor"" and click ""Set as Default"".
"
57800,"By default, SQL Server 2005 installation will create a security group called SQLServer2005MSSQLUser$ComputerName$MSSQLSERVER with the correct rights. You just need to create a domain user or local user and make it a member of that group. 
More details are available in the SQL Server Books Online: Reviewing Windows NT Rights and Privileges Granted for SQL Server Service Accounts
"
57840,"Check the Debug tab on your project's properties page. There should be an ""Enable unmanaged code debugging"" checkbox. This worked for me when we developed a new .NET UI for  our old c++ DLLs.
If your unmanaged DLL is being built from another project (for a while ours were being built using VS6) just make sure you have the DLL's pdb file handy for the debugging.
The other approach is to use the C# exe as the target exe to run from the DLL project, you can then debug your DLL normally.
"
57910,"You have to install scaffold templates with:
grails install-templates
Now, edit in src/templates/scaffolding Controller.groovy and increase the value params.max as you want
"
57990,"I can't say much for other IoC toolkits but I use Spring.Net and have found that there is a one off initial performance penalty at startup. Once the container has been configured the application runs unaffected.
"
58000,"I found that one of the undocumented requirements for using ant with Flexbuilder was to have the variable FLEX_HOME set within your ant script. Typically within build.xml have the following:
<!â Module properties â>
<property environment=âenvâ/>
<property name=âbuild.dirâ value=âbuildâ/>
<property name=âswf.nameâ value=âMyProjectSwfâ/>
<property name=âroot.mxmlâ value=âMain.mxmlâ/>
<property name=âlocaleâ value=âen_USâ/>
<property name=âFLEX_HOMEâ value=â${env.FLEX_HOME}â/>

This may seem like a hassle but it is a far more reasonable approach to obtaining consistency across platforms and environments if you are using multiple platforms for your developers.
HTH
"
58070,"If every method is just a static call straight to the data source, then the ""Posts"" class is really a Factory.  You could certainly put the static methods in ""Posts"" into the ""Post"" class (this is how CSLA works), but they are still factory methods.
I would say that a more modern and accurate name for the ""Posts"" class would be ""PostFactory"" (assuming that all it has is static methods).
I guess I wouldn't say this is a ""procedural"" approach necessarily -- it's just a misleading name, you would assume in the modern OO world that a ""Posts"" object would be stateful and provide methods to manipulate and manage a set of ""Post"" objects.
"
58190,"There are places for both well-written, well-thought-out T-SQL and CLR. If some function is not called frequently and if it required extended procedures in SQL Server 2000, CLR may be an option. Also running things like calculation right next to the data may be appealing. But solving bad programmers by throwing in new technology sounds like a bad idea.
"
58230,"http://cs-sdl.sourceforge.net/index.php/Main_Page is the solution I've come to love.  If you need 3d on top of it, you can use Tao.OpenGL to render inside it.  It's fast, industry standard (SDL, that is), and cross-platform.
"
58280,"Ok, Iâve done  a little more research into this now.
When you create a windows service in .Net, you create a class that inherits from System.ServiceProcess.ServiceBase (In VB this is hidden in the .Designer.vb file). You then override the OnStart and OnStop function, and OnPause and OnContinue if you choose to. 
These methods are invoked from within the base class so I did a little poking around with reflector.
OnStart is invoked by a method in System.ServiceProcess.ServiceBase called ServiceQueuedMainCallback.  The vesion on my machine ""System.ServiceProcess, Version=2.0.0.0"" decompiles like this:


Private Sub ServiceQueuedMainCallback(ByVal state As Object)
    Dim args As String() = DirectCast(state, String())
    Try 
        Me.OnStart(args)
        Me.WriteEventLogEntry(Res.GetString(""StartSuccessful""))
        Me.status.checkPoint = 0
        Me.status.waitHint = 0
        Me.status.currentState = 4
    Catch exception As Exception
        Me.WriteEventLogEntry(Res.GetString(""StartFailed"", New Object() { exception.ToString }), EventLogEntryType.Error)
        Me.status.currentState = 1
    Catch obj1 As Object
        Me.WriteEventLogEntry(Res.GetString(""StartFailed"", New Object() { String.Empty }), EventLogEntryType.Error)
        Me.status.currentState = 1
    End Try
    Me.startCompletedSignal.Set
End Sub


So because Me.OnStart(args) is called from within the Try portion of a Try Catch block I assume that anything that happens within the OnStart method is effectively wrapped by that Try Catch block and therefore any exceptions that occur aren't technically unhandled as they are actually handled in the ServiceQueuedMainCallback Try Catch. So CurrentDomain.UnhandledException never actually happens at least during the startup routine. 
The other 3 entry points (OnStop, OnPause and OnContinue) are all called from the base class in a similar way.
So I âthinkâ that explains why my Exception Handling component canât catch UnhandledException on Start and Stop, but Iâm not sure if it explains why timers that are setup in OnStart canât cause an UnhandledException when they fire. 
"
58300,"@Chris: There won't be a chance that Office 2007 will be available to manipulate the files. So far the only solution which comes close to what I am looking for is Aspose.Slides for .NET. The support for .pptx files is ""a work in progress"" though.
"
58340,"As for the testing itself, you're probably best off using the UI Automation framework. Or if you want a more fluent and wpf/winforms/win32/swt-independent way of using the framework, you could download White from Codeplex (provided that you're in a position to use open source code in your environment).
For the gotchas; If you're trying to unit test your views, you will probably run in to some threading issues. For instance, if you're running NUnit the default testrunner will run in MTA (Multi-Threaded Appartment), while as WPF needs to run as STA (Single-threaded Appartment). Mike Two has a real easy getting-started on unit testing WPF, but without considering the threading issue. Josh Smith has some thoughts on the threading issue in this post, and he also points to this article by Chris Hedgate. Chris uses a modified version of Peter Provost's CrossThreadTestRunner to wrap the MTA/STA issues in a bit more friendly way. 
"
58380,"To avoid seeing the messages, right-click on the output window and uncheck ""Exception Messages"".
However, seeing them happen might be nice, if you're interested in knowing when exceptions are thrown without setting breakpoints and reconfiguring the debugger.
"
58510,"I did use urlmon.dll in the end. I thought there would be an easier way but this works. I include the code to help anyone else and allow me to find it again if I need it.
using System.Runtime.InteropServices;

...
    [DllImport(@""urlmon.dll"", CharSet = CharSet.Auto)]
    private extern static System.UInt32 FindMimeFromData(
        System.UInt32 pBC,
        [MarshalAs(UnmanagedType.LPStr)] System.String pwzUrl,
        [MarshalAs(UnmanagedType.LPArray)] byte[] pBuffer,
        System.UInt32 cbSize,
        [MarshalAs(UnmanagedType.LPStr)] System.String pwzMimeProposed,
        System.UInt32 dwMimeFlags,
        out System.UInt32 ppwzMimeOut,
        System.UInt32 dwReserverd
    );

    public static string getMimeFromFile(string filename)
    {
        if (!File.Exists(filename))
            throw new FileNotFoundException(filename + "" not found"");

        byte[] buffer = new byte[256];
        using (FileStream fs = new FileStream(filename, FileMode.Open))
        {
            if (fs.Length >= 256)
                fs.Read(buffer, 0, 256);
            else
                fs.Read(buffer, 0, (int)fs.Length);
        }
        try
        {
            System.UInt32 mimetype;
            FindMimeFromData(0, null, buffer, 256, null, 0, out mimetype, 0);
            System.IntPtr mimeTypePtr = new IntPtr(mimetype);
            string mime = Marshal.PtrToStringUni(mimeTypePtr);
            Marshal.FreeCoTaskMem(mimeTypePtr);
            return mime;
        }
        catch (Exception e)
        {
            return ""unknown/unknown"";
        }
    }

"
58520,"I'd probably take a look at rsync.
Just create a .CMD file that contains the call to rsync with all the correct parameters and let people call that. rsync is very smart in deciding what part of files need to be transferred, so it'll be very fast even when large files are involved.
What rsync doesn't do though is conflict resolution (or even detection), but in the scenario you described it's more like reading from a central place which is what rsync is designed to handle.
"
58540,"To expand on the link given in the question:

Create a package variable
Double click on the package variable name. (This allows you to access the properties of the variable)
Set the property 'EvaluateAsExpression' to true
Enter the query in the expression builder.
Set the OLE DB source query to SQL Command from Variable

The expression builder can dynamically create expressions using variable to create 'parametised queries'.
So the following 'normal' query:
select * from book where book.BOOK_ID = ?

Can be written in the expression builder as:
""select * from book where book.BOOK_ID = "" + @[User::BookID]

You can then do null handling and data conversion using the expression builder.
"
58620,"This is what MSDN has to say: Design Specifications and Guidelines - Visual Design: Layout.
The default size of a button is 50x14 DLUs, which can be calculated to pixels using the examples shown for GetDialogBaseUnits.
The MapDialogRect function seems to do the calculation for you.
"
58630,"Quoted printable expands 8 bit characters to ""={HEX-Code}"", thus making the messages longer. Maybe you are just hitting this limit?
Have you tried to break the message at, say, 70 characters? That should provide space for a couple of characters per line.
Or you just encode the email with Base64 - all mail client can handle that.
Or you just set Content-Transfer-Encoding to 8bit and send the data unencoded. I know of no mail server unable to handle 8bit bytes these days.
"
58670,"I kind of like to use DeviceIOControl as it gives me the possibility to eject any kind of removable drive (such as USB and flash-disks as well as CD trays). Da codez to properly eject a disk using DeviceIOControl is (just add proper error-handling):
bool ejectDisk(TCHAR driveLetter)
{
  TCHAR tmp[10];
  _stprintf(tmp, _T(""\\\\.\\%c:""), driveLetter);
  HANDLE handle = CreateFile(tmp, GENERIC_READ, FILE_SHARE_WRITE, 0, OPEN_EXISTING, 0, 0);
  DWORD bytes = 0;
  DeviceIoControl(handle, FSCTL_LOCK_VOLUME, 0, 0, 0, 0, &bytes, 0);
  DeviceIoControl(handle, FSCTL_DISMOUNT_VOLUME, 0, 0, 0, 0, &bytes, 0);
  DeviceIoControl(handle, IOCTL_STORAGE_EJECT_MEDIA, 0, 0, 0, 0, &bytes, 0);
  CloseHandle(handle);
  return true;
}

"
58730,"LibHaru

Haru is a free, cross platform,
  open-sourced software library for
  generating PDF written in ANSI-C. It
  can work as both a static-library (.a,
  .lib) and a shared-library (.so,
  .dll).

Didn't try it myself, but maybe it can help you
"
58750,"No you can't get the raw logs, but there's nothing stopping you from getting the exact same data logged to your own web server logs.  Have a look at the Urchin code and borrow that, changing the following two lines to point to your web server instead.
var _ugifpath2=""http://www.google-analytics.com/__utm.gif"";
if (_udl.protocol==""https:"") _ugifpath2=""https://ssl.google-analytics.com/__utm.gif"";

You'll want to create a __utm.gif file so that they don't show up in the logs as 404s.
Obviously you'll need to parse the variables out of the hits into your web server logs.  The log line in Apache looks something like this.  You'll have lots of ""fun"" parsing out all the various stuff you want from that, but everything Google Analytics gets from the basic JavaScript tagging comes in like this.
127.0.0.1 - - [02/Oct/2008:10:17:18 +1000] ""GET /__utm.gif?utmwv=1.3&utmn=172543292&utmcs=ISO-8859-1&utmsr=1280x1024&utmsc=32-bit&utmul=en-us&utmje=1&utmfl=9.0%20%20r124&utmdt=My%20Web%20Page&utmhn=www.mydomain.com&utmhid=979599568&utmr=-&utmp=/urlgoeshere/&utmac=UA-1715941-2&utmcc=__utma%3D113887236.511203954.1220404968.1222846275.1222906638.33%3B%2B__utmz%3D113887236.1222393496.27.2.utmccn%3D(organic)%7Cutmcsr%3Dgoogle%7Cutmctr%3Dsapphire%2Btechnologies%2Bsite%253Arumble.net%7Cutmcmd%3Dorganic%3B%2B HTTP/1.0"" 200 35 ""http://www.mydomain.com/urlgoeshere/"" ""Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/525.19 (KHTML, like Gecko) Chrome/0.2.153.1 Safari/525.19""

"
58910,"You can call the command-line version of inkscape to do this:
http://harriyott.com/2008/05/converting-svg-images-to-png-in-c.aspx
Also there is a C# SVG rendering engine, primarily designed to allow SVG files to be used on the web on codeplex that might suit your needs if that is your problem:
Original Project
http://www.codeplex.com/svg
Fork with fixes and more activity: (added 7/2013)
https://github.com/vvvv/SVG
"
58940,"The short answer is: you can't do it.
From T-SQL there is no way to access multiple results of a nested stored procedure call, without changing the stored procedure as others have suggested.
To be complete, if the procedure were returning a single result, you could insert it into a temp table or table variable with the following syntax:
INSERT INTO #Table (...columns...)
EXEC MySproc ...parameters...

You can use the same syntax for a procedure that returns multiple results, but it will only process the first result, the rest will be discarded.
"
59000,"If you must do it programmatically, a way I've done it in the past is to inspect the url and look for ""https"" in it. Redirect if you don't see that. Request.IsSecureConnection should be the preferred method, however. You may have to add additional logic to handle a loopback address.
"
59080,"
You may be running into concurrency issues, depending on how your application runs. Try performing your reads with the ""nolock"" keyword. 
Try adding in table aliases for your columns (and avoid the use of SELECT *), this helps out MSSQL, as it doesn't have to ""guess"" which table the columns come from. 
If you aren't already, move to SPROCs, this allows MSSQL to index your data better for a given query's normal result set.
Try following the execution plan of your SPROCS to ensure they are using the indexes you think they are.
Run a trace against your database to see what the incoming requests look like. You may notice a particular SPROC is being run over and over: generally a good sign to cache the responses on the client if possible. (lookup lists, etc.)

"
59130,"A couple of things that I've learned:

Absolutely and brutally minimize the number of images you have that contain text. Doing so will make your life a billion percent easier since you won't have to get a new set of images for every friggin' language.
Be very wary of css positioning that relies on things always remaining the same size. If  those things contain text, they will not remain the same size, and you will then need to go back and fix your designs.
If you use character types in your sql tables, make sure that any of those that might receive international input are unicode (nchar, nvarchar, ntext). For that matter, I would just standardize on using the unicode versions.
If you're building SQL queries dynamically, make sure that you include the N prefix before any quoted text if there's any chance that text might be unicode. If you end up putting garbage in a SQL table, check to see if that's there.
Make sure that all your web pages definitively state that they are in a unicode format. See Joel's article, mentioned above.
You're going to be using resource files a lot for this project. That's good - ASP.NET 2.0 has great support for such. You'll want to look into the App_LocalResources and App_GlobalResources folder as well as GetLocalResourceObject, GetGlobalResourceObject, and the concept of meta:resourceKey. Chapter 30 of Professional ASP.NET 2.0 has some great content regarding that. The 3.5 version of the book may well have good content there as well, but I don't own it.
Think about fonts. Many of the standard fonts you might want to use aren't unicode capable. I've always had luck with Arial Unicode MS, MS Gothic, MS Mincho. I'm not sure about how cross-platform these are, though. Also, note that not all fonts support all of the Unicode character definition. Again, test, test, test.
Start thinking now about how you're going to get translations into this system. Go talk to whoever is your translation vendor about how they want data passed back and forth for translation. Think about the fact that, through your local resource files, you will likely be repeating some commonly used strings through the system. Do you normalize those into global resource files, or do you have some sort of database layer where only one copy of each text used is generated. In our recent project, we used resource files which were generated from a database table that contained all the translations and the original, english version of the resource files. 
Test. Generally speaking I will test in German, Polish, and an Asian language (Japanese, Chinese, Korean). German and Polish are wordy and nearly guaranteed to stretch text areas, Asian languages use an entirely different set of characters which tests your unicode support.

"
59180,"Go into the install directory of web data admin, usually:
C:\Program Files\Microsoft SQL Server Tools\Microsoft SQL Web Data Administrator
Then in the ""Web"" folder open the file ""QueryDatabase.aspx"" and edit the following line:
<%@ Page language=""c#"" Codebehind=""QueryDatabase.aspx.cs"" AutoEventWireup=""false"" Inherits=""SqlWebAdmin.query"" %>
Add ValidateRequest=""false"" to the end of it like so:
<%@ Page language=""c#"" Codebehind=""QueryDatabase.aspx.cs"" AutoEventWireup=""false"" Inherits=""SqlWebAdmin.query"" ValidateRequest=""false"" %>
NOTE: THIS IS POTENTIALLY DANGEROUS!! Be Careful!
"
59220,"Couple of options here:

Attach to AppDomain.AssemblyResolve and do another LoadFile based on the requested assembly.
Spin up another AppDomain with the directory as its base and load the assemblies in that AppDomain.

I'd highly recommend pursuing option 2, since that will likely be cleaner and allow you to unload all those assemblies after. Also, consider loading assemblies in the reflection-only context if you only need to reflect over them (see Assembly.ReflectionOnlyLoad).
"
59270,"I recently spent a few days working on automating deployments at my company. 
We use a combination of CruiseControl, NAnt, MSBuild to generate a release version of the app. Then a separate script uses MSDeploy and XCopy to backup the live site and transfer the new files over. 
Our solution is briefly described in an answer to this question http://stackoverflow.com/questions/45783/automate-deployment-for-web-applications
"
59280,"You want ComboBox_SetCurSel:
ComboBox_SetCurSel(hWndCombo, n);

or if it's an MFC CComboBox control you can probably do:
m_combo.SetCurSel(2);

I would imagine if you're doing it manually you would also want SendMessage rather than PostMessage. CBN_SELCHANGE is the notification that the control sends back to you when the selection is changed.
Finally, you might want to add the c++ tag to this question.
"
59380,"Your .htaccess does nothing useful, as Apache is probably configured with DirectoryIndex index.php. Well, it does move domain.com/a  to domain.com/index.php, but I doubt that is what you want.
Your wildcard virtualhost works because you probably have ServerAlias *.domain.com in your configuration, or a single virtualhost and DNS pointing to the address of your server. (When you have a single virtualhost, it shows up for any request, and the first listed virtualhost is the default one)
You have to create new VirtualHosts for the static domains, leaving the default one as, well, the default one :)
Check these tutorials that explain it all.
"
59390,"It won't matter to specify ""variables"" when you create the variable, because foo will be placed in the variables scope by default; but it will matter when you access the variable.
<cfcomponent>
    <cfset foo = ""a private instance variable"">

    <cffunction name=""doSomething"">
    	<cfargument name=""foo"" required=""yes""/>
        <cfset var bar = ""a function local variable"">
        <cfreturn ""I have #foo# and #bar#."">
    </cffunction>

    <cffunction name=""doAnotherThing"">
    	<cfargument name=""foo"" required=""yes""/>
        <cfset var bar = ""a function local variable"">
        <cfreturn ""I have #variables.foo# and #bar#."">
    </cffunction>

</cfcomponent>

doSomething(""args"") returns ""I have args and a function local variable""
doAnotherThing(""args"") returns ""I have a private instance of a variable and a function local variable.""
"
59560,"
I believe that CAPTCHA is dying. If someone really wants to break it, it will be broken. I read (somewhere, don't remember where) about a site that gave you free porn in exchange for answering CAPTCHAs to they can be rendered obsolete by bots. So, why bother?

Anyone who really wants to break this padlock can use a pair of bolt cutters, so why bother with the lock?
Anyone who really wants to steal this car can drive up with a tow truck, so why bother locking my car?
Anyone who really wants to open this safe can cut it open with an oxyacetylene torch, so why bother putting things in the safe?
Because using the padlock, locking your car, putting valuables in a safe, and using a CAPTCHA weeds out a large spectrum of relatively unsophisticated or unmotivated attackers.  The fact that it doesn't stop sophisticated, highly motivated attackers doesn't mean that it doesn't work at all.  Using a CAPTCHA isn't going to stop all spammers, but it's going to tremendously reduce the amount that requires filtering or manual intervention.  
Heck look at the lame CAPTCHA that Jeff uses on his blog.  Even a wimpy barrier like that still provides a lot of protection.
"
59590,"
When should the lock be used?

A lock should be used to protect shared resources in multithreaded code.  Not for anything else.

But is it necessary when the application does not spin off any other threads?

Absolutely not.  It's just a time waster.  However do be sure that you're not implicitly using system threads.  For example if you use asynchronous I/O you may receive callbacks from a random thread, not your original thread.

Is there performance issues with using lock?

Yes.  They're not very big in a single-threaded application, but why make calls you don't need?

...if that is a good design pattern to follow in the future[?]

Locking everything willy-nilly is a terrible design pattern.  If your code is cluttered with random locking and then you do decide to use a background thread for some work, you're likely to run into deadlocks.  Sharing a resource between multiple threads requires careful design, and the more you can isolate the tricky part, the better.
"
59670,"Any functions into which you pass string literals ""I am a string literal"" should use char const * as the type instead of char*.
If you're going to fix something, fix it right.
"
59680,"Set s = New NotesSession
Set db = s.CurrentDatabase

If db.Server <> """" Then
  Set sName = New NotesName(db.Server)
Else
  Set sName = New NotesName(s.Username)
End If

"
59790,"In an attempt to try and help, we may need some clarification. Maybe by restating the problem you can let us know if this is what you're asking:
How can one import existing xml into a SQL 2005 database, without relying on the built-in xml type?
A fairly straight forward solution that you already mentioned is the sp_xml_preparedocument, combined with openxml. 
Hopefully the following example illustrates the correct usage. For a more complete example checkout the MSDN docs on Using OPENXML.
declare @XmlDocumentHandle int
declare @XmlDocument nvarchar(1000)
set @XmlDocument = N'<ROOT>
<Customer>
   <FirstName>Will</FirstName>
   <LastName>Smith</LastName>
</Customer>
</ROOT>'

-- Create temp table to insert data into
create table #Customer 
( 
    FirstName varchar(20),
    LastName varchar(20) 
)
-- Create an internal representation of the XML document.
exec sp_xml_preparedocument @XmlDocumentHandle output, @XmlDocument

-- Insert using openxml allows us to read the structure
insert into #Customer
select 
    FirstName = XmlFirstName,
    LastName = XmlLastName
from openxml ( @XmlDocumentHandle, '/ROOT/Customer',2 )
with 
(
    XmlFirstName  varchar(20) 'FirstName',
    XmlLastName varchar(20) 'LastName'
)
where ( XmlFirstName = 'Will' and XmlLastName = 'Smith' )

-- Cleanup xml document
exec sp_xml_removedocument @XmlDocumentHandle

-- Show the data
select * 
from #Customer

-- Drop tmp table
drop table #Customer

If you have an xml file and are using C#, then defining a stored procedure that does something like the above and then passing the entire xml file contents to the stored procedure as a string should give you a fairly straight forward way of importing xml into your existing table(s).
"
59840,"The more I look at it, and after running more tests, I'm thinking the bug may be in the Sql Server Query Visualizer plugin for Visual Studio, not actually in Linq to SQL itself. So it is not nearly as bad a situation as I thought - the query will return the right results, but you can't trust what the Visualizer is showing. Not great, but better than what I thought was going on.
"
59850,"Declare it like this
<bean id=""doubleValue"" class=""java.lang.Double"">
    <constructor-arg index=""0"" value=""3.7""/>
</bean>

And use like this
<bean id=""someOtherBean"" ...>
    <property name=""value"" ref=""doubleValue""/>
</bean>

"
59880,"
NOTE that this is a general look at stored procedures not regulated to a specific
  DBMS. Some DBMS (and even, different
  versions of the same DBMS!) may operate
  contrary to this, so you'll want to
  double-check with your target DBMS
  before assuming all of this still holds.
I've been a Sybase ASE, MySQL, and SQL Server DBA on-and off since for almost a decade (along with application development in C, PHP, PL/SQL, C#.NET, and Ruby). So, I have no particular axe to grind in this (sometimes) holy war.

The historical performance benefit of stored procs have generally been from the following (in no particular order):

Pre-parsed SQL
Pre-generated query execution plan
Reduced network latency
Potential cache benefits

Pre-parsed SQL -- similar benefits to compiled vs. interpreted code, except on a very micro level. 
Still an advantage? 
Not very noticeable at all on the modern CPU, but if you are sending a single SQL statement that is VERY large eleventy-billion times a second, the parsing overhead can add up.
Pre-generated query execution plan. 
If you have many JOINs the permutations can grow quite unmanageable (modern optimizers have limits and cut-offs for performance reasons). It is not unknown for very complicated SQL to have distinct, measurable (I've seen a complicated query take 10+ seconds just to generate a plan, before we tweaked the DBMS) latencies due to the optimizer trying to figure out the ""near best"" execution plan. Stored procedures will, generally, store this in memory so you can avoid this overhead.
Still an advantage? 
Most DBMS' (the latest editions) will cache the query plans for INDIVIDUAL SQL statements, greatly reducing the performance differential between stored procs and ad hoc SQL. There are some caveats and cases in which this isn't the case, so you'll need to test on your target DBMS.
Also, more and more DBMS allow you to provide optimizer path plans (abstract query plans) to significantly reduce optimization time (for both ad hoc and stored procedure SQL!!).

WARNING Cached query plans are not a performance panacea. Occasionally the query plan that is generated is sub-optimal.
  For example, if you send SELECT *
  FROM table WHERE id BETWEEN 1 AND
  99999999, the DBMS may select a
  full-table scan instead of an index
  scan because you're grabbing every row
  in the table (so sayeth the
  statistics). If this is the cached
  version, then you can get poor
  performance when you later send
  SELECT * FROM table WHERE id BETWEEN
  1 AND 2. The reasoning behind this is
  outside the scope of this posting, but
  for further reading see:
  http://www.microsoft.com/technet/prodtechnol/sql/2005/frcqupln.mspx
  and
  http://msdn.microsoft.com/en-us/library/ms181055.aspx
  and http://www.simple-talk.com/sql/performance/execution-plan-basics/
""In summary, they determined that
  supplying anything other than the
  common values when a compile or
  recompile was performed resulted in
  the optimizer compiling and caching
  the query plan for that particular
  value. Yet, when that query plan was
  reused for subsequent executions of
  the same query for the common values
  (âMâ, âRâ, or âTâ), it resulted in
  sub-optimal performance. This
  sub-optimal performance problem
  existed until the query was
  recompiled. At that point, based on
  the @P1 parameter value supplied, the
  query might or might not have a
  performance problem.""

Reduced network latency
A) If you are running the same SQL over and over -- and the SQL adds up to many KB of code -- replacing that with a simple ""exec foobar"" can really add up.
B) Stored procs can be used to move procedural code into the DBMS. This saves shuffling large amounts of data off to the client only to have it send a trickle of info back (or none at all!). Analogous to doing a JOIN in the DBMS vs. in your code (everyone's favorite WTF!)
Still an advantage?
A) Modern 1Gb (and 10Gb and up!) Ethernet really make this negligible. 
B) Depends on how saturated your network is -- why shove several megabytes of data back and forth for no good reason?
Potential cache benefits
Performing server-side transforms of data can potentially be faster if you have sufficient memory on the DBMS and the data you need is in memory of the server.
Still an advantage?
Unless your app has shared memory access to DBMS data, the edge will always be to stored procs.
Of course, no discussion of Stored Procedure optimization would be complete without a discussion of parameterized and ad hoc SQL.
Parameterized / Prepared SQL
Kind of a cross between stored procedures and ad hoc SQL, they are embedded SQL statements in a host language that uses ""parameters"" for query values, e.g.:
SELECT .. FROM yourtable WHERE foo = ? AND bar = ?

These provide a more generalized version of a query that modern-day optimizers can use to cache (and re-use) the query execution plan, resulting in much of the performance benefit of stored procedures.
Ad Hoc SQL
Just open a console window to your DBMS and type in a SQL statement. In the past, these were the ""worst"" performers (on average) since the DBMS had no way of pre-optimizing the queries as in the parameterized/stored proc method.
Still a disadvantage?
Not necessarily. Most DBMS have the ability to ""abstract"" ad hoc SQL into parameterized versions -- thus more or less negating the difference between the two. Some do this implicitly or must be enabled with a command setting (SQL server: http://msdn.microsoft.com/en-us/library/ms175037.aspx , Oracle: http://www.praetoriate.com/oracle_tips_cursor_sharing.htm).
Lessons learned?
Moore's law continues to march on and DBMS optimizers, with every release, get more sophisticated. Sure, you can place every single silly teeny SQL statement inside a stored proc, but just know that the programmers working on optimizers are very smart and are continually looking for ways to improve performance. Eventually (if it's not here already) ad hoc SQL performance will become indistinguishable (on average!) from stored procedure performance, so any sort of massive stored procedure use ** solely for ""performance reasons""** sure sounds like premature optimization to me.
Anyway, I think if you avoid the edge cases and have fairly vanilla SQL, you won't notice a difference between ad hoc and stored procedures.
"
60000,"C++03 std, Â§4.11 2 Pointer to member conversions:

An rvalue of type âpointer to member of B of type cv T,â where B is a class type, can be converted to an rvalue of type âpointer to member of D of type cv T,â where D is a derived class (clause 10) of B. If B is an inaccessible (clause 11), ambiguous (10.2) or virtual (10.1) base class of D, a program that necessitates this conversion is ill-formed. The result of the conversion refers to the same member as the pointer to member before the conversion took place, but it refers to the base class member as if it were a member of the derived class. The result refers to the member in Dâs instance of B. Since the result has type âpointer to member of D of type cv T,â it can be dereferenced with a D object. The result is the same as if the pointer to member of B were dereferenced with the B sub-object of D.   The null member pointer value is converted to the null member pointer value of the destination type. 52)
52)The rule for conversion of pointers to members (from pointer to member of base to pointer to member of derived) appears inverted compared to the rule for pointers to objects (from pointer to derived to pointer to base) (4.10, clause 10). This inversion is necessary to ensure type safety. Note that a pointer to member is not a pointer to object or a pointer to function and the rules for conversions of such pointers do not apply to pointers to members. In particular, a pointer to member cannot be converted to a void*.

In short, you can convert a pointer to a member of an accessible, non-virtual base class to a pointer to a member of a derived class as long as the member isn't ambiguous. 
class A {
public: 
    void foo();
};
class B : public A {};
class C {
public:
    void bar();
};
class D {
public:
    void baz();
};
class E : public A, public B, private C, public virtual D {
public: 
    typedef void (E::*member)();
};
class F:public E {
public:
    void bam();
};
...
int main() {
   E::member mbr;
   mbr = &A::foo; // invalid: ambiguous; E's A or B's A?
   mbr = &C::bar; // invalid: C is private 
   mbr = &D::baz; // invalid: D is virtual
   mbr = &F::bam; // invalid: conversion isn't defined by the standard
   ...

Conversion in the other direction (via static_cast) is governed by Â§ 5.2.9 9:

An rvalue of type ""pointer to member of D of type cv1 T"" can be converted to an rvalue of type ""pointer to member of B of type cv2 T"", where B is a base class (clause 10 class.derived) of D, if a valid standard conversion from ""pointer to member of B of type T"" to ""pointer to member of D of type T"" exists (4.11 conv.mem), and cv2 is the same cv-qualification as, or greater cv-qualification than, cv1.11) The null member pointer value (4.11 conv.mem) is converted to the null member pointer value of the destination type. If class B contains the original member, or is a base or derived class of the class containing the original member, the resulting pointer to member points to the original member.  Otherwise, the result of the cast is undefined. [Note: although class B need not contain the original member, the dynamic type of the object on which the pointer to member is dereferenced must contain the original member; see 5.5 expr.mptr.oper.]
11) Function types (including those used in pointer to member function
    types) are never cv-qualified; see 8.3.5 dcl.fct.

In short, you can convert from a derived D::* to a base B::* if you can convert from a B::* to a D::*, though you can only use the B::* on objects that are of type D or are descended from D.
"
60030,"javascript:resizeTo(1024,768);
vbscript:resizeto(1024,768)
Will work in IE7, But consider using something like
javascript:moveTo(0,0);resizeTo(1024,768);
because IE7 doesn't allow the window to ""resize"" beyond the screen borders. If you work on a 1024,768 desktop, this is what happens...Firefox: 1024x768 Window, going behind the taskbar. If you drop the moveTo part, the top left corner of the window won't change position.(You still get a 1024x768 window)
IE7: As close as possible to the requested size without obscuring the taskbar or allowing any part of the window to lie beyond the screen borders.
safari: As close as possible to the requested size without obscuring the taskbar or allowing any part of the window to lie beyond the screen borders, but you can ommit the moveTo part. Safari will move the top left corner of the window for you.
Opera: Nothing happens.
Chrome: Nothing happens.

"
60070,"As far as I know a process doesn't have an explicit list of its children's PIDs, but it can easily be built, since a process should know which child processes it spawns. For example the UNIX fork() call returns the child PID in the parent process and 0 in the child process, CreateProcess() on Windows returns (IIRC) the PID of the new process created.
"
60100,"I like to start refactoring when I need to, rather than the first opportunity that I get. You might say this is somewhat of an agile approach to refactoring. When do I feel I need to? Usually when I feel that the ugly parts of my codes are starting to spread. I think ugliness is okay as long as they are contained, but the moment when they start having the urge to spread, that's when you need to take care of business. 
The techniques you use for refactoring should start with the simplest. I would strongly recommand Martin Fowler's book. Combining common code into functions, removing unneeded variables, and other simple techniques gets you a lot of mileage. For list operations, I prefer using functional programming idioms. That is to say, I use internal iterators, map, filter and reduce(in python speak, there are corresponding things in ruby, lisp and haskell) whenever I can, this makes code a lot shorter and more self-contained.
"
60160,"Since Java 1.5, yes:
Pattern.quote(""$5"");

"
60260,"Siebel gives an extensive rundown (for simple cases anyway) of possible sources of leaks, and there aren't any of those here. Both value and factor are evaluated only once and in order, and rem doesn't have any side effects.
This is not good Lisp though, because there's no reason to use a macro in this case. A function
(defun multp (value factor)
  (zerop (rem value factor)))

is identical for all practical purposes. (Note the use of zerop. I think it makes things clearer in this case, but in cases where you need to highlight, that the value you're testing might still be meaningful if it's something other then zero, (= ... 0) might be better)
"
60290,"Here's some good information about image opacity and transparency with CSS.
So to make an image with opacity 50%, you'd do this:
<img src=""image.png"" style=""opacity: 0.5; filter: alpha(opacity=50)"" />

The opacity: part is how Firefox does it, and it's a value between 0.0 and 1.0. filter: is how IE does it, and it's a value from 0 to 100.
"
60330,"It's more of a browse assist than a search assist.  If you see a large or bold tag in a tag cloud that interests you it my lead to some knowledge discovery that wouldn't have otherwise been sought out with a deliberate search.  When I am browsing del.ico.us or stackoverflow I appreciate the tags as they sometimes lead me to discover related topics.
Wikipedia has an interesting definition:

A tag cloud or word cloud (or weighted list in visual design) is a visual depiction of user-generated tags, or simply the word content of a site, used typically to describe the content of web sites. Tags are usually single words and are typically listed alphabetically, and the importance of a tag is shown with font size or color. [1] Thus both finding a tag by alphabet and by popularity is possible. The tags are usually hyperlinks that lead to a collection of items that are associated with a tag.

"
60360,"You could use all those libraries, but I highly recommend against it. Downloading and executing that much JavaScript will most likely choke the browser and slow down your user's experience. It would be much better from a user's perspective and a developer's to pick one. Less context/architecture switching and less code to maintain.
Like other answers have said, most don't conflict. 
See Yahoo!'s Exceptional Performance site for more info. 
"
60470,"I think classes are lazy loaded in applets. being loaded on demand.
Anyway, if the classes are outside of a jar you can simply use the applet classloader and load them by name. Ex:
ClassLoader loader = this.getClass().getClassLoader();
Class clazz = loader.loadClass(""acme.AppletAddon"");

If you want to load classes from a jar I think you will need to create a new instance of URLClassLoader with the url(s) of the jar(s).
URL[] urls = new URL[]{new URL(""http://localhost:8080/addon.jar"")};
URLClassLoader loader = URLClassLoader.newInstance(urls,this.getClass().getClassLoader());
Class clazz = loader.loadClass(""acme.AppletAddon"");

By default, applets are forbidden to create new classloaders. But if you sign your applet and include permission to create new classloaders you can do it.
"
60570,"I think most people refer to this as the Handle Body idiom. See James Coplien's book Advanced C++ Programming Styles and Idioms (Amazon link). It's also known as the Cheshire Cat because of Lewis Caroll's character that fades away until only the grin remains.
The example code should be distributed across two sets of source files. Then only Cat.h is the file that is shipped with the product.
CatImpl.h is included by Cat.cpp and CatImpl.cpp contains the implementation for CatImpl::Purr(). This won't be visible to the public using your product.
Basically the idea is to hide as much as possible of the implementation fom prying eyes.
This is most useful where you have a commercial product that is shipped as a series of libraries that are accessed via an API that the customer's code is compiled against and linked to.
We did this with the rewrite of IONAs Orbix 3.3 product in 2000.
As mentioned by others, using his technique completely decouples the implementation from the interface of the object. Then you won't have to recompile everything that uses Cat if you just want to change the implementation of Purr().
This technique is used in a methodology called design by contract.
"
60590,"You can also do a meta refresh, which most browsers support.  Download.com places one in a noscript tag.
<meta http-equiv=""refresh"" content=""5;url=/download.php?doc=123.zip""/>

"
60620,"Yes there is tooling support for Visual Studio. It is still in Beta though.
Get Started Building Silverlight 2 Applications
1) Install Visual Studio 2008 then Install Silverlight Tools Beta 2 for Visual Studio 2008
This add-on to Visual Studio 2008 allows you to use .NET to create Silverlight 2 Beta 2 Web sites. The Silverlight 2 Beta 2 Runtime and the Silverlight 2 Beta 2 SDK are installed as part of this install. For additional information read the overview and the Silverlight 2 Beta 2 Readme Notes. Note if you have Visual Studio 2008 Service Pack 1 Beta installed, please see this information for details on installing correctly. 
2) Install Expression Blend 2.5 June 2008 Preview
This is a preview version of Expression Blend for designing Silverlight 2 experiences. 
3) Install Deep Zoom Composer
This tool allows you to prepare your images for use with the Deep Zoom feature in Silverlight 2. 
One thing to watch out for is that Silverlight does not support Synchronous calls to the server. All calls are Asynchronous as of this Beta.
"
60650,"Asp.net Postbacks are initiated from the client (typically form submission). I am not sure what you are trying to achieve. Some of the server side page lifecyle events are already executed and what you are trying to do is raise the previous event handlers again.
"
60680,"Sure; just start two different servers on two different ports in two different threads that each use the same handler.  Here's a complete, working example that I just wrote and tested.  If you run this code then you'll be able to get a Hello World webpage at both http://localhost:1111/ and http://localhost:2222/
from threading import Thread
from SocketServer import ThreadingMixIn
from BaseHTTPServer import HTTPServer, BaseHTTPRequestHandler

class Handler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.send_header(""Content-type"", ""text/plain"")
        self.end_headers()
        self.wfile.write(""Hello World!"")

class ThreadingHTTPServer(ThreadingMixIn, HTTPServer):
    pass

def serve_on_port(port):
    server = ThreadingHTTPServer((""localhost"",port), Handler)
    server.serve_forever()

Thread(target=serve_on_port, args=[1111]).start()
serve_on_port(2222)

"
60720,"Yes. The easiest way is to raise the value as a string. Like so: raise @foo.to_s
Or, you can install the debugger (gem install ruby-debug), and then start the development server with the --debugger flag. Then, in your code, call the debugger instruction.
Inside the debugger prompt, you have many commands, including p to print the value of a variable.
Update: here's a bit more about ruby-debug.
"
60740,"I'm using jquery.pngFix.js.  I don't know if it's officially sanctioned or not, I do know that it works.  I chose it because it was the plugin included with FancyBox, no other reason.  
"
60800,"It's been a while since I ran linux, but try looking for the x64 version. There are also x64 to x86 compatibility libraries available that should make 32 bit programs work for most situations. 
The ubuntu forums are a much better place for this question, however. 
"
60820,"If you are not trying to do it in code itself, which I'm assuming based on your ANTS reference, try taking a look at CLRProfiler (currently v2.0). It's free and if you don't mind the rather simplistic UI, it can provide valuable information. It will give you a in-depth overview of all kinds of stats. I used it a while back as one tool for finding a memory leek.
Download here: http://www.microsoft.com/downloads/details.aspx?FamilyId=A362781C-3870-43BE-8926-862B40AA0CD0&displaylang=en
If you do want to do it in code, the CLR has profiling APIs you could use. If you find the information in CLRProfiler, since it uses those APIs, you should be able to do it in code too. More info here:
http://msdn.microsoft.com/de-de/magazine/cc300553(en-us).aspx
(It's not as cryptic as using WinDbg, but be prepared to do mighty deep into the CLR.)
"
60830,"It worth pointing out that the inline keyword is actually just a hint to the compiler. The compiler may ignore the inline and simply generate code for the function someplace.
The main drawback to inline functions is that it can increase the size of your executable (depending on the number of instantiations).  This can be a problem on some platforms (eg. embedded systems), especially if the function itself is recursive.
I'd also recommend making inline'd functions very small - The speed benefits of inline functions tend to diminish as the function grows in size. At some point the overhead of the function call becomes small compared to the execution of the function body, and the benefit is lost.
"
60910,"In Aquamacs 2.1, you can set the font through Options->Appearance->Font for Text Mode...   That brings up the standard font chooser window, choose the font you like.  Then, when you exit out of emacs (C-x C-c) you'll be prompted to save options, hit ""y"".
"
60920,"Depending on what you're doing, you might want to move the audit out of the data layer into the data access layer.  It give you more control.
I asked a similar question wrt NHibernate and SqlServer here.
"
60950,"Sorry for the self-promotion, I'm the author of another Console Emulator, not mentioned here.
ConEmu is opensource console emulator with tabs, which represents multiple consoles and simple GUI applications as one customizable GUI window.
Initially, the program was designed to work with Far Manager (my favorite shell replacement - file and archive management, command history and completion, powerful editor). But ConEmu can be used with any other console application or simple GUI tools (like PuTTY for example). ConEmu is a live project, open to suggestions.
A brief excerpt from the long list of options:

Latest versions of ConEmu may set up itself as default terminal for Windows
Use any font installed in the system, or copied to a folder of the program (ttf, otf, fon, bdf)
Run selected tabs as Administrator (Vista+) or as selected user
Windows 7 Jump lists and Progress on taskbar
Integration with DosBox (useful in 64bit systems to run DOS applications)
Smooth resize, maximized and fullscreen window modes
Scrollbar initially hidden, may be revealed by mouseover or checkbox in settings
Optional settings (e.g. pallette) for selected applications
User friendly text and block selection (from keyboard or mouse), copy, paste, text search in console
ANSI X3.64 and Xterm 256 color

Far Manager users will acquire shell style drag-n-drop, thumbnails and tiles in panles, tabs for editors and viewers, true colors and font styles (italic/bold/underline).
PS. Far Manager supports UNC paths (\\server\share\...)
"
61000,"After a couple years working with different structures I recently found a structure that hols most variations for me:
/project_name     (everything goes here)
  /web            (htdocs)
    /img
    /css
  /app            (usually some framework or sensitive code)
  /lib            (externa libs)
    /vendor_1
    /vendor_2
  /tmp
    /cache
  /sql            (sql scripts usually with maybe diagrams)
  /scripts
  /doc            (usually an empty directory)

"
61110,"The perfect solution for this is to use log4net with a console appender and a file appender.  There are many other appenders available as well.  It also allows you to turn the different appenders off and on at runtime. 
"
61150,"PowerMock is another mock framework that extends EasyMock and Mockito. With PowerMock you can easily remove unwanted behavior from a class, for example a static initializer. In your example you simply add the following annotations to your JUnit test case:
@RunWith(PowerMockRunner.class)
@SuppressStaticInitializationFor(""some.package.ClassWithStaticInit"")

PowerMock does not use a Java agent and therefore does not require modification of the JVM startup parameters. You simple add the jar file and the above annotations. 
"
61180,"hmm..Interestingly 

Mozilla seems to provide ActiveX control
K-Melon is another Gecko based browser control

"
61240,"http://www.fckeditor.net/ ?
EDIT: Just found this: http://blog.newt.cz/blog/integration-fckeditor-django/
"
61250,"There's the Yahoo Grid CSS which can do all sorts of things. But remember: CSS IS NOT A RELIGION. If you save hours by using tables instead of css, do so. 
One of the corner cases I could never make my mind up about is forms. I'd love to do it in css, but it's just so much more complicated than tables. You could even argue that forms are tables, in that they have headers (labels) and data (input fields). 
"
61320,"Both are very similar but Subversive is the ""eclipse svn provider"". I primarily use Subversive because of a few convenient features:
Grouping of history
When I'm browsing the history of a branch instead of just seeing a bunch of rows for every commit it can group commits by today, week, etc.
Mapping of trunk, branches, and tags
Subversive assumes the default svn layout: trunk, branches, tags (which you can change), so whenever you want to tag or branch it is one click and you provide the name of the tag or branch.
Like I said these are minor differences that I just find convenient. Both work great with mylyn, but overall there really isn't a whole lot of differences with these two extensions.
Merging with Subversive is a pain though (haven't tried Subclipse), I've never been able to successfully merge. The preview of the merge is great but it would never complete the merge or it will take way to long. Most of the time I complete merging through the command line without any issues.
"
61400,"Let me begin by plugging sources - Pragmatic Unit Testing in Java with JUnit (There's a version with C#-Nunit too.. but I have this one.. its agnostic for the most part. Recommended.)
Good Tests should be A TRIP (The acronymn isn't sticky enough - I have a printout of the cheatsheet in the book that I had to pull out to make sure I got this right..)

Automatic : Invoking of tests as well as checking results for PASS/FAIL should be automatic
Thorough: Coverage; Although bugs tend to cluster around certain regions in the code, ensure that you test all key paths and scenarios.. Use tools if you must to know untested regions
Repeatable: Tests should produce the same results each time.. every time. Tests should not rely on uncontrollable params.
Independent: Very important. 

Tests should test only one thing at a time. Multiple assertions are okay as long as they are all testing one feature/behavior. When a test fails, it should pinpoint the location of the problem.
Tests should not rely on each other - Isolated. No assumptions about order of test execution. Ensure 'clean slate' before each test by using setup/teardown appropriately

Professional: In the long run you'll have as much test code as production (if not more), therefore follow the same standard of good-design for your test code. Well factored methods-classes with intention-revealing names, No duplication, tests with good names, etc. 
Good tests also run Fast. any test that takes over half a second to run.. needs to be worked upon. The longer the test suite takes for a run.. the less frequently it will be run. The more changes the dev will try to sneak between runs.. if anything breaks.. it will take longer to figure out which change was the culprit.

Update 2010-08:

Readable : This can be considered part of Professional - however it can't be stressed enough. An acid test would be to find someone who isn't part of your team and asking him/her to figure out the behavior under test within a couple of minutes. Tests need to be maintained just like production code - so make it easy to read even if it takes more effort. Tests should be symmetric (follow a pattern) and concise (test one behavior at a time). Use a consistent naming convention (e.g. the TestDox style). Avoid cluttering the test with ""incidental details"".. become a minimalist.

Apart from these, most of the others are guidelines that cut down on low-benefit work: e.g. 'Don't test code that you don't own' (e.g. third-party DLLs). Don't go about testing getters and setters. Keep an eye on cost-to-benefit ratio or defect probability.
"
61480,"The aim of the new automatic properties is to reduce the amount of boilerplate code you need to write when you just have a simple property that doesn't need any special logic in the get or the set. 
If you want to access the private member that these properties use, that's usually for a few reasons:

You need to more than just a simple get/set - in this case, you should just avoid using automatic properties for this member.
You want to avoid the performance hit of going through the get or set and just use the member directly - in this case, I'd be surprised if there really was a performance hit. The simple get/set members are very very easy to inline, and in my (admittedly limited) testing I haven't found a difference between using the automatic properties and accessing the member directly. 
You only want to have public read access (i.e. just a 'get') and the class write to the member directly - in this case, you can use a private set in your automatic property. i.e.
public class MyClass
{
    public int Age {get; private set;} 
}

This usually covers most the reasons for wanting to directly get to the backing field used by the automatic properties.
"
61520,"I've been using db4o which is an OODB and it solves most of the cons listed:

Familiarity - Programmers know their language better then SQL (see Native queries)
Performance - this one is highly subjective but you can take a look at PolePosition
Vendor support and maturity - can change over time
Cannot be used by programs that don't also use the same framework - There are OODB standards and you can use different frameworks
Versioning is probably a bit of a bitch - Versioning is actually easier!

The pros I'm interested in are:

Native queries - Db4o lets you write queries in your static typed language so you don't have to worry about mistyping a string and finding data missing at runtime,
Ease of use - Defining buissiness logic in the domain layer, persistence layer (mapping) and finally the SQL database is certainly violation of DRY. With OODB you define your domain where it belongs.

I agree - OODB have a long way to go but they are going. And there are domain problems out there that are better solved by OODB,
"
61680,"You need about 2.5 megs, so just using the heap should be fine.  You don't need a vector unless you need to resize it.  See C++ FAQ Lite for an example of using a ""2D"" heap array.
int *array = new int[800*800];

(Don't forget to delete[] it when you're done.)
"
61750,"There would have been a universal solution if SQL specifications had included paging as a standard. The requirement for any RDBMS language to be called an RDBMS language does not include paging support as well. 
Many database products support SQL with proprietary extensions to the standard language. Some of them support paging like MySQL with the limit clause, Rowid with Oracle; each handled differently. Other DBMS's will need to add a field called rowid or something like that.
I dont think you can have a universal solution (anyone is free to prove me wrong here;open to debate) unless it is built into the database system itself or unless there is a company say ABC that uses Oracle, MySQL, SQL Server and they decide to have all the various database systems provide their own implementation of paging by their database developers providing a universal interface for the code that uses it.  
"
61760,"There's actually a way to turn that ""feature"" off. This will allow the user to post whichever characters they want, and there will be no need to convert characters to an alias using Javascript.  See this article for disabling request validation.  It means that you'll have to do your own validation, but from the sounds of your post, it seems that is what you are looking to do anyway.  You can also disable it per page  by following the instructions here.
"
61850,"As far as I know, it is not easy to get just Data and data-bind the repeater on the client side. But, you might want to check this out.
"
61870,"You can do LINQ to Objects and the use LINQ to calculate the totals:
decimal sumLineTotal = (from od in orderdetailscollection
select od.LineTotal).Sum();

You can also use lambda-expressions to do this, which is a bit ""cleaner"".
decimal sumLineTotal = orderdetailscollection.Sum(od => od.LineTotal);

You can then hook this up to your Order-class like this if you want:
Public Partial Class Order {
  ...
  Public Decimal LineTotal {
    get {
      return orderdetailscollection.Sum(od => od.LineTotal);
    }
  }
}

"
62110,"Microsoft offers .NET 3.5 Enhancements Training Kit it contains documentation and sample code for ADO.NET EF
"
62230,"var
  S : TMemoryStream;
begin
  S := TMemoryStream.Create;
  try
    TBlobField(AdoQuery1.FieldByName('ImageField')).SaveToStream(S);
    S.Position := 0;
    Image1.Picture.Graphic.LoadFromStream(S);
  finally
    S.Free;
  end;
end;

if you are using JPEG images, add JPG unit to uses clause of your unit file.
"
62340,"Here is your answer, directly from The Holy Standard:

23.2.4.2 A vector satisfies all of the requirements of a container and of a reversible container (given in two tables in 23.1) and of a sequence, including most of the optional sequence requirements (23.1.1).


23.1.1.12 Table 68


expressiona.pop_back()
return typevoid
operational semanticsa.erase(--a.end())
containervector, list, deque


Notice that a.pop_back is equivalent to a.erase(--a.end()).  Looking at vector's specifics on erase:

23.2.4.3.3 - iterator erase(iterator position) - effects - Invalidates all the iterators and references after the point of the erase

Therefore, once you call pop_back, any iterators to the previously final element (which now no longer exists) are invalidated.
Looking at your code, the problem is that when you remove the final element and the list becomes empty, you still increment it and walk off the end of the list.
"
62430,"Probably this:
[^\w\W]

\w - word character (letter, digit, etc)
\W - opposite of \w
[^\w\W] - should always fail, because any character should belong to one of the character classes - \w or \W
Another snippets:
$.^

$ - assert position at the end of the string
^ - assert position at the start of the line
. - any char  
(?#it's just a comment inside of empty regex)

Empty lookahead/behind should work:
(?<!)

"
62490,"I have the same issue.  For the moment, I've worked around it by writing a BasicHandler extension, and then walking the SOAPPart myself and moving the namespace reference up to a parent node.  I don't like this solution, but it does seem to work.
I really hope somebody comes along and tells us what we have to do.
EDIT
This is way too complicated, and like I said, I don't like it at all, but here we go.  I actually broke the functionality into a few classes (This wasn't the only manipulation that we needed to do in that project, so there were other implementations)  I really hope that somebody can fix this soon.  This uses dom4j to process the XML passing through the SOAP process, so you'll need dom4j to make it work.
public class XMLManipulationHandler extends BasicHandler {
private static Log log = LogFactory.getLog(XMLManipulationHandler.class);
private static List processingHandlers;

public static void setProcessingHandlers(List handlers) {
	processingHandlers = handlers;
}

protected Document process(Document doc) {
	if (processingHandlers == null) {
		processingHandlers = new ArrayList();
		processingHandlers.add(new EmptyProcessingHandler());
	}
	log.trace(processingHandlers);
	treeWalk(doc.getRootElement());
	return doc;
}

protected void treeWalk(Element element) {
	for (int i = 0, size = element.nodeCount(); i < size; i++) {
		Node node = element.node(i);
		for (int handlerIndex = 0; handlerIndex < processingHandlers.size(); handlerIndex++) {
			ProcessingHandler handler = (ProcessingHandler) processingHandlers.get(handlerIndex);
			handler.process(node);
		}
		if (node instanceof Element) {
			treeWalk((Element) node);
		}
	}
}

public void invoke(MessageContext context) throws AxisFault {
	if (!context.getPastPivot()) {
		SOAPMessage message = context.getMessage();
		SOAPPart soapPart = message.getSOAPPart();
		ByteArrayOutputStream baos = new ByteArrayOutputStream();

		try {
			message.writeTo(baos);
			baos.flush();
			baos.close();

			ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray());
			SAXReader saxReader = new SAXReader();
			Document doc = saxReader.read(bais);
			doc = process(doc);
			DocumentSource ds = new DocumentSource(doc);
			soapPart.setContent(ds);
			message.saveChanges();
		} catch (Exception e) {
			throw new AxisFault(""Error Caught processing document in XMLManipulationHandler"", e);
		}
	}
}

}


public interface ProcessingHandler {
    public Node process(Node node);
}


public class NamespaceRemovalHandler implements ProcessingHandler {
private static Log log = LogFactory.getLog(NamespaceRemovalHandler.class);
private Namespace namespace;
private String targetElement;
private Set ignoreElements;

public NamespaceRemovalHandler() {
	ignoreElements = new HashSet();
}

public Node process(Node node) {
	if (node instanceof Element) {
		Element element = (Element) node;
		if (element.isRootElement()) {
			// Evidently, we never actually see the root node when we're called from
			// SOAP...
		} else {
			if (element.getName().equals(targetElement)) {
				log.trace(""Found the target Element.  Adding requested namespace"");
				Namespace already = element.getNamespaceForURI(namespace.getURI());
				if (already == null) {
					element.add(namespace);
				}
			} else if (!ignoreElements.contains(element.getName())) {
				Namespace target = element.getNamespaceForURI(namespace.getURI());
				if (target != null) {
					element.remove(target);
					element.setQName(new QName(element.getName(), namespace));
				}
			}
			Attribute type = element.attribute(""type"");
			if (type != null) {
				log.trace(""Replacing type information: "" + type.getText());
				String typeText = type.getText();
				typeText = typeText.replaceAll(""ns[0-9]+"", namespace.getPrefix());
				type.setText(typeText);
			}
		}
	}

	return node;
}

public Namespace getNamespace() {
	return namespace;
}

public void setNamespace(Namespace namespace) {
	this.namespace = namespace;
}

/**
 * @return the targetElement
 */
public String getTargetElement() {
	return targetElement;
}

/**
 * @param targetElement the targetElement to set
 */
public void setTargetElement(String targetElement) {
	this.targetElement = targetElement;
}

/**
 * @return the ignoreElements
 */
public Set getIgnoreElements() {
	return ignoreElements;
}

/**
 * @param ignoreElements the ignoreElements to set
 */
public void setIgnoreElements(Set ignoreElements) {
	this.ignoreElements = ignoreElements;
}

public void addIgnoreElement(String element) {
	this.ignoreElements.add(element);
}
}

No warranty, etc, etc.
"
62530,"Maybe this will work? (is the same behaviour like hovering on links with css background image)
"
62570,"To move a file or set of files using Tortoise SVN, right-click-and-drag the target files to their destination and release the right mouse button. The popup menu will have a SVN move versioned files here option.
Note that the destination folder must have already been added to the repository for the SVN move versioned files here option to appear.
"
62650,"The easiest way here is to serialize the object graph.
Java 1.4 has built in support for serialization as XML.
A solution I have used successfully is XStream (http://x-stream.github.io/)- it's a small library that will easily allow you to serialize and deserialize to and from XML.
The downside is you can only very limited define the resulting XML; which might not be neccessary in your case.
"
62720,"Download Debugging tools for Windows:
http://www.microsoft.com/whdc/DevTools/Debugging/default.mspx
Debugging Tools for Windows has has a script (ADPLUS) that allows you to create dumps when a process CRASHES:
http://support.microsoft.com/kb/286350
The command should be something like (if you are using IIS6):
cscript adplus.vbs -crash -pn w3wp.exe

This command will attach the debugger to the worker process. When the crash occurs it will generate a dump (a *.DMP file).
You can open it in WinDBG (also included in the Debugging Tools for Windows). File > Open Crash dump...
By default, WinDBG will show you (next to the command line) the thread were the process crashed.
The first thing you need to do in WinDBG is to load the .NET Framework extensions:
.loadby sos mscorwks

then, you will display the managed callstack:
!clrstack

if the thread was not running managed code, then you'll need to check the native stack:
kpn 200

This should give you some ideas. To continue troubleshooting I recommend you read the following article:
http://msdn.microsoft.com/en-us/library/ms954594.aspx
"
62810,"Here's a patch given by Jarl at CodeProject:
In RcfServer.cpp, before the line where RcfServer::handleSession() is defined (around line 792), insert the following code:
void serialize(SerializationProtocolOut & out, const RemoteException & e)
{
      serialize(out, std::auto_ptr<RemoteException>(new RemoteException(e)));
}

And in Marshal.cpp, around line 37, replace this line:
ar & boost::serialization::make_nvp(""Dummy"", apt.get());

, with
T *pt = apt.get();
ar & boost::serialization::make_nvp(""Dummy"", pt);

"
62850,"In my perspective asynchbeans are a workaround to create threads inside Websphere J2EE server. So far so good, websphere lets you create pool of ""worker"" threads, controlling this way the maximum number of threads, typical J2EE scalability concern. 
I had some problems using asynchbeans inside websphere on ""unmanaged"" threads (hacked callbacks from JMS Listener via the ""outlawed"" setMessageListener). I was ""asking for it"" not using MDBs in the first place, but I have requisites that do not feet MDB way.
"
62940,"A easy-to-use snippet would be to make a multiline textbox. With a timer you may insert line after line and scroll to the end after that:
textbox1.SelectionStart = textbox1.Text.Length;
textbox1.ScrollToCaret();
textbox1.Refresh();

Not the best method but it's simple and working. There are also some free controls available for exactly this auto-scrolling.
"
63030,"The AWT code in IKVM is fairly easy to read and edit.  I'd recommend you look for the methods that you are using that throw that exception, and then implement them.  I've done this several times before with IKVM's AWT implementation and found it easy to do for background/server related functions.  Its much less usable if your app is a desktop app, however.
"
63090,"Just a few reasons for maintaining surrogate keys:

Stability: Changing a key because of a business or natural need will negatively affect related tables.  Surrogate keys rarely, if ever, need to be changed because there is nothing tied to the value.
Convention: Allows you to have a standardized Primary Key column naming convention rather than having to think about how to join tables with various names for their PKs.
Speed: Depending on the PK value and type, a surrogate key of an integer may be smaller, faster to index and search.

"
63100,"In general testers and documenters (and other non-developes)  are all equal members of a scrum team. The idea behind that is to minimize risk. 
Requiring a definition of done, which includes a potentially shipable product that's fully tested and documented, forces the project to come together at the end of each sprint.
If testing does not start until AFTER dev. is done, what happens is that a lot of bugs are discovered after the developers are done with a task. So now you have to fix those bugs, and that's very slow and expensive both because bugs interact and because the general rule is: ""The expense of fixing a bug grows exponentially with time.""  Bugs you catch early are cheap and easy to fix, late bugs are a nightmare.
That is why you want testing (and documentation) to move in step with development. And right now you should be asking, how! Testing is slow, how the heck can it move in step with dev? 
The answer is automation, that is SCRUM always sits on top of XP or Agile, both demand excellent unit test coverage and TDD. Here's another gotcha to watch out for. The features developers should be the ones writing both, unit and system test. All testing automation should be done by the feature dev. team. Some places split feature dev. from automation dev. and that's bad.
OK, so now you have great automated testing and you run it AT LEAST once a day. And obviously you practice continuous integration right? This reduces the work load of the testers by a huge amount. And that's how testing can stay in step with dev. One more thing, the testers now work on the really hard and creative stuff that's impossible or very difficult to automate, every time they find a bug that way, what ever it took to expose the bug is automated and becomes part of the daily regression tests. Phew, that's a long answer!
Now to the second part of your question. Scrum is about discipline.  Sprints are short and backlog changes during a sprint should NOT happen. Non technical work should be branched of onto a customer support team and they can do Scrum around that. You're right when you say that is sounds like your culture and practices are incompatible with scrum.
In my experience transitioning to Scrum/Agile is a very painful, stressful process and most attempts to transition fail. One of the key's to success is a champion for Scrum/Agile in the executive team. From your description it sounds like you don't have one.  
There are costs and benefits to Scrum, but you're doing it badly you might be incurring costs with little or no benefit.  If you're doing Scrum wrong and badly, you might be better off not doing Scrum at all. 
"
63130,"This MSDN article explains how to add a custom control to a DataGridView
You should be able to make a UserControl that has a textbox and button on it and embed that in the DataGridView.
"
63150,"Pre Java 8:
Apache's commons lang is your friend here - it provides a join method very similar to the one you refer to in Ruby: 
StringUtils.join(java.lang.Iterable,char)

Java 8:
Java 8 provides joining out of the box via StringJoiner and String.join(). The snippets below show how you can use them:
StringJoiner
StringJoiner joiner = new StringJoiner("","");
joiner.add(""01"").add(""02"").add(""03"");
String joinedString = joiner.toString(); // ""01,02,03""


String.join(CharSequence delimiter, CharSequence... elements))
String joinedString = String.join("" - "", ""04"", ""05"", ""06""); // ""04 - 05 - 06""


String.join(CharSequence delimiter, Iterable<? extends CharSequence> elements)
List<String> strings = new LinkedList<>();
strings.add(""Java"");strings.add(""is"");
strings.add(""cool"");
String message = String.join("" "", strings);
//message returned is: ""Java is cool""

"
63390,"To answer the original question, there is no way to compile FLAs without using the Flash IDEs. 
The only partial solution to to use a command line script that automates opening Flash Authoring and compiling the FLA. You can find one such example here:
http://www.mikechambers.com/blog/2004/02/20/flashcommand-flash-command-line-compiler-for-os-x/
If you just need to compile ActionScript code and assets, there are a number of options (some included in this thread), including the mxmlc compiler included in the Flex SDK (provided by Adobe).
http://www.adobe.com/products/flex/
Hope that helps...
mike chambers
mesh@adobe.com
"
63690,"The reference dhclient from the ISC should run forever in the default configuration, and it should acquire a lease later if it doesn't get one at startup.
I am using the out of the box dhcp client on FreeBSD, which is derived from OpenBSD's and based on the ISC's dhclient, and this is the out of the box behavior.
See http://www.isc.org/index.pl?/sw/dhcp/
"
63720,"When Microsoft got the security religion, DCOM (and the underlying RPC) got a lot of attention, and there definitely were changes made to close security holes that resulted in stricter marshaling.  I'm suprised you see this in Vista but not in XP, but its possible that additional checks were added for Vista.  Alternatively, its possible that optional strictness in XP was made mandatory in Vista.
While I don't know enough about MDAC to know if you could have prevented this, I do know that security is one of the few areas where Microsoft is pretty willing to sacrifice backward compatibility, so it is possible you could not have done anything ""better"" back in 1999.
"
63790,"This question is very old so you have probably solved the issue, but just in case: Does the project file use IIS? If so then it is probably trying to read the project file from IIS and the virtual directory does not exist on the newly formatted computer. Also, there should be more detail about the message in the Output window when you open the solution which should help you find the cause. With VS2003, you also need to add your user account to the ""Debugger Users"" and ""VS Developers"" and possibly the account that is running the AppPool (possibly Network Server, ASPNET, or IUSER_xxx). This may depend on the type of authentication you are using as well. Occasionally I had to add those group permissions the the virtual directory location as well. It's been a while since I have used VS2003 with web projects though.
"
63800,"No, you can escape any character that Java doesn't allow in String literals but the filesystem allows.
Also, if trying to port an Windows app to Mac or Unix it is best to use:
File.separator

To determine the correct file separator to use on each platform.
"
63870,"Homework?  :-)
I would think that a simple pipe with sed (to split each line into two) and split (to split things up into multiple files) would be enough.
The man command is your friend.

Added after confirmation that it is not homework:
How about
sed 's/\(.....\)\(.....\)/\1\n\2/' input_file | split -l 2000000 - out-prefix-

?
"
63910,"If you're building a Flex application, you should use Flex's native Effect classes. They're probably already compiled into your app, since the core components use them, and you won't increase your SWF size with duplicate functionality like you would if you used another library. For simple animations, either mx.effects.AnimateProperty or mx.effects.Tween should work well.
If you're working on a regular ActionScript project (without the Flex framework), then I concur with the answer given by Marc Hughes. However, if that's the case, then please don't say you're using Flex because that implies that you're using the Flex framework and it can be very confusing. If you mean Flex Builder, then please use the full name to avoid potential misunderstandings.
"
63930,"You can't ""forward"", in the strict sense.  Just call sendRedirect() on the HttpServletResponse object in your Action class's execute() method.  and, then 'return null'.
alternately, either call setModule on the ActionForward object (that you are going to return) or set the path to an absolute URI
"
63940,"WMI does not give limited users this information.
If you can access Win32 functions from your language, you can call GetVolumeInformation.
"
63950,"You don't have to be stuck to your terminal's default 16 (or fewer) colours. Modern terminals will support 256 colours (which will get you pretty close to your GUI look).
Unfortunately, getting your terminal to support 256 colours is the tricky part, and varies from term to term. This page helped me out a lot (but it is out of date; I've definitely gotten 256 colours working in gnome-terminal and xfce4-terminal; but you may have to build them from source.) 
Once you've got your terminal happily using 256 colours, the magic invocation is setting your terminal type to ""xterm-256color"" before you invoke emacs, e.g.:
env TERM=xterm-256color emacs -nw

Or, you can set TERM in your .bashrc file:
export TERM=xterm-256color

You can check if it's worked in emacs by doing M-x list-colors-display, which will show you either 16, or all 256 glorious colours.
If it works, then look at color-theme like someone else suggested.
(You'll probably get frustrated at some point; god knows I do every time I try to do something similar. But stick with it; it's worth it.)
"
63960,"If you were to think of an event as a subscriber list, in your code all you are doing is registering a subscriber.  The number of instructions needed to achieve that is likely to be minimal at the CLR level.
If you want your code to be generic or dynamic, then you're need to check if something is subscribed prior to calling an event.  The event/delegate mechanism of C# and .NET provides this to you at very little cost (in terms of CPU).
If you're really concerned about every clock cycle, you'd never write generic/dynamic game logic. It's a trade off between maintainable/configurable code and outright speed.
Written well, I'd favour events/delegates until I could prove it is an issue.
The only way you'll truly know if it is an issue for you is by profiling your code -- which you should do anyway for any game development!
"
64000,"Set the redirectErrorStream property on ProcessBuilder to send stderr output to stdout:
ProcessBuilder builder = new ProcessBuilder(command);
builder.redirectErrorStream(true);

You should then create a thread to deal with the process stream, something like the following:
Process p = builder.start();

InputHandler outHandler = new InputHandler(p.getInputStream());

Where InputHandler is defined as:
private static class InputHandler extends Thread {

    private final InputStream is;

    private final ByteArrayOutputStream os;

    public InputHandler(InputStream input) {
        this.is = input;
        this.os = new ByteArrayOutputStream();
    }

    public void run() {
        try {
            int c;
            while ((c = is.read()) != -1) {
                os.write(c);
            }
        } catch (Throwable t) {
            throw new IllegalStateException(t);
        }
    }

    public String getOutput() {
        try {
        os.flush();
        } catch (Throwable t) {
            throw new IllegalStateException(t);
        }
        return os.toString();
    }

}

Alternatively, just create two InputHandlers for the InputStream and ErrorStream. Knowing that the program will block if you don't read them is 90% of the battle :)
"
64010,"This is an old thread, but the issue remains relevant.  It should be noted that there is a way to record audio to the server in Flash without a proprietary back-end.  Here's an example project to get you started:
https://code.google.com/p/wami-recorder/
"
64170,"Use minerva. I've tried it, it works with every .sol I open it with.
"
64200,"MySQL stored procedures that produce datasets need you to use Perl DBD::mysql 4.001 or later. (http://www.perlmonks.org/?node_id=609098)
Below is a test program that will work in the newer version:
mysql> delimiter //
mysql> create procedure Foo(x int)
  -> begin
  ->   select x*2;
  -> end
  -> //

perl -e 'use DBI; DBI->connect(""dbi:mysql:database=bonk"", ""root"", """")->prepare(""call Foo(?)"")->execute(21)'

But if you have too old a version of DBD::mysql, you get results like this:
DBD::mysql::st execute failed: PROCEDURE bonk.Foo can't return a result set in the given context at -e line 1.

You can install the newest DBD using CPAN.
"
64360,"Let's be careful with our definitions here

An Emacs copy is the command kill-ring-save (usually bound to M-w).
A system copy is what you typically get from pressing C-c (or choosing ""Edit->Copy"" in a application window).
An X copy is ""physically"" highlighting text with the mouse cursor.
An Emacs paste is the command yank (usually bound to C-y).
A system paste is what you typically get from pressing C-v (or choosing ""Edit-Paste"" in an application window).
An X paste is pressing the ""center mouse button"" (simulated by pressing the left and right mouse buttons together).

In my case (on GNOME):

Both Emacs and system copy usually work with X paste.
X copy usually works with Emacs paste.
To make system copy work with Emacs paste and Emacs copy work with system paste, you need to add (setq x-select-enable-clipboard t) to your .emacs. Or try 
META-X set-variable RET x-select-enable-clipboard RET t


I think this is pretty standard modern Unix behavior.
It's also important to note (though you say you're using Emacs in a separate window) that when Emacs is running in a console, it is completely divorced from the system and X clipboards: cut and paste in that case is mediated by the terminal. For example, ""Edit->Paste"" in your terminal window should act exactly as if you typed the text from the clipboard into the Emacs buffer. 
"
64380,"Something as simple as:
RewriteRule ^/[^/]+/([^/]+)/?$ /$2 [R]

Perhaps would do it? 
That simple redirects /foo/bar/ to /bar.
"
64400,"You probably want the Web AIM Server API; it looks like you can set the AIM status through authenticated HTTP calls, among many other things.  Should be language-independent; in PHP you could use the cURL library, for instance.  I've never used it personally, though.
"
64420,"I found the answer after searching around. Here's what I have done:

Create a new project in XCode. I think I used the view-based app.
Drag a WebView object onto your interface and resize.
Inside of your WebViewController.m (or similarly named file, depending on the name of your view), in the viewDidLoad method:
NSString *filePath = [[NSBundle mainBundle] pathForResource:@""index"" ofType:@""html""];  
NSData *htmlData = [NSData dataWithContentsOfFile:filePath];  
if (htmlData) {  
  NSBundle *bundle = [NSBundle mainBundle]; 
  NSString *path = [bundle bundlePath];
  NSString *fullPath = [NSBundle pathForResource:@""index"" ofType:@""html"" inDirectory:path];
  [webView loadRequest:[NSURLRequest requestWithURL:[NSURL fileURLWithPath:fullPath]]];
}
Now any files you have added as resources to the project are available for use in your web app. I've got an index.html file including javascript and css and image files with no problems. The only limitation I've found so far is that I can't create new folders so all the files clutter up the resources folder.
Trick: make sure you've added the file as a resource in XCode or the file won't be available. I've been adding an empty file in XCode, then dragging my file on top in the finder. That's been working for me.

Note: I realize that Obj-C must not be that hard to learn. But since I already have this app existing in JS and I know it works in Safari this is a much faster dev cycle for me. Some day I'm sure I'll have to break down and learn Obj-C.
A few other resources I found helpful:
Calling Obj-C from javascript: calling objective-c from javascript
Calling javascript from Obj-C: iphone app development for web hackers
Reading files from application bundle: uiwebview
"
64570,"Try preg_split.
$exploded = preg_split('@/@', '1/2//3/', NULL, PREG_SPLIT_NO_EMPTY);
"
64640,"The IFormatProvider argument can be null.
"
64760,"Generally, it's better to keep presentation (HTML) separate from logic (""back-end"" code). Your code is decoupled and easier to maintain this way.
"
64790,"First of all, I agree 100% with the earlier folks that said turn OFF Load Symbols Lazily.
I have two more things to add.
(My first suggestion sounds obvious, but the first time someone suggested it to me, my reaction went along these lines: ""come on, please, you really think I wouldn't know better......  oh."")

Make sure you haven't accidentally set ""Active Build Configuration"" to ""Release.""
Under ""Targets"" in the graphical tree display of your project, right click on your Target and do ""Get Info.""  Look for a property named ""Generate Debug Symbols"" (or similar) and make sure this is CHECKED (aka ON).  Also, you might try finding (also in Target >> Get Info) a property called ""Debug Information Format"" and setting it to ""Dwarf with dsym file.""

There are a number of other properties under Target >> Get Info that might affect you.  Look for things like optimizing or compressing code and turn that stuff OFF (I assume you are working in a debug mode, so that this is not bad advice).  Also, look for things like stripping symbols and make sure that is also OFF. For example, ""Strip Linked Product"" should be set to ""No"" for the Debug target.
"
64820,"The short answer is that you use Javascript to capture a keydown event and use that event to fire off a function.
Relevant articles:

http://www.openjs.com/scripts/events/keyboard_shortcuts/
http://udayms.wordpress.com/2006/03/17/ajax-key-disabling-using-javascript/
http://protocolsofmatrix.blogspot.com/2007/09/javascript-keycode-reference-table-for.html
http://www.quirksmode.org/js/keys.html

If you're using the jQuery library, I'd suggest you look at the HotKeys plugin for a cross-browser solution.


I know this is not answering the orginal question, but here is my advice: Don't Use Key Combination Shortcuts In A Web Application!
Why? Because it might break de the usability, instead of increasing it. While it's generally accepted that ""one-key shortcut"" are not used in common browsers (Opera remove it as default from its last major version), you cannot figure out what are, nor what will be, the key combination shortcuts used by various browser.


Gizmo makes a good point. There's some information about commonly-used accesskey assignments at http://www.clagnut.com/blog/193/. 
If you do change the accesskeys, here are some articles with good suggestions for how to do it well:

Accesskeys: Unlocking Hidden Navigation
Using accesskey attribute in HTML forms and links 

And you may find this page of Firefox's default Keyboard and Mouse Shortcuts useful (Another version of same information). Keyboard shortcuts for Internet Explorer 7 and Internet Explorer 6. Keyboard shortcuts for Opera and Safari.
You're more likely to run into problems with JAWS or other screen readers that add more keyboard shortcuts.
"
64860,"Stand-alone utility approach
iconv -f UTF-8 -t ISO-8859-1 in.txt > out.txt


-f ENCODING  the encoding of the input
-t ENCODING  the encoding of the output

"
65010,"I don't know about GCJ, but my company uses Excelsior JET with success.  We haven't done it with a webapp (yet) but it should be able to handle anything that the Sun JRE can.  In fact JET is a Sun-certified Java implementation.
"
65020,"No there is no way to add a global error handler in VB6.  However, you do not need to add an error handler in every method.  You only really need to add an error handler in every event handler.  E.g. Every click event,load event, etc
"
65060,"As an indirect answer to your question, here is how I do it without a named query.
    var session = GetSession();
    var criteria = session.CreateCriteria(typeof(Order))
			.Add(Restrictions.Eq(""Product"", product))
			.SetProjection(Projections.CountDistinct(""Price""));
    return (int) criteria.UniqueResult();

"
65150,"Here's an article that compares kBPM, OpenWFE, and Enhydra Shark that looks like it has some good, thorough info.
"
65170,"There is a correct (although undocumented) way to do this on Windows XP which also works with directories -- the same method GetFinalPathNameByHandle uses on Windows Vista and later.
Here are the eneded declarations. Some of these are already in WInternl.h and MountMgr.h but I just put them here anyway:
#include ""stdafx.h""
#include <Windows.h>
#include <assert.h>

enum OBJECT_INFORMATION_CLASS { ObjectNameInformation = 1 };
enum FILE_INFORMATION_CLASS { FileNameInformation = 9 };
struct FILE_NAME_INFORMATION { ULONG FileNameLength; WCHAR FileName[1]; };
struct IO_STATUS_BLOCK { PVOID Dummy; ULONG_PTR Information; };
struct UNICODE_STRING { USHORT Length; USHORT MaximumLength; PWSTR Buffer; };
struct MOUNTMGR_TARGET_NAME { USHORT DeviceNameLength; WCHAR DeviceName[1]; };
struct MOUNTMGR_VOLUME_PATHS { ULONG MultiSzLength; WCHAR MultiSz[1]; };

extern ""C"" NTSYSAPI NTSTATUS NTAPI NtQueryObject(IN HANDLE Handle OPTIONAL,
    IN OBJECT_INFORMATION_CLASS ObjectInformationClass,
    OUT PVOID ObjectInformation OPTIONAL, IN ULONG ObjectInformationLength,
    OUT PULONG ReturnLength OPTIONAL);
extern ""C"" NTSYSAPI NTSTATUS NTAPI NtQueryInformationFile(IN HANDLE FileHandle,
    OUT PIO_STATUS_BLOCK IoStatusBlock, OUT PVOID FileInformation,
    IN ULONG Length, IN FILE_INFORMATION_CLASS FileInformationClass);

#define MOUNTMGRCONTROLTYPE ((ULONG) 'm')
#define IOCTL_MOUNTMGR_QUERY_DOS_VOLUME_PATH \
    CTL_CODE(MOUNTMGRCONTROLTYPE, 12, METHOD_BUFFERED, FILE_ANY_ACCESS)

union ANY_BUFFER {
    MOUNTMGR_TARGET_NAME TargetName;
    MOUNTMGR_VOLUME_PATHS TargetPaths;
    FILE_NAME_INFORMATION NameInfo;
    UNICODE_STRING UnicodeString;
    WCHAR Buffer[USHRT_MAX];
};

Here's the core function:
LPWSTR GetFilePath(HANDLE hFile)
{
    static ANY_BUFFER nameFull, nameRel, nameMnt;
    ULONG returnedLength; IO_STATUS_BLOCK iosb; NTSTATUS status;
    status = NtQueryObject(hFile, ObjectNameInformation,
        nameFull.Buffer, sizeof(nameFull.Buffer), &returnedLength);
    assert(status == 0);
    status = NtQueryInformationFile(hFile, &iosb, nameRel.Buffer,
        sizeof(nameRel.Buffer), FileNameInformation);
    assert(status == 0);
    //I'm not sure how this works with network paths...
    assert(nameFull.UnicodeString.Length >= nameRel.NameInfo.FileNameLength);
    nameMnt.TargetName.DeviceNameLength = (USHORT)(
        nameFull.UnicodeString.Length - nameRel.NameInfo.FileNameLength);
    wcsncpy(nameMnt.TargetName.DeviceName, nameFull.UnicodeString.Buffer,
        nameMnt.TargetName.DeviceNameLength / sizeof(WCHAR));
    HANDLE hMountPointMgr = CreateFile(_T(""\\\\.\\MountPointManager""),
        0, FILE_SHARE_READ | FILE_SHARE_WRITE | FILE_SHARE_DELETE,
        NULL, OPEN_EXISTING, 0, NULL);
    __try
    {
        DWORD bytesReturned;
        BOOL success = DeviceIoControl(hMountPointMgr,
            IOCTL_MOUNTMGR_QUERY_DOS_VOLUME_PATH, &nameMnt,
            sizeof(nameMnt), &nameMnt, sizeof(nameMnt),
            &bytesReturned, NULL);
        assert(success && nameMnt.TargetPaths.MultiSzLength > 0);
        wcsncat(nameMnt.TargetPaths.MultiSz, nameRel.NameInfo.FileName,
            nameRel.NameInfo.FileNameLength / sizeof(WCHAR));
        return nameMnt.TargetPaths.MultiSz;
    }
    __finally { CloseHandle(hMountPointMgr); }
}

and here's an example usage:
int _tmain(int argc, _TCHAR* argv[])
{
    HANDLE hFile = CreateFile(_T(""\\\\.\\C:\\Windows\\Notepad.exe""),
        0, FILE_SHARE_READ | FILE_SHARE_WRITE, NULL, OPEN_EXISTING, 0, NULL);
    assert(hFile != NULL && hFile != INVALID_HANDLE_VALUE);
    __try
    {
        wprintf(L""%s\n"", GetFilePath(hFile));
        //  Prints:
        //  C:\Windows\notepad.exe
    }
    __finally { CloseHandle(hFile); }
    return 0;
}

"
65200,"I wouldn't call throwing an OutOfMemoryError or StackOverflowError a crash. These are just normal exceptions. To really crash a VM there are 3 ways:

Use JNI and crash in the native code.
If no security manager is installed you can use reflection to crash the VM. This is VM specific, but normally a VM stores a bunch of pointers to native resources in private fields (e.g. a pointer to the native thread object is stored in a long field in java.lang.Thread). Just change them via reflection and the VM will crash sooner or later.
All VMs have bugs, so you just have to trigger one.

For the last method I have a short example, which will crash a Sun Hotspot VM quiet nicely:
public class Crash {
    public static void main(String[] args) {
        Object[] o = null;

        while (true) {
            o = new Object[] {o};
        }
    }
}

This leads to a stack overflow in the GC so you will get no StackOverflowError but a real crash including a hs_err* file.
"
65250,"A simple RMagick example to convert a PDF to a PNG would be:
require 'RMagick'
pdf = Magick::ImageList.new(""doc.pdf"")
thumb = pdf.scale(300, 300)
thumb.write ""doc.png""

To convert a MS Word document, it won't be as easy.  Your best option may be to first convert it to a PDF before generating the thumbnail.  Your options for generating the PDF depend heavily on the OS you're running on.  One might be to use OpenOffice and the Python Open Document Converter.  There are also online conversion services you could try, including http://Zamzar.com.
"
65310,"According to the documentation linked to by @arnonym, this exception is somewhat misleading. In the first attempt to find the service a ConfigurationException is thrown and caught. It is logged at DEBUG level by the ConfigurationException class. Then another attempt is made using a different method to find the service that may then succeed. The workaround for this is to just change the log level on the ConfigurationException class to INFO in your log4j.properties:
log4j.logger.org.apache.axis.ConfigurationException = INFO

"
65400,"Try dynamically extending the bases that way you can take advantage of the mro and the methods are actual methods:
class Parent(object):
    def bar(self):
        print ""bar""

class MetaFoo(type):
    def __new__(cls, name, bases, dict):
    	return type(name, (Parent,) + bases, dict)

class Foo(object):
    __metaclass__ = MetaFoo

if __name__ == ""__main__"":
    f = Foo()
    f.bar()
    print f.bar.func_name

"
65530,"In Tomcat 6.0 it should be something like:
org.apache.catalina.ServerFactory.getServer().getServices

to get the services. After that you might use 
Service.findConnectors

which returns a Connector which finally has the method
Connector.getPort

See the JavaDocs for the details.
"
65800,"I'm partial to TinyMCE WYSIWYG editor due to the following reasons:

Javascript - so it is broadly usable
regardless of the platform I'm
working in.
Easy to use - just a couple lines of
code and a textarea and the control is up and
running.
Easily themed - so I can quickly
make it look like the site in which
it is being used
Most importantly - easily customized
to show/hide particular buttons
depending on my application needs

"
65820,"One unit testing framework in C is Check; a (LAST UPDATED ON 2008) list of unit testing frameworks in C can be found here and is reproduced below.  Depending on how many standard library functions your runtime has, you may or not be able to use one of those.

AceUnit
AceUnit (Advanced C and Embedded Unit) bills itself as a comfortable C code unit test framework. It tries to mimick JUnit 4.x and includes reflection-like capabilities. AceUnit can be used in resource constraint environments, e.g. embedded software development, and importantly it runs fine in environments where you cannot include a single standard header file and cannot invoke a single standard C function from the ANSI / ISO C libraries. It also has a Windows port. It does not use forks to trap signals, although the authors have expressed interest in adding such a feature. See the AceUnit homepage.
GNU Autounit
Much along the same lines as Check, including forking to run unit tests in a separate address space (in fact, the original author of Check borrowed the idea from GNU Autounit). GNU Autounit uses GLib extensively, which means that linking and such need special options, but this may not be a big problem to you, especially if you are already using GTK or GLib. See the GNU Autounit homepage.
cUnit
Also uses GLib, but does not fork to protect the address space of unit tests.
CUnit
Standard C, with plans for a Win32 GUI implementation. Does not currently fork or otherwise protect the address space of unit tests. In early development. See the CUnit homepage.
CuTest
A simple framework with just one .c and one .h file that you drop into your source tree. See the CuTest homepage.
CppUnit
The premier unit testing framework for C++; you can also use it to test C code. It is stable, actively developed, and has a GUI interface. The primary reasons not to use CppUnit for C are first that it is quite big, and second you have to write your tests in C++, which means you need a C++ compiler. If these donât sound like concerns, it is definitely worth considering, along with other C++ unit testing frameworks. See the CppUnit homepage.
embUnit
embUnit (Embedded Unit) is another unit test framework for embedded systems. This one appears to be superseded by AceUnit. Embedded Unit homepage.
MinUnit
A minimal set of macros and thatâs it! The point is to show how easy it is to unit test your code. See the MinUnit homepage.
CUnit for Mr. Ando
A CUnit implementation that is fairly new, and apparently still in early development. See the CUnit for Mr. Ando homepage.
This list was last updated in March 2008.

Others:
CMocka
CMocka is a test framework for C with support for mock objects. It's easy to use and setup. CMocka official homepage.
Criterion
Criterion is a cross-platform C unit testing framework supporting automatic test registration, parameterized tests, theories, and that can output to multiple formats, including TAP and JUnit XML. Each test is run in its own process, so signals and crashes can be reported or tested if needed. See the Criterion homepage for more information.
HWUT
HWUT is a general Unit Test tool with great support for C. It can help to create Makefiles, generate massive test cases coded in minimal 'iteration tables', walk along state machines, generate C-stubs and more. The general approach is pretty unique: Verdicts are based on 'good stdout/bad stdout'. The comparison function, though, is flexible. Thus, any type of script may be used for checking. It may be applied to any language that can produce standard output. See HWUT homepage.
"
65910,"Assuming this is about Windows, NVIDIA has a GLExpert tool. It can print various OpenGL warnings/errors.
In some other cases, using GLIntercept OpenGL call interceptor with error checking turned on can be useful.
If the tools do not help, well, then it's good old debugging. Try to narrow down the problem and locate what exactly causes a crash. If it's a NVIDIA specific problem, try installing different drivers and/or asking on NVIDIA developer forums.
"
65940,"Try using the GoDaddy SQL backup/restore tool to get a local copy of the database. At that point, use the SQL Server DTS tool to import the data. It's an easy to use, drag-and-drop graphical interface.
"
65970,"shuffle($arr); :)
edit: I should clarify... my definition of best involves not just algorithm efficiency but code readability and maintainability as well. Using standard library functions means maintaining less code and reading much less too. Beyond that, you can get into year-long debates with PhD professors about the best ""true random"" function, so somebody will always disagree with you on randomization questions.
"
65990,"Just look in the msdn database for (T) delegate.
Here you got a direct link: List of delegates
That should get you started.
"
66040,"Lotus/ Domino is your answer. I've been working with it for ten years and its exactly what you need. It may not be trendy (a perception that I would challenge) but its powerful, adaptable and very secure, The latest version R8 is the best yet.
"
66330,"Perl has excellent utilities for doing testing. The most commonly used module is probably Test::More, which provides all the infrastructure you're likely to need for writing regression tests. The prove utility provides an easy interface for running test suites and summarizing the results. The Test::Differences module (which can be used with Test::More) might be useful to you as well. It formats differences as side-by-side comparisons. As for committing the actual output as the new reference material, that will depend on how your code under test provides output and how you capture it. It should be easy if you write to files and then compare them. If that's the case you might want to use the Text::Diff module within your test suite.
"
66420,"Try adding this to your source:
debugger;

It works in most, if not all browsers. Just place it somewhere in your code, and it will act like a breakpoint.
"
66540,"In practice, it usually decides to do a garbage collection.  The answer varies depending on lots of factors, like which JVM you're running on, which mode it's in, and which garbage collection algorithm it's using.  
I wouldn't depend on it in your code.  If the JVM is about to throw an OutOfMemoryError, calling System.gc() won't stop it, because the garbage collector will attempt to free as much as it can before it goes to that extreme.  The only time I've seen it used in practice is in IDEs where it's attached to a button that a user can click, but even there it's not terribly useful.
"
66610,"If you have a Linux system available to you use wget:
wget -k -K  -E -r -l 10 -p -N -F -nH http://website.com/

Options

-k : convert links to relative
-K : keep an original versions of files without the conversions made by wget
-E : rename html files to .html (if they donât already have an htm(l) extension)
-r : recursiveâ¦ of course we want to make a recursive copy
-l 10 : the maximum level of recursion. if you have a really big website you may need to put a higher number, but 10 levels should be enough.
-p : download all necessary files for each page (css, js, images)
-N : Turn on time-stamping.
-F : When input is read from a file, force it to be treated as an HTML file.
-nH : By default, wget put files in a directory named after the siteâs hostname. This will disabled creating of those hostname directories and put everything in the current directory.

Source: Jean-Pascal Houde's weblog
"
66720,"RDF Gravity is an RDF visualisation tool.
Here's a screenshot:

"
66730,"You can also define signals inside the class definition:
class MyGObjectClass(gobject.GObject):
    __gsignals__ = {
      ""some-signal"": (gobject.SIGNAL_RUN_FIRST, gobject.TYPE_NONE, (object, )),
    }

The contents of the tuple are the the same as the three last arguments to gobject.signal_new.
"
66750,"Not all languages share english capitalization rules. I guess you'd need to alter the data used by the API, but your non-english clients might not appreciate it...
about.com on french capitalization
"
66770,"I definitely suggest checking out spork.
http://spork.rubyforge.org/
The railstutorial specifically addresses this, and gives a workaround to get spork running nicely in rails 3.0 (as of this moment, spork is not rails 3 ready out of the box).  Of course, if you're not on rails 3.0, then you should be good to go.
The part of the tutorial showing how to get spork running in rails 3.0
http://railstutorial.org/chapters/static-pages#sec:spork
Checking when spork is rails 3.0 ready
http://www.railsplugins.org/plugins/440-spork
"
66800,"check out SCons. For example Doom 3 and Blender make uses of it.
"
66810,"Check out the Stylesheets facility in Qt 4.  While it's still a hassle, it's way easier than doing a full-on custom style.  You can just adjust one visual facet at a time and try it out.
It pays attention to inheritance.  So if you style the font in QWidget, then every visual widget will also use that font.  And so on.
"
66840,"I think this is your answer.  Looks like it is baked in to ActieMQ.  I tried the examples and they seem to work.
http://activemq.apache.org/ajax.html
"
66870,"You will require assistance and a lot of trust from your system administrator.  Ordinary users are not able to run the executable of their choice on behalf on other users, period.
She may add your application to /etc/sudoers with proper settings and you'll be able to run it as with sudo -u nobody.   This will work for both scripts and binary executables.
Another option is that she will do chown nobody and chmod +s on your binary executable and you'll be able to execute it directly.  This task must be repeated each time your executable changes.    
This could also work for scripts if you'll create a tiny helper executable which simply does exec(""/home/you/bin/your-application"").   This executable can be made suid-nobody (see above) and you may freely modify your-application.
Hope it helps,
"
66880,"MasterCard: 5431111111111111
Amex: 341111111111111
Discover: 6011601160116611
American Express (15 digits)  378282246310005
American Express (15 digits)  371449635398431
American Express Corporate (15 digits)  378734493671000
Diners Club (14 digits)  30569309025904
Diners Club (14 digits) 38520000023237
Discover (16 digits)  6011111111111117
Discover (16 digits)  6011000990139424
JCB (16 digits) 3530111333300000
JCB (16 digits)  3566002020360505
MasterCard (16 digits)  5555555555554444
MasterCard (16 digits)  5105105105105100
Visa (16 digits)  4111111111111111
Visa (16 digits)  4012888888881881
Visa (13 digits)  4222222222222

Credit Card Prefix Numbers: 
Visa: 13 or 16 numbers starting with 4
MasterCard: 16 numbers starting with 5
Discover: 16 numbers starting with 6011
AMEX: 15 numbers starting with 34 or 37

"
67000,"The Pyglet library for Python might suit your needs. It lets you use OpenGL, a cross-platform graphics API. You can disable anti-aliasing and capture regions of the screen to a buffer or a file. In addition, you can use its event handling, resource loading, and image manipulation systems. You can probably also tie it into PIL (Python Image Library), and definitely Cairo, a popular cross-platform vector graphics library.
I mention Pyglet instead of pure PyOpenGL because Pyglet handles a lot of ugly OpenGL stuff transparently with no effort on your part.
A friend and I are currently working on a drawing program using Pyglet. There are a few quirks - for example, OpenGL is always double buffered on OS X, so we have to draw everything twice, once for the current frame and again for the other frame, since they are flipped whenever the display refreshes. You can look at our current progress in this subversion repository. (Splatterboard.py in trunk is the file you'll want to run.) If you're not up on using svn, I would be happy to email you a .zip of the latest source. Feel free to steal code if you look into it.
"
67180,"check the max_packet setting in your my.cnf file. this determines the largest amount of data you can send to your mysql server in a single statement. exceeding this values results in that error.
"
67200,"I would concur with the comment.  You have 500,000 of tried and true VB.Net code.  Why on earth would you waste any time changing that?  No one says that you can't write all new components in C#.  
I would consider not worrying about a tool and instead ask yourself, truly, why you are doing this.
"
67300,"The solution in Rajesh's blog is really useful, but it colours the tab part of the control only. In my case I had a tabcontrol on a different coloured background. The tabs themselves were grey which wasn't a problem, but the area to the right of the tabs was displaying as a grey strip. 
To change this colour to the colour of your background you need to add the following code to the DrawItem method (as described in Rajesh's solution). I'm using VB.Net:
...

Dim r As Rectangle = tabControl1.GetTabRect(tabControl1.TabPages.Count-1)
Dim rf As RectangleF = New RectangleF(r.X + r.Width, r.Y - 5, tabControl1.Width - (r.X + r.Width), r.Height + 5)
Dim b As Brush = New SolidBrush(Color.White)
e.Graphics.FillRectangle(b, rf)

...

Basically you need to get the rectangle made of the right hand side of the last tab to the right hand side of the tab control and then fill it to your desired colour.
"
67370,"What you are looking for is MakeGenericType
string elementTypeName = Console.ReadLine();
Type elementType = Type.GetType(elementTypeName);
Type[] types = new Type[] { elementType };

Type listType = typeof(List<>);
Type genericType = listType.MakeGenericType(types);
IProxy  proxy = (IProxy)Activator.CreateInstance(genericType);

So what you are doing is getting the type-definition of the generic ""template"" class, then  building a specialization of the type using your runtime-driving types.
"
67410,"I think the error occurs if the input encoding of the file is different from the preferred encoding of your environment. 
Example: in is UTF-8
$ LANG=de_DE.UTF-8 sed 's/.*| //' < in
X
Y
$ LANG=de_DE.iso88591 sed 's/.*| //' < in
X 
Y

UTF-8 can safely be interpreted as ISO-8859-1, you'll get strange characters but apart from that everything is fine.
Example: in is ISO-8859-1
$ LANG=de_DE.UTF-8 sed 's/.*| //' < in
X
Gras Och Stenar Trad - From MÃ¶Y
$ LANG=de_DE.iso88591 sed 's/.*| //' < in
X 
Y

ISO-8859-1 cannot be interpreted as UTF-8, decoding the input file fails. The strange match is probably due to the fact that sed tries to recover rather than fail completely.
The answer is based on Debian Lenny/Sid and sed 4.1.5.
"
67640,"I recently learned that Jetbrains the make of my favorite IDE (Idea) may support Objective-C (though it is unclear how much it will work for iPhone/iPad development). See the thread here for early discussion on this.
In the last year or two, they have started adding additional language support both in their flagship IDE as well as specialized IDEs (for Ruby, Python, PHP). I guess this is just another step in the process. I for one would love to have another option other than XCode and I couldn't think of one that I'd love more.
This is obviously vaporware at the moment, but I think it is something to keep an eye on.
This is now a real product, albeit still in Early Access. See here for a the blog on this new product, which will give you pointers to check out the EAP.
UPDATE: AppCode has now been released and offers a true alternative to using Xcode for Objective-C and iPhone/iPad/Mac development. It does still rely on Interface Builder for layout and wiring of GUI components and uses the iOS simulator, but all coding, including a slew of refactorings, smart templating and static analysis, is available through App Code.
"
67760,"By default, Sys::Syslog is going to try to connect with one of the following socket types:
[ 'tcp', 'udp', 'unix', 'stream' ]

On Solaris, though, you'll need to use an inet socket.  Call:
setlogsock('inet', $hostname);

and things should start working.
"
67780,"This MSDN Blog article Has quite a good review of using burndowns in combination with Cumulative Flow Diagrams which fleshes out the diagrams even more. In the resources links at the bottom of the article there is a link to the Microsoft Scrum kit which has a pre-built excel file.
"
67790,"If you ensure that the field is placed in the same place in each such structure, you can simply cast a pointer to get at the field. This technique is used in lots of low level system libraries e.g. BSD sockets.
struct person {
  int index;
};

struct clown {
  int index;
  char *hat;
};

/* we're not going to define a firetruck here */
struct firetruck;


struct fireman {
  int index;
  struct firetruck *truck;
};

int getindexof(struct person *who)
{
  return who->index;
}

int main(int argc, char *argv[])
{
  struct fireman sam;
  /* somehow sam gets initialised */
  sam.index = 5;

  int index = getindexof((struct person *) &sam);
  printf(""Sam's index is %d\n"", index);

  return 0;
}

You lose type safety by doing this, but it's a valuable technique.
[ I have now actually tested the above code and fixed the various minor errors. It's much easier when you have a compiler. ]
"
67810,"I just Googled it.  :)
http://bugs.sakaiproject.org/confluence/display/BOOT/Setting+Up+Tomcat+For+Remote+Debugging
Many more on google.
Effectively, set your JPDA settings:
set JPDA_ADDRESS=8000
set JPDA_TRANSPORT=dt_socket
bin/catalina.bat jpda start
Then, in Eclipse, Run->Debug Configurations...->Remote Applications.
"
67890,"Depending on how long a string you would like you can use a few alternatives:
require 'digest'
Digest.hexencode('http://foo-bar.com/yay/?foo=bar&a=22')
# ""687474703a2f2f666f6f2d6261722e636f6d2f7961792f3f666f6f3d62617226613d3232""

require 'digest/md5'
Digest::MD5.hexdigest('http://foo-bar.com/yay/?foo=bar&a=22')
# ""43facc5eb5ce09fd41a6b55dba3fe2fe""

require 'digest/sha1'
Digest::SHA1.hexdigest('http://foo-bar.com/yay/?foo=bar&a=22')
# ""2aba83b05dc9c2d9db7e5d34e69787d0a5e28fc5""

require 'digest/sha2'
Digest::SHA2.hexdigest('http://foo-bar.com/yay/?foo=bar&a=22')
# ""e78f3d17c1c0f8d8c4f6bd91f175287516ecf78a4027d627ebcacfca822574b2""

Note that this won't be unguessable, you may have to combine it with some other (secret but static) data to salt the string:
salt = 'foobar'
Digest::SHA1.hexdigest(salt + 'http://foo-bar.com/yay/?foo=bar&a=22')
# ""dbf43aff5e808ae471aa1893c6ec992088219bbb""

Now it becomes much harder to generate this hash for someone who doesn't know the original content and has no access to your source.
"
67980,"Please see chapter 5 of the spring reference manual here: 5.4.2.1. Registering additional custom PropertyEditors
"
68120,"I don't know if it's what you require, but perhaps you may want to investigate creating your own custom resource factory for Tomcat.  Here is the general documentation for all things resources via Tomcat: Tomcat Resources
"
68150,"Forever (or as close as I can get).  That's the whole point of a source control system.
"
68160,"
$ gdb --pid=26426
(gdb) gcore
Saved corefile core.26426
(gdb) detach

"
68340,"If you work on several different sites then by using a common framework across all of them you can spend time working on the code rather than trying to remember what is located where and why.
I'd always use a framework of some sort, even if it's your own, as the uniformity will help you structure your project. Unless it's a one page static HTML project.
There is no mandatory limit however.
"
68460,"DataViz offers a program for PalmOS called SmartListToGo. It hasn't been updated in a while, but if you're basically collecting data, you can design forms/tables with minimal programming knowledge. I've used it to keep track of mileage/car repairs. I've also used it to keep track of health insurance invoices.
It's not open source, and it actually hasn't had an update of significance in a while. You can even write plugins for it if you are unable to get what you need out of the basic functionality.
"
68610,"Can we see more code?  My first hunch is the table cell needs the text-align: center.
"
68630,"In general, you might expect tuples to be slightly faster. However you should definitely test your specific case (if the difference might impact the performance of your program --  remember ""premature optimization is the root of all evil"").
Python makes this very easy: timeit is your friend.
$ python -m timeit ""x=(1,2,3,4,5,6,7,8)""
10000000 loops, best of 3: 0.0388 usec per loop

$ python -m timeit ""x=[1,2,3,4,5,6,7,8]""
1000000 loops, best of 3: 0.363 usec per loop

and...
$ python -m timeit -s ""x=(1,2,3,4,5,6,7,8)"" ""y=x[3]""
10000000 loops, best of 3: 0.0938 usec per loop

$ python -m timeit -s ""x=[1,2,3,4,5,6,7,8]"" ""y=x[3]""
10000000 loops, best of 3: 0.0649 usec per loop

So in this case, instantiation is almost an order of magnitude faster for the tuple, but item access is actually somewhat faster for the list! So if you're creating a few tuples and accessing them many many times, it may actually be faster to use lists instead.
Of course if you want to change an item, the list will definitely be faster since you'd need to create an entire new tuple to change one item of it (since tuples are immutable).
"
68640,"Yes, you can.  The pointer to the class member variable is stored on the stack with the rest of the struct's values, and the class instance's data is stored on the heap.
Structs can also contain class definitions as members (inner classes).
Here's some really useless code that at least compiles and runs to show that it's possible:
using System;

namespace ConsoleApplication1
{
    class Program
    {
        static void Main(string[] args)
        {
            MyStr m = new MyStr();
            m.Foo();

            MyStr.MyStrInner mi = new MyStr.MyStrInner();
            mi.Bar();

            Console.ReadLine();
        }
    }

    public class Myclass
    {
        public int a;
    }

    struct MyStr
    {
        Myclass mc;

        public void Foo()
        {
            mc = new Myclass();
            mc.a = 1;
        }

        public class MyStrInner
        {
            string x = ""abc"";

            public string Bar()
            {
                return x;
            }
        }
    }
}

"
68750,"I don't have VS installed on my current machine, but I think the syntax would be:
namespace System.Web.Mvc
{
    public static class ViewPageExtensions
    {
        public static string GetDefaultPageTitle<T>(this ViewPage<T> v)
        {
            return """";
        }
    }
}

"
69000,"Create a .Bat file which uses svcutil, for proxygeneration, that has the settings that is right for your project. It's fairly easy. Clicking on the batfile, to generate new proxyfiles whenever the interface have been changed is easy.
The batch can then later be used in automated builds. Then you only need to set up the app.config (or web.config) once. We generally separate the different configs for different environments, such as dev, test prod.
Example (watch out for linebreaks):
REM generate meta data
call ""SVCUTIL.EXE"" /t:metadata ""MyProject.dll"" /reference:""MyReference.dll""

REM making sure the file is writable
attrib -r ""MyServiceProxy.cs""

REM create new proxy file
call ""SVCUTIL.EXE"" /t:code *.wsdl *.xsd /serializable /serializer:Auto /collectionType:System.Collections.Generic.List`1  /out:""MyServiceProxy.cs"" /namespace:*,MY.Name.Space /reference:""MyReference.dll""

:)
//W
"
69030,"The built in key shortcut cmd-? already behaves like this.  It moves key focus to the help menu's search field if it is not already focused, and otherwise dismisses the menu.
"
69060,"Create documentation that speeds up communication and helps you move faster. Let the principle of ""Mutual Benefit"" guide you.

Adoption documents: ""NewPerson handbook"". Getting started with any ""framework"" or niche tools you are using. The best way might be to get the first bunch of newbies to collaborate on refining the content... listen to the Voice of the people. 
Instructions for Setting up a development machine is another good one. Source Control server settings, Installation paths for tools used.
Also document team conventions if any. 
Product Maps: You would need product design roadmaps - block diagrams of various top-level components and the like. Tests can serve as the always updated specs - ground zero documentation.. but you need a simple word doc ... bulleted list of high level product needs / features.
""Here the dragons lie"" - any known minefields with products (esp. legacy), 'Don't tread here' areas that you need to be careful while changing.. e.g. If you change something here, make sure you have it reviewed by Y and Z before checking in.
Update from Dimarzionist: Stash away decisions taken during development, reasons and supporting evidence (mail chains) if needed in a 'well-known place'

Core Metric: If you find no one on the team complaining ""WTH? Why didnt anyone document this? I'm stuck.. How am I supposed to proceed on this?"" - you're good.

If the team finds that they have been drawing a class diagram or sequence diagram over and over, that's proof that it is a useful artifact. Soon someone will make a sticky copy and save it somewhere to save time. Over time , the more useful artifacts would build up. 
Don't pester the team to churn out documents no one else will read...(No ""This is mandated by the process"")
Don't create documents that are 40-50 pages long. No one will read them.. ""Take more time and write a shorter letter"" 5-6 pages max.

Finally as for TFS, once again let the team tell you. If it seems to be working well.. continue if not find alternatives & switch.
"
69230,"One possible solution is:

Add a DATE field that represents the last update time to MY_TABLE table.
ALTER TABLE my_table ADD (last_update_time DATE);
Create an index on that field.
CREATE INDEX i_my_table_upd_time ON my_table (last_update_time);
Create a database trigger on that table that fires ON UPDATE and ON INSERT and stores SYSDATE into the new field.
CREATE OR REPLACE TRIGGER my_table_insert_trg  
BEFORE INSERT OR UPDATE  
ON my_table  
FOR EACH ROW  
BEGIN  
   :new.last_update_time := SYSDATE;  
END;


Now you can issue the following query every 5 minutes
SELECT max(last_update_time) FROM my_table;

and it will give you the time when your table was last updated.
There is no easy way to get a notification from Oracle, sorry.
"
69250,"Without any optimization on, the flow through your code is linear.  If you are on line 5 and single step, you step to line 6.  With optimization on, you can get instruction re-ordering, loop unrolling and all sorts of optimizations.
For example:

void foo() {
1:  int i;
2:  for(i = 0; i < 2; )
3:    i++;
4:  return;

In this example, without optimization, you could single step through the code and hit lines 1, 2, 3, 2, 3, 2, 4
With optimization on, you might get an execution path that looks like: 2, 3, 3, 4 or even just 4! (The function does nothing after all...)
Bottom line, debugging code with optimization enabled can be a royal pain! Especially if you have large functions.
Note that turning on optimization changes the code! In certain environment (safety critical systems), this is unacceptable and the code being debugged has to be the code shipped. Gotta debug with optimization on in that case.
While the optimized and non-optimized code should be ""functionally"" equivalent, under certain circumstances, the behavior will change.
Here is a simplistic example:

    int* ptr = 0xdeadbeef;  // some address to memory-mapped I/O device
    *ptr = 0;   // setup hardware device
    while(*ptr == 1) {    // loop until hardware device is done
       // do something
    }

With optimization off, this is straightforward, and you kinda know what to expect.
However, if you turn optimization on, a couple of things might happen:

The compiler might optimize the while block away (we init to 0, it'll never be 1)
Instead of accessing memory, pointer access might be moved to a register->No I/O Update
memory access might be cached (not necessarily compiler optimization related)

In all these cases, the behavior would be drastically different and most likely wrong.
"
69330,"I recommend getting the Zend Studio Toolbar. The extension allows you to control which pages are debugged from within the browser instead of from Zend Studio.  The options for debugging let you debug the next page, the next form post or all pages.  When you debug like this it runs the PHP just like it will from your server instead of from within Zend Studio. It's an essential tool when using Zend Studio. 
"
69430,"In most browsers, this can be achieved using CSS:
*.unselectable {
   -moz-user-select: -moz-none;
   -khtml-user-select: none;
   -webkit-user-select: none;

   /*
     Introduced in IE 10.
     See http://ie.microsoft.com/testdrive/HTML5/msUserSelect/
   */
   -ms-user-select: none;
   user-select: none;
}

For IE < 10 and Opera, you will need to use the unselectable attribute of the element you wish to be unselectable. You can set this using an attribute in HTML:
<div id=""foo"" unselectable=""on"" class=""unselectable"">...</div>

Sadly this property isn't inherited, meaning you have to put an attribute in the start tag of every element inside the <div>. If this is a problem, you could instead use JavaScript to do this recursively for an element's descendants:
function makeUnselectable(node) {
    if (node.nodeType == 1) {
        node.setAttribute(""unselectable"", ""on"");
    }
    var child = node.firstChild;
    while (child) {
        makeUnselectable(child);
        child = child.nextSibling;
    }
}

makeUnselectable(document.getElementById(""foo""));

"
69440,"I think the question is valid. I agree with the other responses, but it doesn't mean it's a terrible question. I've only ever had to use a Safari CSS hack once as a temporary solution and later got rid of it. I agree that you shouldn't have to target just Safari, but no harm in knowing how to do it.
FYI, this hack only targets Safari 3, and also targets Opera 9.
@media screen and (-webkit-min-device-pixel-ratio:0) {
   /* Safari 3.0 and Opera 9 rules here */
}

"
69470,"What about select the current node selecting the relevant data from the current node into an XSL parameter, and passing that parameter to the function? Like:
<xsl:value-of select=""ourFunction($data)"" />

"
69480,"You can change the background color by command set object 1 rectangle from screen 0,0 to screen 1,1 fillcolor rgb""green"" behind to set the background color to the  the color you specified (here is green).
To get more knowledge about setting the background in gnuplot, you can visit this blog. There are even provided methods to set a gradient color background and background pictures. Good luck!
"
69700,"This really depends on what you're trying to do, but one of the features of the new Test::Harness (disclaimer: I'm the original author and still a core developer) is that if your tests output TAP (the Test Anything Protocol), you can use Test::Harness to run test suites written in multiple languages.  As a result, you don't have to worry about getting ""locked in"" to a particular language because that's all your testing software supports.  In one of my talks on the subject, I even give an example of a test suite written in Perl, C, Ruby, and HTML (yes, HTML -- you'd have to see it).
"
69890,"Since it's based on WebKit, its rendering will most closely resemble Safari and Konqueror.
"
69930,"Have you tried: Russel and Norvig's Artificial Intelligence: A Modern Approach. 
I realise that this is heavy on theory, but it also contains useful code samples that can be used to help your learning.
You can also check out: http://www.kanungo.com/software/software.html for a c-implementation of a HMM
"
70090,"You can use CSS to modify the look of this component.  For the Ajax auto-complete component in 1.3 the element you want to override is div.wicket-aa, so for example you might do:
div.wicket-aa {
    background-color:white;
    border:1px solid #CCCCCC;
    color:black;
}
div.wicket-aa ul {
   list-style-image:none;
   list-style-position:outside;
   list-style-type:none;
   margin:0pt;
   padding:5px;
}
div.wicket-aa ul li.selected {
    background-color:#CCCCCC;
}

"
70140,"The 'M' is just part of the unique filename and has nothing to do with the fact that the mail doesn't show up in mail clients. 
The 'T' at the end of the filename, after the ':' sign, however tells the IMAP server that this message is Trashed.
See http://cr.yp.to/proto/maildir.html
"
70150,"Ecma-335 specifies some more CompilationRelaxations for relaxed exception handling (so-called e-relaxed calls) in Annex F ""Imprecise faults"", but they have not been exposed by Microsoft.
Specifically CompilationRelaxations.RelaxedArrayExceptions and CompilationRelaxations.RelaxedNullReferenceException are mentioned there.
It'd be intersting what happens when you just try some integers in the CompilationRelaxationsAttribute's ctor ;)
"
70170,"You could connect over a secure socket connection, or hash the password locally before sending it to the database (or better, both) - Ideally, the only time the password should exist in plain text form is prior to hashing. If you can do all of that on the client side, more the better.
"
70450,"Bruce Schneier has a good response to this kind of problem.

Cryptography is not the solution to your security problems. It might be part of the solution, or it might be part of the problem. In many situations, cryptography starts out by making the problem worse, and it isn't at all clear that using cryptography is an improvement.

Essentially encrypting your emails in the database 'just in case' is not really making the database more secure. Where are the keys stored for the database? What file permissions are used for these keys? Is the database accesable publically? Why? What kind of account restrictions are in place for these accounts? Where is the machine stored, who has physical access to this box? What about remote login/ssh access etc. etc. etc.
So I guess you can encrypt the emails if you want, but if that is the extent of the security of the system then it really isn't doing much, and would actually make the job of maintaining the database harder.
Of course this could be part of an extensive security policy for your system - if so then great!
I'm not saying that it is a bad idea - But why have a lock on the door from Deadlocks'R'us which cost $5000 when they can cut through the plywood around the door? Or come in through the window which you left open? Or even worse they find the key which was left under the doormat. Security of a system is only as good as the weakest link. If they have root access then they can pretty much do what they want.
Steve Morgan makes a good point that even if they cannot understand the email addresses, they can still do a lot of harm (which could be mitigated if they only had SELECT access)
Its also important to know what your reasons are for storing the email address at all. I might have gone a bit overboard with this answer, but my point is do you really need to store an email address for an account? The most secure data is data that doesn't exist.
"
70460,"If components are 100% decoupled, it means that they don't communicate with each other.
Actually there are different types of coupling. But the general idea is that objects are not coupled if they don't depend on each other.
"
70560,"One approach is the so called bag-of-words model.
As you guessed, first you count how many times words appear in the text (usually called document in the NLP-lingo). Then you throw out the so called stop words, such as ""the"", ""a"", ""or"" and so on.
You're left with words and word counts. Do this for a while and you get a comprehensive set of words that appear in your documents. You can then create an index for these words:
""aardvark"" is 1, ""apple"" is 2, ..., ""z-index"" is 70092. 
Now you can take your word bags and turn them into vectors. For example, if your document contains two references for aardvarks and nothing else, it would look like this:
[2 0 0 ... 70k zeroes ... 0].

After this you can count the ""angle"" between the two vectors with a dot product. The smaller the angle, the closer the documents are.
This is a simple version and there other more advanced techniques. May the Wikipedia be with you.
"
70600,"Yes, my preferred way of doing this would be via PHP. You'd have to set up a script which would load up the file and send it to the user browser. This script would also be able to log the download somewhere (e.g. your database).
For example - in very rough pseudo-code:
download.php
$file = $_GET['file'];
updateFileCount($file);
header('Content-Type: image/jpeg');
sendFile($file);

Then, you just have your download link point to download.php instead of the actual file. (Note that updateFileCount and sendFile are functions that you would have to provide, of course - this script is an example of a download script which you could use)
Note: I highly recommend avoiding the use of $_GET['file'] to get the whole filename - malicious users could use it to retrieve sensitive files from your web server. But the safe use of PHP downloads is a topic for another question.
"
70850,"The top example is know as ""Whitesmiths style"". Wikipedia's entry on Indent Styles explains several styles along with their advantages and disadvantages.
"
70880,"It's not guaranteed to be safe.  Here's a relevant link in the C++ FAQ lite:
[16.13] Can I drop the [] when deleting array of some built-in type (char, int, etc.)?
http://www.parashift.com/c++-faq-lite/freestore-mgmt.html#faq-16.13
"
70890,"Try using the RichFaces Paint 2D tag
It exposes the Graphics2D package to the user interface.
Track user drag events on the image using javascript, then post the co-ordrdinates to the backing bean to re-render the image with a drawn on selection box.
"
71000,"I have used DotNetZip library and it seems to work properly. Typical code:
using (ZipFile zipFile = new ZipFile())
{
  zipFile.AddDirectory(sourceFolderPath);
  zipFile.Save(archiveFolderName);
}

"
71030,"You can do this but you're probably better off doing it in the POM as others have said.
On the command line you can specify a property for the local repository, and another repository for the remote repositories. The remote repository will have all default settings though
The example below specifies two remote repositories and a custom local repository.
mvn package -Dmaven.repo.remote=http://www.ibiblio.org/maven/,http://myrepo 
  -Dmaven.repo.local=""c:\test\repo""

"
71100,"In my experience, testing Sharepoint for accessibility is not worth it. Even if you've used the Accessibility Toolkit for Sharepoint (AKS) with Sharepoint 2007, the end result is far from accessible.
The trouble is that accessibility was not, and still is not a big consideration for MS when they made Sharepoint. Everything depends on table layout, and screenreaders are given a nightmare to deal with.
There are a few online tools - some will help validate your output, others pretend to test you for accessibility (TAW). 
The problem is that many of the guidelines under WCAG are just too arbitrary, and will never be testable by an automated tool. This may change with WCAG 2.
Anyway, wish you the best trying to make Sharepoint accessible.
EDIT: As a side not, I can highly recommend the following tools/resources for anyone interested in accessible development:

Chris Pederick's Web Accessibility
Toolbar
NDA's Web Accessibility IT
Guidelines

"
71180,"How about:
 Sub GetLastRow(strSheet, strColum)
 Dim MyRange As Range
 Dim lngLastRow As Long

    Set MyRange = Worksheets(strSheet).Range(strColum & ""1"")

    lngLastRow = Cells(Rows.Count, MyRange.Column).End(xlUp).Row
 End Sub

Re Comment
This
  Cells.Find(""*"",SearchOrder:=xlByRows,SearchDirection:=xlPrevious).Row

Will return the row number of the last cell even when only a single cell in the last row has data. 
"
71440,"Use the following attribute ...
using System.ComponentModel;

[Browsable(false)]
public bool SampleProperty { get; set; }

In VB.net, this will be:
<System.ComponentModel.Browsable(False)>

"
71590,"After reading your comments to Andrew's answer.
You would read the status like this:
function getStatus() {
    $.getJSON(""/status.php"",{""session"":0, ""requestID"":12345}, 
    function(data) { //data is the returned JSON object from the server {name:""value""}
          setStatus(data.status);
          window.setTimeout(""getStatus()"",intervalInMS)
    });
}

Using this method you can open several simultaneous XHR request on the server.
all your status.php as to output is :
{""status"":""We are done row 1040/45983459""}

You can however output as many information you want in the response and to process it accordingly (feeding a progress bar for example or performing an animation..)
For more information on $.getJSON see http://docs.jquery.com/Ajax/jQuery.getJSON
"
71720,"The answer I discovered eventually was that while OpenGL only has its one amalgamated MODELVIEW matrix, in D3D the ""world"" and ""view"" transforms are kept separate, and placing lights seems to be the major reason for this.  So the answer is you use D3DTS_VIEW to set up matrices that should apply to your lights, and D3DTS_WORLD to set up matrices that apply to the placement of your geometry in the world.
So actually the D3D system kinda makes more sense than the OpenGL way.  It allows you to specify your light positions whenever and wherever the heck you feel like it once and for all, without having to constantly reposition them so that they get transformed by your  current ""view"" transform.  OpenGL has to work that way because it simply doesn't know what you think your ""view"" is vs your ""model"".  It's all just a modelview to GL.
(Comment - apologies if I'm not supposed to answer my own questions here, but this was a real question that I had a few weeks ago and thought it was worth posting here to help others making the shift from OpenGL to D3D.  Basic overviews of the D3D lighting and rendering pipeline seem hard to come by.)
"
71740,"After some time the problem solved itself.
It was indeed a bug in the java runtime which is now fixed by sun. Just make sure your JRE is > 1.6.10.
"
71820,"Depending on your unix implementation ioctl/FIONREAD might do the trick

err = ioctl(pipedesc, FIONREAD, &bytesAvailable);

Unless this returns the error code for ""invalid argument"" (or any other error) bytesAvailable contains the amount of data available for unblocking read operations at that time.
"
71920,"You could use something similar to the Reddit algorithm - the basic principle of which is you compute a value for a post based on the time it was posted and the score. What's neat about the Reddit algorithm is that you only need recompute the value when the score of a post changes. When you want to display your front page, you just get the top n posts from your database based on that score. As time goes on the scores will naturally increase, so you don't have to do any special processing to remove items from the front page.
"
71980,"First, you might not actually have to do anything at all, if all you need to do is read the contents. A BSTR type is a pointer to a null-terminated wchar_t array already. In fact, if you check the headers, you will find that BSTR is essentially defined as:
typedef BSTR wchar_t*;

So, the compiler can't distinguish between them, even though they have different semantics.
There is are two important caveat.

BSTRs are supposed to be immutable. You should never change the contents of a BSTR after it has been initialized. If you ""change it"", you have to create a new one assign the new pointer and release the old one (if you own it).
[UPDATE: this is not true; sorry! You can modify BSTRs in place; I very rarely have had the need.]
BSTRs are allowed to contain embedded null characters, whereas traditional C/C++ strings are not.

If you have a fair amount of control of the source of the BSTR, and can guarantee that the BSTR does not have embedded NULLs, you can read from the BSTR as if it was a wchar_t and use conventional string methods (wcscpy, etc) to access it. If not, your life gets harder. You will have to always manipulate your data as either more BSTRs, or as a dynamically-allocated array of wchar_t. Most string-related functions will not work correctly.
Let's assume you control your data, or don't worry about NULLs. Let's assume also that you really need to make a copy and can't just read the existing BSTR directly. In that case, you can do something like this:
UINT length = SysStringLen(myBstr);        // Ask COM for the size of the BSTR
wchar_t *myString = new wchar_t[lenght+1]; // Note: SysStringLen doesn't 
                                           // include the space needed for the NULL

wcscpy(myString, myBstr);                  // Or your favorite safer string function

// ...

delete myString; // Done

If you are using class wrappers for your BSTR, the wrapper should have a way to call SysStringLen() for you. For example:
CComBString    use .Length();
_bstr_t        use .length();

UPDATE: This is a good article on the subject by someone far more knowledgeable than me:
""Eric [Lippert]'s Complete Guide To BSTR Semantics""
UPDATE: Replaced strcpy() with wcscpy() in example
"
72010,"The two âoverloadsâ aren't in the same scope. By default, the compiler only considers the smallest possible name scope until it finds a name match. Argument matching is done afterwards. In your case this means that the compiler sees B::DoSomething. It then tries to match the argument list, which fails.
One solution would be to pull down the overload from A into B's scope:
class B : public A {
public:
    using A::DoSomething;
    // â¦
}

"
72070,"Some statements will still be executed, even with SET FMTONLY ON.  You ""Conversion failed"" error could be from something as simple as a set variable statement in the stored proc.  For example, this returns the metadata for the first query, but throws an exception when it runs the last statement:
SET FMTONLY on

select 1 as a

declare @a int
set @a = 'a'

As for running a dropped procedure, that's a new one to me.  SQL Server uses the system tables to determine the object to execute, so it doesn't matter if the execution plan is cached for that object.  If you drop it, it is deleted from the system tables, and should never be executable.  Could you please query sysobjects (or sys.objects) just before you execute the procedure?  I expect you'll find that you haven't dropped it.
"
72090,"So I googled greasemonkey dom ready and the first result seemed to say that the greasemonkey script is actually running at ""DOM ready"" so you just need to remove the onload call and run the script straight away.
I removed the  window.addEventListener (""load"", function() { and }, false); wrapping and it worked perfectly. It's much more responsive this way, the page appears straight away with your script applied to it and all the unseen questions highlighted, no flicker at all. And there was much rejoicing.... yea.
"
72220,"Mocha (http://mocha.rubyforge.org/) is a very good mocking library for ruby.  Depending on what you're actually wanting to test (i.e. if you want to just fake out the File.new call to avoid the file system dependency or if you want to verify that the correct arguments are passed into File.new) you could do something like this:


require 'mocha'

mock_file_obj = mock(""My Mock File"") do
  stubs(:some_instance_method).returns(""foo"")
end

File.stubs(:new).with(is_a(String)).returns(mock_file_obj)


"
72240,"The way I've accomplished something similar in the past is by using direct binding ports in the orchestrations and letting the MsgBox do the dirty work for me. Basically, it goes something like this:

Make the callable orchestrations use a direct-bound port attached to your activating receive shape.
Set up a filter expression on your activating receive shape with a custom context-based property and set it equal to a value that uniquely identifies the orchestration (such as the orchestration name or whatever)
In the calling orchestration, create the message you'll want to use to fire the new orchestration. In that message, set your custom context property to the value that matches the filter used in the specific orchestration you want to fire.
Send the message through a direct-bound send port so that it gets sent to the MsgBox directly and the Pub/Sub mechanisms in BizTalk will take care of the rest.

One thing to watch out in step 4: To have this work correctly, you will need to create a new Correlation Set type that includes your custom context property, and then make sure that the direct-bound send port ""follows"" the correlation set on the send. Otherwise, the custom property will only be written (and not promoted) to the msg context and the routing will fail.
Hope this helps!
"
72360,"I've used the IsAssignableFrom method when faced with this problem.
Type theTypeWeWant; // From argument or whatever
foreach (object o in myCollection)
{
    if (theTypeWeWant.IsAssignableFrom(o.GetType))
         return o;
}

Another approach that may or may not work with your problem is to use a generic method:
private T FindObjectOfType<T>() where T: class
{
    foreach(object o in myCollection)
    {
        if (o is T)
             return (T) o;
    }
    return null;
}

(Code written from memory and is not tested)
"
72380,"There's an open source library Sphinx
"
72410,"Firstly put all code for all languages under one domain - it will help your google-rank.
We have a fully multi-lingual system, with localisations stored in a database but cached with the web application.
Wherever we want a localisation to appear we use:
<%$ Resources: LanguageProvider, Path/To/Localisation %>

Then in our web.config:
<globalization resourceProviderFactoryType=""FactoryClassName, AssemblyName""/>

FactoryClassName then implements ResourceProviderFactory to provide the actual dynamic functionality. Localisations are stored in the DB with a string key ""Path/To/Localisation""
It is important to cache the localised values - you don't want to have lots of DB lookups on each page, and we cache thousands of localised strings with no performance issues.
Use the user's current browser localisation to choose what language to serve up.
"
72540,"I would say ""no"". I don't think you can really get the ""something you have"" part of multi-factor authentication without issuing something the end user can carry with them. If you ""have"" something, it implies it can be lost - not many users lose their entire desktop machines. The security of ""something you have"", after all, comes from the following:

you would notice when you don't have it - a clear indication security has been compromised
only 1 person can have it. So if you do, someone else doesn't

Software tokens do not offer the same guarantees, and I would not in good conscience class it as something the user ""has"". 
"
72580,"As far as my experience in Flex/AIR/Flash actionscripting goes, Adobe AIR development environment and coding/debugging toolsets are far inferior to the Visual Studio and .NET SDK as of the moment. The UI toolsets are superior though.
But as you already have a working C# code, porting it to ActionScript might requires a redesign due to ActionScript having a different way of thinking/programming, they use different primitive data types, for example, they use just a Number instead of int float double etc. and the debugging tools are quiet lacking compared to VS IMO.
And I heard that Mono's GtkSharp is quiet a decent platform.
But if you don't mind the coding/debugging tooling problems, then AIR is a great platform. I like how Adobe integrates the Flash experience into it e.g. you can start an installation of AIR application via a button click in a flash movieclip, that kind of integration.
"
73000,"Make a background Thread that calls toFront on the Dialog every 2 seconds.
Code that we use (I hope I got everything):
class TestClass {
protected void toFrontTimer(JFrame frame) {
    try {
        bringToFrontTimer = new java.util.Timer();
        bringToFrontTask = new BringToFrontTask(frame);
        bringToFrontTimer.schedule( bringToFrontTask, 300, 300);
    } catch (Throwable t) {
        t.printStackTrace();
    }
}

class BringToFrontTask extends TimerTask {
    private Frame frame;
    public BringToFrontTask(Frame frame) {
        this.frame = frame;
    }
    public void run()
    {
        if(count < 2) {
            frame.toFront();
        } else {
            cancel();
        }
        count ++;
    }
    private int count = 0;
}

public void cleanup() {
    if(bringToFrontTask != null) {
        bringToFrontTask.cancel();
        bringToFrontTask = null;
    }
    if(bringToFrontTimer != null) {
        bringToFrontTimer = null;
    }
}

java.util.Timer bringToFrontTimer = null;
java.util.TimerTask bringToFrontTask = null;
}

"
73110,"I came across this question when I wanted to solve the same problem. 
The easiest way to do it is to change to System.Windows.Forms.RichTextBox. The ScrollBars property in this case can be left to the default value of RichTextBoxScrollBars.Both, which indicates ""Display both a horizontal and a vertical scroll bar when needed."" It would be nice if this functionality were provided on TextBox.
"
73230,"Try using autocomplete=""off"" as an attribute of the text box. I've used it in the past to stop credit card details being stored by the browser but i dont know if it works with passwords. e.g. print(""<input type=""text"" name=""cc"" autocomplete=""off"" />"");
"
73260,"For explicit time tracking for projects I use SlimTimer.  I also run RescueTime to track my time implicitly, but I end up not looking at that data very often.
"
73320,"In case someone needs a quick solution (it draws up/down arrow at the beginning of column header text):
ListViewExtensions.cs:
public static class ListViewExtensions
{
    public static void DrawSortArrow(this ListView listView, SortOrder sortOrder, int colIndex)
    {
        string upArrow = ""â²   "";
        string downArrow = ""â¼   "";

        foreach (ColumnHeader ch in listView.Columns)
        {
            if (ch.Text.Contains(upArrow))
                ch.Text = ch.Text.Replace(upArrow, string.Empty);
            else if (ch.Text.Contains(downArrow))
                ch.Text = ch.Text.Replace(downArrow, string.Empty);
        }

        if (sortOrder == SortOrder.Ascending)
            listView.Columns[colIndex].Text = listView.Columns[colIndex].Text.Insert(0, downArrow);
        else
            listView.Columns[colIndex].Text = listView.Columns[colIndex].Text.Insert(0, upArrow);
    }
}

Usage:
private void lstOffers_ColumnClick(object sender, ColumnClickEventArgs e)
{
    lstOffers.DrawSortArrow(SortOrder.Descending, e.Column);
}

"
73380,"That is odd as the ViewState is stored as a string in the webpage itself. So I do not see how an extended period of time would cause that error. Perhaps one or more objects on the page have been garbage collected or the application reset, so the viewstate is referencing   old controls instead of the controls created when the application restarted. 
Whatever the case, I feel your pain, these errors are never pleasant to debug, and I have no easy answer as to how to find the problem other than perhaps studying how ViewState works
"
73580,"Here's an example for Gmail smtp:
/*
 *
 */

import java.io.*;
import java.net.InetAddress;
import java.util.Properties;
import java.util.Date;

import javax.mail.*;

import javax.mail.internet.*;

import com.sun.mail.smtp.*;


public class Distribution {

    public static void main(String args[]) throws Exception {
        Properties props = System.getProperties();
        props.put(""mail.smtps.host"",""smtp.gmail.com"");
        props.put(""mail.smtps.auth"",""true"");
        Session session = Session.getInstance(props, null);
        Message msg = new MimeMessage(session);
        msg.setFrom(new InternetAddress(""mail@tovare.com""));;
        msg.setRecipients(Message.RecipientType.TO,
        InternetAddress.parse(""tov.are.jacobsen@iss.no"", false));
        msg.setSubject(""Heisann ""+System.currentTimeMillis());
        msg.setText(""Med vennlig hilsennTov Are Jacobsen"");
        msg.setHeader(""X-Mailer"", ""Tov Are's program"");
        msg.setSentDate(new Date());
        SMTPTransport t =
            (SMTPTransport)session.getTransport(""smtps"");
        t.connect(""smtp.gmail.com"", ""admin@tovare.com"", ""<insert password here>"");
        t.sendMessage(msg, msg.getAllRecipients());
        System.out.println(""Response: "" + t.getLastServerResponse());
        t.close();
    }
}

Now, do it this way only if you would like to keep your project dependencies to a minimum, otherwise i can warmly recommend using classes from apache
http://commons.apache.org/email/ 
Regards
Tov Are Jacobsen
"
73910,"See this article: Pocket Console on Windows Mobile 6
"
73930,"You use a .desktop file for icons under linux.  Where to put the icon depends on what distribution and what desktop environment you are using.  Since I'm currently running Gnome on Fedora 9, I will answer it in those terms.
An example foo.desktop file would be:
[Desktop Entry]
Encoding=UTF-8
GenericName=Generic Piece Of Software
Name=FooBar
Exec=/usr/bin/foo.sh
Icon=foo.png
Terminal=false
Type=Application
Categories=Qt;Gnome;Applications;

The .desktop file should under Fedora 9 Gnome be located in /usr/share/applications/ , you can run a locate on .desktop to figure out where you should put in on your distro.  Gnome will generally look in the KDE icon directory to see if there are other icons there also....

Encoding, Name and Exec should speak for themselves.

Generic name == Brief Description of application.
Icon == The image to display for the icon
Terminal == Is this a terminal application, should I start it as one?
Type == Type of program this is, can be used in placing the icon in a menu.
Categories == This information is what is mainly used to place the icon in a given menu if an XML file to specify such is not present.  The setup for menus is handled a little differently by everyone.


There are more attributes you can set, but they aren't strictly necessary.
The image file used sits somewhere in the bowels of the /usr/share/icons/ directory.  You can parse through that to find all the wonders of how such things work, but the basics are that you pick the directory for the icon type (in my case gnome) and place the image within the appropriate directory (there is a scalable directory for .svg images, and specific sizes such as 48x48 for raster images.  Under Gnome all images are generally .png).
"
73950,"I don't think you can.
Opensource component PDFSharp has that functionality, and a nice source code sample on file combining
"
73960,"Here's another jQuery based example. In contrary to all the other answers posted here, it takes all keyboard and mouse events into account, especially clicks:
if (!$.support.leadingWhitespace) { // if IE6/7/8
    $('select.wide')
        .bind('focus mouseover', function() { $(this).addClass('expand').removeClass('clicked'); })
        .bind('click', function() { $(this).toggleClass('clicked'); })
        .bind('mouseout', function() { if (!$(this).hasClass('clicked')) { $(this).removeClass('expand'); }})
        .bind('blur', function() { $(this).removeClass('expand clicked'); });
}

Use it in combination with this piece of CSS:
select {
    width: 150px; /* Or whatever width you want. */
}
select.expand {
    width: auto;
}

All you need to do is to add the class wide to the dropdown element(s) in question.
<select class=""wide"">
    ...
</select>

Here is a jsfiddle example. Hope this helps.
"
74010,"An implicit cursor is one created ""automatically"" for you by Oracle when you execute a query. It is simpler to code, but suffers from 

inefficiency (the ANSI standard specifies that it must fetch twice to check if there is more than one record)
vulnerability to data errors (if you ever get two rows, it raises a TOO_MANY_ROWS exception)

Example
SELECT col INTO var FROM table WHERE something;

An explicit cursor is one you create yourself. It takes more code, but gives more control - for example, you can just open-fetch-close if you only want the first record and don't care if there are others. 
Example
DECLARE   
  CURSOR cur IS SELECT col FROM table WHERE something; 
BEGIN
  OPEN cur;
  FETCH cur INTO var;
  CLOSE cur;
END;

"
74100,"Here's a quick hack:
public Image AppendBorder(Image original, int borderWidth)
{
    var borderColor = Color.White;

    var newSize = new Size(
        original.Width + borderWidth * 2,
        original.Height + borderWidth * 2);

    var img = new Bitmap(newSize.Width, newSize.Height);
    var g = Graphics.FromImage(img);

    g.Clear(borderColor);
    g.DrawImage(original, new Point(borderWidth, borderWidth));
    g.Dispose();

    return img;
}

It creates a new Bitmap object which has the size of the original plus 2 times border width and then paint the original image in the middle and then return the finished image.
You can do a lot of drawing/painting with the Graphics object above too.
"
74190,"I'd look into Session State Partitioning. Good info here:
http://blog.maartenballiauw.be/post/2008/01/ASPNET-Session-State-Partitioning-using-State-Server-Load-Balancing.aspx
"
74350,"Remote debugging is a godsend for debugging visual issues. It's a pain to set up, but having a VM ready for remote debugging will pay off for sure.
What I like to do is set a ton of breakpoints in my paint handling, as well as in the framework paint code itself. This allows you to effectively ""freeze frame"" the painting without borking it up by flipping into devenv. This way you can get the true picture of who's painting in what order, and where you've got the chance to break in a fill that rect the way you need to.
"
74430,"You probably have a file named random.py or random.pyc in your working directory.  That's shadowing the built-in random module.  You need to rename random.py to something like my_random.py and/or remove the random.pyc file.
To tell for sure what's going on, do this:
>>> import random
>>> print random.__file__

That will show you exactly which file is being imported.
"
74560,"It depends on how your Visual SVN Server is set up. If you are using native windows authentication, just enter you domain username and password. Otherwise, you will have to log into the machine running Visual SVN Server and reset your password there. Visual SVN Server provides a convenient tool for managing users, passwords, permissions, etc. This tool should be available from the Start Menu on your server.
"
74570,"It's the background-image on the body showing through. Quick fix (edit style.css or add elsewhere):
#page-container
{
   background-color: white;
}

"
74620,"What milliseconds? You are providing only minutes information in the first example, whereas your second example grabs current date from the system with milliseconds, what is it you're looking for?
String date = ""06-04-2007 07:05:00.999"";
SimpleDateFormat fmt = new SimpleDateFormat(""MM-dd-yyyy HH:mm:ss.S"");
Date myDate = fmt.parse(date);

System.out.println(myDate); 
long timestamp = myDate.getTime();
System.out.println(timestamp);

"
74690,"Use the QWidget::saveGeometry feature to write the current settings into the registry.(The registry is accessed using QSettings).  Then use restoreGeometry() upon startup to return to the previous state.
"
74790,"How global do your hotkeys need to be?  Is it enough for them to be global for a X session?  In that case you should be able to open an Xlib connection and listen for the events you need.
Ordinarily keyboard events in X are delivered to the window that currently has the focus, and propagated up the hierarchy until they are handled.  Clearly this is not what we want.  We need to process the event before any other window can get to it.  We need to call XGrabKey on the root window with the keycode and  modifiers of our hotkey to accomplish this.
I found a good example here.
"
74880,"The BackgroundWorker class was added to .NET 2.0 for this exact purpose.
In a nutshell you do:
BackgroundWorker worker = new BackgroundWorker();
worker.DoWork += delegate { myBClass.DoHardWork(); }
worker.RunWorkerCompleted += new RunWorkerCompletedEventHandler(SomeOtherMethod);
worker.RunWorkerAsync();

You can also add fancy stuff like cancellation and progress reporting if you want :)
"
74960,"Using WSDL2Java
If you have used the Axis2 WSDL2Java tool you're kind of stuck with what it generates for you.  However you can try to change the skeleton in this section:
   // create SOAP envelope with that payload
   org.apache.axiom.soap.SOAPEnvelope env = null;
   env = toEnvelope(
       getFactory(_operationClient.getOptions().getSoapVersionURI()),
       methodName,
       optimizeContent(new javax.xml.namespace.QName
       (""http://tempuri.org/"",""methodName"")));

//adding SOAP soap_headers
_serviceClient.addHeadersToEnvelope(env);

To add the namespace to the envelope add these lines somewhere in there:
OMNamespace xsi = getFactory(_operationClient.getOptions().getSoapVersionURI()).
    createOMNamespace(""http://www.w3.org/2001/XMLSchema-instance"", ""xsi"");

env.declareNamespace(xsi);

Hand-coded
If you are ""hand-coding"" the service you might do something like this:
SOAPFactory fac = OMAbstractFactory.getSOAP11Factory();   
SOAPEnvelope envelope = fac.getDefaultEnvelope();
OMNamespace xsi = fac.createOMNamespace(""http://www.w3.org/2001/XMLSchema-instance"", ""xsi"");

envelope.declareNamespace(xsi);
OMNamespace methodNs = fac.createOMNamespace(""http://somedomain.com/wsinterface"", ""ns1"");

OMElement method = fac.createOMElement(""CreateEntityTypesResponse"", methodNs);

//add the newkeys and errors as OMElements here...

Exposing service in aar
If you are creating a service inside an aar you may be able to influence the SOAP message produced by using the target namespace or schema namespace properties (see this article).
Hope that helps.
"
75180,"Yes, simple.
say you have
char *a = new char[10];

writing in the debugger:
a,10

would show you the content as if it were an array.
"
75230,"Google might be your best bet.  I know the msdn site search has time and again pointed me in the wrong direction, but a quick switch to Google (""GetLongPathName site:msdn.microsoft.com"") never steers me wrong.
"
75270,"I use SQL Explorer.
It comes as an Eclipse plugin or standalone.
http://eclipsesql.sourceforge.net/
"
75340,"Try the ""libxslt-ruby"" gem. It depends on the ""libxmlr-ruby"" bindings for libxml library, which you probably already have installed if you're developing on Linux.
"
75400,"You cannot set secondary caching settings at property level (as far as I know), but you can individually tune cache settings for each entity directly in their XML files.
For instance:
<?xml version=""1.0"" encoding=""utf-8"" ?>

<hibernate-mapping xmlns=""urn:nhibernate-mapping-2.2"">  

<class name=""ClassName"" table=""Table"">
   <cache usage=""nonstrict-read-write"" />

    <id name=""Id"" type=""Int64"" ...

Where the cache ""usage"" property can be any of the following values:

read-write: assures read committed isolation, makes sure data is consistent but doesn't reduce DB access as much as the other modes,
nonstrict-read-write: objects with rare writes, slight chance of inconsistency between DB and cache,
read-only: for data objects that never change, no chance of inconsistency.

"
75440,"In [1]: class test(object):
   ...:     pass
   ...: 

In [2]: test.__name__
Out[2]: 'test'

"
75500,"Use Imagemagick, or better yet, Ghostscript.
http://www.ibm.com/developerworks/library/l-graf2/#N101C2 has an example for imagemagick:
convert foo.pdf pages-%03d.tiff

http://www.asmail.be/msg0055376363.html has an example for ghostscript:
gs -q -dNOPAUSE -sDEVICE=tiffg4 -sOutputFile=a.tif foo.pdf -c quit

I would install ghostscript and read the man page for gs to see what exact options are needed and experiment.
"
75650,"i'd look into MSBuild or ANT
"
75700,"I guess you have 2 choices
If your use-cases never require updates to both databases within the same transaction, then you can use two JpaTransactionManagers, but I'm not sure you will be able to use the @Transactional approach? In this case, you would need to fallback on the older mechanism of using a simple TransactionProxyFactoryBean to define transaction boundaries, eg:
<bean id=""firstRealService"" class=""com.acme.FirstServiceImpl""/>
<bean id=""firstService""  
    class=""org.springframework.transaction.interceptor.TransactionProxyFactoryBean"">
    <property name=""transactionManager"" ref=""firstJpaTm""/>
    <property name=""target"" ref=""firstRealService""/>
    <property name=""transactionAttributes"">
        <props>
           <prop key=""insert*"">PROPAGATION_REQUIRED</prop>
           <prop key=""update*"">PROPAGATION_REQUIRED</prop>
           <prop key=""*"">PROPAGATION_REQUIRED,readOnly</prop>
        </props>
    </property>
</bean>
<!-- similar for your second service -->

If you are require a transaction spanning both databases, then you will need to use a JTA transaction manager. The API states:

This transaction manager is appropriate for applications that use a single JPA EntityManagerFactory for transactional data access. JTA (usually through JtaTransactionManager) is necessary for accessing multiple transactional resources within the same transaction. Note that you need to configure your JPA provider accordingly in order to make it participate in JTA transactions.

What this means is that you will need to provide a JTA transaction manager. In our application, we use config similar to the following:
<tx:annotation-driven transaction-manager=""txManager""/>

<bean id=""txManager"" 
    class=""org.springframework.transaction.jta.JtaTransactionManager"">
    <property name=""transactionManagerName"" value=""appserver/jndi/path"" />
</bean>

If you are deploying within an appserver, then the spring JtaTransactionManager needs to do a lookup to the real XA-compliant JTA transaction manager provided by the appserver. However, you can also use a standalone JTA transaction manager (but I haven't tried this myself yet)
As for configuring the Jpa persistence provider, I'm not that familiar. What JPA persistence provider are you using?
The code above is based on our approach, where we were using native Hibernate as opposed to Hibernate's JPA implementation. In this case, we were able to get rid of the two HibernateTransactionManager beans, and simply ensure that both SessionFactories were injected with the same JTA TM, and then use the tx:annotation-driven element.
Hope this helps
"
75980,"escape()
Don't use it, as it has been deprecated since ECMAScript v3.
encodeURI()
Use encodeURI when you want a working URL. Make this call:
encodeURI(""http://www.google.com/a file with spaces.html"")

to get:

http://www.google.com/a%20file%20with%20spaces.html

Don't call encodeURIComponent since it would destroy the URL and return

http%3A%2F%2Fwww.google.com%2Fa%20file%20with%20spaces.html

encodeURIComponent()
Use encodeURIComponent when you want to encode a URL parameter.
param1 = encodeURIComponent(""http://xyz.com/?a=12&b=55"")

Then you may create the URL you need:
url = ""http://domain.com/?param1="" + param1 + ""&param2=99"";

And you will get this complete URL:
http://www.domain.com/?param1=http%3A%2F%2Fxyz.com%2F%Ffa%3D12%26b%3D55&param2=99
Note that encodeURIComponent does not escape the ' character. A common bug is to use it to create html attributes such as href='MyUrl', which could suffer an injection bug. If you are constructing html from strings, either use "" instead of ' for attribute quotes, or add an extra layer of encoding (' can be encoded as %27).
For more information on this type of encoding you can check: http://en.wikipedia.org/wiki/Percent-encoding
"
76080,"AppData on vista refers to C:\Users\xxxx\AppData\Roaming not the C:\Users\xxxx\AppData folder it's self.
Also this artical http://www.microsoft.com/technet/scriptcenter/resources/qanda/sept05/hey0901.mspx on a microsoft site implies that you simply have to use the path relative to the appdata folder 
"
76210,"My view of the world may be different, as I'm based in the UK, but for the past 20-odd years, I've worked primarily in the public sector on systems handling sensitive data.
The rules are **completely** cut-and-dried. No production data is allowed on the development estate.
As a fundamental principle, we do not want to be responsible for the loss of sensitive data. The users are perfectly good at that, themselves.
Within the past 12 months, my wife has moved from the same regime to one in the private sector where they allow developers access to production data and she's horrified by it. The legal implications (in the UK, at least) can be severe.
Developers don't **need** access to production data. It's simply laziness. Define and create test data to exercise defined test cases (including edge cases) and don't rely on the random-esque nature of production data.
If you **must** use production data (i.e. you manage to convince someone who doesn't know any better that it's acceptable), ensure the data is anonymised **before** it reaches the development estate.
"
76300,"ArrayList is not thread-safe. You can obtain a thread-safe List with Collections.synchronizedList. However, it is much simpler to use an AtomicInteger in your case or AtomicReference in a more general case.
final AtomicInteger resultAtomicInteger = new AtomicInteger();
Display.getCurrent().syncExec(new Runnable() { 
    public void run() {
        MessageBox mb = /* ... */;
            /* set up messagebox */
        resultAtomicInteger.set(mb.open());
}});
if (SWT.OK == resultAtomicInteger.get()) { /* ... */ }

"
76350,"Power*Architect is the way to go.  It's free, open source, and does a really great job helping you build your ERDs.  Plus, it works on Windows, Linux, and OSX.
"
76440,"We are following these practices you've mentioned:

Planning game
Test driven development
Whole team (being empowered to
deliver)
Continuous integration
Refactoring or design improvement
Small releases
Coding standards
Collective code ownership
Simple design

And I must say that after one year I can't imagine working differently.
As for Pair programming I must say that it makes sense in certain areas, where there is a very high difficult area or where an initial good design is essential (e.g. designing interfaces). However I don't consider this as very effective. In my opinion it is better to perform code and design reviews of smaller parts, where Pair programming would have made sense.
As for the 'Whole team' practice I must admit that it has suffered as our team grew. It simply made the planning sessions too long, when everybody can give his personal inputs. Currently a core team is preparing the planning game by doing some initial, rough planning.
"
76650,"It is a bug in Date::Manip version 5.48-5.54 for Win32. I've had difficulty with using standard/daylight variants of a timezones, e.g. 'EST5EDT', 'US/Eastern'. The only timezones that appear to work are those without daylight savings, e.g. 'EST'.
It is possible to turn off timezone conversion processing in the Date::Manip module:
Date::Manip::Date_Init(""ConvTZ=IGNORE"");

This will have undesired side-effects if you treat dates correctly. I would not use this workaround unless you are confident you will be never be processing dates from different timezones.
"
76680,"Well, you could use
SELECT id FROM messages m WHERE m.id NOT IN(
    SELECT message_id FROM messages_read WHERE user_id = ?)

Where ? is passed in by your app.
"
76700,"The unix command tee does this.
man tee

"
76760,"I have learned the answer to my question through other sources, yes, yes! Sadly, it didn't fix my problem! What's that make me -- a fixer-upper? Yes, yes!
To put stuff in a sub-directory of the Common Application Data folder from a VS2008 Setup project, here's what you do:

Right-click your setup project in the Solution Explorer and pick ""View -> File System"".
Right-click ""File system on target machine"" and pick ""Add Special Folder -> Custom Folder"".
Rename the custom folder to ""Common Application Data Folder."" (This isn't the name that will be used for the resulting folder, it's just to help you keep it straight.)
Change the folder's DefaultLocation property to ""[CommonAppDataFolder][Manufacturer]\[ProductName]"". Note the similarity with the DefaultLocation property of the Application Folder, including the odd use of a single backslash.
Marvel for a moment at the ridiculous (yet undeniable) fact that there is a folder property named ""Property."" 
Change the folder's Property property to ""COMMONAPPDATAFOLDER"".

Data files placed in the ""Common Application Data"" folder will be copied to ""\ProgramData\Manufacturer\ProductName"" (on Vista) or ""\Documents and Settings\All Users\Application Data\Manufacturer\ProductName"" (on XP) when the installer is run.
Now it turns out that under Vista, non-Administrators don't get modify/write access to the files in here. So all users get to read the files, but they get that in ""\Program Files"" as well. So what, I wonder, is the point of the Common Application Data folder?
"
76870,"Step 1: Define a property in your NAnt script to track the environment you're building for (local, test, production, etc.).
<property name=""environment"" value=""local"" />

Step 2: If you don't already have a configuration or initialization target that all targets depends on, then create a configuration target, and make sure your other targets depend on it.
<target name=""config"">
    <!-- configuration logic goes here -->
</target>

<target name=""buildmyproject"" depends=""config"">
    <!-- this target builds your project, but runs the config target first -->
</target>

Step 3: Update your configuration target to pull in an appropriate properties file based on the environment property.
<target name=""config"">
    <property name=""configFile"" value=""${environment}.config.xml"" />
    <if test=""${file::exists(configFile)}"">
        <echo message=""Loading ${configFile}..."" />
        <include buildfile=""${configFile}"" />
    </if>
    <if test=""${not file::exists(configFile) and environment != 'local'}"">
        <fail message=""Configuration file '${configFile}' could not be found."" />
    </if>
</target>

Note, I like to allow team members to define their own local.config.xml files that don't get committed to source control.  This provides a nice place to store local connection strings or other local environment settings.
Step 4: Set the environment property when you invoke NAnt, e.g.:

nant -D:environment=dev
nant -D:environment=test
nant -D:environment=production

"
76930,"use exiftool. open source, written in perl, but also available as standalone .exe file. author seems to have though of everything exif related. mature code.
examples:
exiftool ""-DateTimeOriginal+=5:10:2 10:48:0"" DIR

exiftool -AllDates-=1 DIR

refs:

http://www.sno.phy.queensu.ca/~phil/exiftool/
http://www.sno.phy.queensu.ca/~phil/exiftool/#shift

"
77090,"I found that Infinitest now has an Eclipse plugin that seems to work pretty well. 
"
77280,"A number of smart people are working on a standard, and it's called OAuth. It already has a number of sample implementations, so it's pretty easy to get started.
"
77670,"I don't like idea of storing permissions as flags in one variable.
I'd rather make roles objects in relation many-to-many with users.
For editing rights of the specific object I use an object's method or external function depending on how can I generalise security policies.
For a middle sized portals this approach works very good.
"
77890,"OK, I think that I have it figured out. 
I had to create a type library file of the hnetcfg.dll. I did that when I first started but have learned a lot about the firewall objects since then. It didn't work then, but its working now. You can create your own file from Component|Import Component. And then follow the wizard. 
The wrapping code uses exceptions which I normally don't like to do, but I don't know how to tell whether an Interface that is returning an Interface is actually returning data that I can work off of... So that would be an improvement if somebody can point me in the right direction.
And now to the code, with a thanks to Jim for his response.
constructor TFirewallUtility.Create;
begin
  inherited Create;
  CoInitialize(nil);
  mxCurrentFirewallProfile := INetFwMgr(CreateOLEObject('HNetCfg.FwMgr')).LocalPolicy.CurrentProfile;
end;

function TFirewallUtility.IsPortInExceptionList(iPortNumber: integer): boolean;
begin
  try
    Result := mxCurrentFirewallProfile.GloballyOpenPorts.Item(iPortNumber, NET_FW_IP_PROTOCOL_TCP).Port = iPortNumber;
  except
    Result := False;
  end;
end;

function TFirewallUtility.IsPortEnabled(iPortNumber: integer): boolean;
begin
  try
    Result := mxCurrentFirewallProfile.GloballyOpenPorts.Item(iPortNumber, NET_FW_IP_PROTOCOL_TCP).Enabled;
  except
    Result := False;
  end;
end;

procedure TFirewallUtility.SetPortEnabled(iPortNumber: integer; sPortName: string; xProtocol: TFirewallPortProtocol);
begin
  try
   mxCurrentFirewallProfile.GloballyOpenPorts.Item(iPortNumber, CFirewallPortProtocalConsts[xProtocol]).Enabled := True;
  except
    HaltIf(True, 'xFirewallManager.TFirewallUtility.IsPortEnabled: Port not in exception list.');
  end;
end;

procedure TFirewallUtility.AddPortToFirewall(sPortName: string; iPortNumber: Cardinal; xProtocol: TFirewallPortProtocol);
var
  port: INetFwOpenPort;
begin
  port := INetFwOpenPort(CreateOLEObject('HNetCfg.FWOpenPort'));
  port.Name := sPortName;
  port.Protocol := CFirewallPortProtocalConsts[xProtocol];
  port.Port := iPortNumber;
  port.Scope := NET_FW_SCOPE_ALL;
  port.Enabled := true;
  mxCurrentFirewallProfile.GloballyOpenPorts.Add(port);
end;

"
77900,"Scott Mitchell posted a good article on this a while back. 
http://aspnet.4guysfromrolla.com/articles/012506-1.aspx
I've used this approach in the past in conjection with css on the 'read only' fields to make them look and work exactly like a label, even though they are in fact text boxes.
"
77960,"This is pretty hard to answer because it's so application-specific, but here are a few guidelines I use:

Put as little as possible in the session.
User-specific selections that should only last during a given visit are a good choice
often, variables that need to be accessible to multiple pages throughout the user's visit to your site (to avoid passing them from page to page) are also good to put in the session.

From what little you've said about your application, I'd probably select your data from the db and try to find ways to minimize the impact of those queries instead of loading down the session.
"
77990,"Depending on the terminal you send control seuqences.  Common sequences are for example esc[;H  to send the cursor to a specific position (e.g. on Ansi, Xterm, Linux, VT100).  However, this will vary with the type or terminal the user has ... curses (in conjunction with the terminfo files) will wrap that information for you.
"
78230,"The Flex SDK ships with a set of ant tasks. More info at:
http://livedocs.adobe.com/flex/3/html/help.html?content=anttasks_1.html
Here is an example of compiling Flex SWCs with ant:
http://www.mikechambers.com/blog/2006/05/19/example-using-ant-with-compc-to-compile-swcs/
mike chambers
"
78360,"Testability: If you make your design testable, everything else will fall in line.
"
78380,"This client, is it a desktop application and not some software that runs inside the browser? In that case, please just supply a regular download installer application. My personal experience with browser-hosted installers is that they are just confusing and the few I have seen seemed to be poorly coded in some way.
If you use an MSI based installer I'm sure lots of Windows domain administrators will love you too, as Microsoft has tools to deploy MSI based installations onto large sets of machines remotely.
"
78450,"Well, it looks as if I will be answering my own question.
First, the documentation flat out lies where it reads ""In any style command the first row index may be set to one of the special strings 'splitlast' or 'splitfirst' to indicate that the style should be used only for the last row of a split table, or the first row of a continuation.""  In the current release, the ""splitlast"" and ""splitfirst"" row indices break with the aforementioned TypeErrors on the TEXTCOLOR and BACKGROUND commnds.
My suspicion, based on reading the source code, is that only the tablestyle line commands (GRID, BOX, LINEABOVE, and LINEBELOW) are currently compatible with the 'splitfirst' and 'splitlast' row indices.  I suspect that all cell commands break with the aforementioned TypeErrors.
However, I was able to do what I wanted by subclassing the Table class and overriding the onSplit method.  Here is my code:
class XTable(Table):
    def onSplit(self, T, byRow=1):
        T.setStyle(TableStyle([
          ('TEXTCOLOR', (0, 1), (1, 1), colors.black)]))

What this does is apply the text color black to the first and second cell of the second row of each page.  (The first row is a header, repeated by the repeatRows parameter of the Table.)  More precisely, it is doing this to the first and second cell of each frame, but since I am using the SimpleDocTemplate, frames and pages are identical.
"
78560,"Crazy as it sounds, did you try manually granting yourself perms on the files via right-click / properties / security? I think SQL Server 2005 will set permissions on a detached file exclusively to the principal that did the detach (maybe your account, maybe the account under which the SQL Server service runs) and no-one else can manipulate the file. To get around this I have had to manually grant myself file permissions on MDF and LDF files before moving or deleting them. See also blog post at onupdatecascade.com
"
78570,"I would definitely recommend JQuery as the easiest to use and the one which requires you to write the least code. http://jquery.com/
"
78590,"Yes, I think Google Web Toolkit is the java equivalent to RJS templates.
"
78700,"I assume that you could configure your Windows guest to use the host as its default gateway, and set up NAT via the wireless interface on the host. So the signal flow would look like this:

Windows software opens connections to a host on the internets.
Windows routes the packet via the default gateway, i.e. the host Linux system.
Linux does NAT magic and routes the packet via its normal routing table (which should use a default gateway via the wireless interface).

I have never tried this in combination with bridging though.
"
78850,"There is not much difference between ""publish"", and copying the files. Publish appears in a webapplication. The only difference really is publishing gives you the option to only include html and dll's, where as copying you would need to parse out source code manually. There is no full precompiling in the publish option, as Fully precompiled means no HTML at all; The aspx files are just placeholders; All html is in the compiled binaries.
"
78900,"You've got a couple options. One is to write a supressions file for valgrind that turns off reporting of stuff that you're not working on. Python has such a file, for example: 
http://svn.python.org/projects/python/trunk/Misc/valgrind-python.supp
If valgrind doesn't like your setup, another possibility is using libmudflap; you compile your program with gcc -fmudflap -lmudflap, and the resulting code is instrumented for pointer debugging. Described in the gcc docs, and here: http://gcc.gnu.org/wiki/Mudflap_Pointer_Debugging
"
79210,"On Ubuntu, some the IDEs that are available in the repositories are:

Kdevelop
Geany
Anjuta

There is also:  

Eclipse (Recommended you don't install from repositories, due to issues with file/folder permissions)  
Code::blocks

And of course, everyone's favourite text-based editors:

vi/vim
emacs

Its true that vim and emacs are very powerful tools, but the learning curve is very steep.. 
I really don't like Eclipse that much, I find it buggy and a bit too clunky.
I've started using Geany as a bare-bones but functional and usable IDE. It has a basic code-completion feature, and is a nice, clean [Gnome] interface.
Anjuta I tried for a day, didn't like it at all. I didn't find it as useful as Geany.
Kdevelop and code::blocks get a bunch of good reviews, but I haven't tried them. I use gnome, and I'm yet to see a KDE app that looks good in gnome (sorry, I'm sure its a great program).
If only bloodshed dev-c++ was released under linux. That is a fantastic (but windows-only) program. You could always run it under Wine ;)
To a degree, it comes down to personal preference. My advice is to investigate Kdevelop, Geany and code::blocks as a starting point. 
"
79350,"Virtual Server 2005 R2 SP1 is free (registration required) and supports x64 hosts. It does not support x64 guests.
Windows Server 2008 includes Hyper-V, Microsoft's new virtualization technology, which supports x64 guests and multiple virtual processors. There are editions without Hyper-V as well, for marginally less money, to satisfy the anti-trust authorities. The Hyper-V update has to be downloaded as it was completed after the rest of Windows Server 2008 was released.
VMware Server is also free. It supports (experimentally) up to 2 virtual CPUs.
To get best performance you need drivers and patches in the virtual machine which work well with the virtualization environment. In Virtual Server these are called Additions, in Hyper-V they are Integration Components, and for VMware, VMware Tools. Because of the nature of kernel binary compatibility (there are no guarantees), only specific distributions are generally supported.

Download Virtual Server Additions for Linux
Download Hyper-V Linux Integration Components

"
79360,"It looks like you're using 1.0 as the aspect when you call gluPerspective().  You should use width/height.  For example, if your viewport is 640x480, you would use 1.33333 as the aspect argument.
"
79490,"Install uptimed. It does exactly what you want.
Edit:
You can apparantly include it in a PHP page as easily as this:
<? system(""/usr/local/bin/uprecords -a -B""); ?>

Examples - link broken?
"
79780,"You can retrieve the name/value pairs by searching for newline newline or more specifically \r\n\r\n (after this, the body of the message will start).
Then you can simply split the list by the &, and then split each of those returned strings  between the = for name/value pairs. 
See the HTTP 1.1 RFC.
"
79850,"Designing a bigtable schema is an open process, and basically requires you to think about:

The access patterns you will be using and how often each will be used
The relationships between your types
What indices you are going to need
The write patterns you will be using (in order to effectively spread load)

GAE's datastore automatically denormalizes your data. That is, each index contains a (mostly) complete copy of the data, and thus every index adds significantly to time taken to perform a write, and the storage space used.
If this were not the case, designing a Datastore schema would be a lot more work: You would have to think carefully about the primary key for each type, and consider the effect of your decision on the locality of data. For example, when rendering a blog post you would probably need to display the comments to go along with it, so each comment's key would probably begin with the associated post's key.
With Datastore, this is not such a big deal: The query you use will look something like ""Select * FROM Comment WHERE post_id = N."" (If you want to page the comments, you would also have a limit clause, and a possible suffix of "" AND comment_id > last_comment_id"".) Once you add such a query, Datastore will build the index for you, and your reads will be magically fast.
Something to keep in mind is that each additional index creates some additional cost: it is best if you can use as few access patterns as possible, since it will reduce the number of indices GAE will construct, and thus the total storage required by your data.
Reading over this answer, I find it a little vague. Maybe a hands-on design question would help to scope this down? :-)
"
79960,"By using the wordwrap function. It splits the texts in multiple lines such that the maximum width is the one you specified, breaking at word boundaries. After splitting, you simply take the first line:
substr($string, 0, strpos(wordwrap($string, $your_desired_width), ""\n""));

One thing this oneliner doesn't handle is the case when the text itself is shorter than the desired width. To handle this edge-case, one should do something like:
if (strlen($string) > $your_desired_width) 
{
    $string = wordwrap($string, $your_desired_width);
    $string = substr($string, 0, strpos($string, ""\n""));
}


The above solution has the problem of prematurely cutting the text if it contains a newline before the actual cutpoint. Here a version which solves this problem:
function tokenTruncate($string, $your_desired_width) {
  $parts = preg_split('/([\s\n\r]+)/', $string, null, PREG_SPLIT_DELIM_CAPTURE);
  $parts_count = count($parts);

  $length = 0;
  $last_part = 0;
  for (; $last_part < $parts_count; ++$last_part) {
    $length += strlen($parts[$last_part]);
    if ($length > $your_desired_width) { break; }
  }

  return implode(array_slice($parts, 0, $last_part));
}

Also, here is the PHPUnit testclass used to test the implementation:
class TokenTruncateTest extends PHPUnit_Framework_TestCase {
  public function testBasic() {
    $this->assertEquals(""1 3 5 7 9 "",
      tokenTruncate(""1 3 5 7 9 11 14"", 10));
  }

  public function testEmptyString() {
    $this->assertEquals("""",
      tokenTruncate("""", 10));
  }

  public function testShortString() {
    $this->assertEquals(""1 3"",
      tokenTruncate(""1 3"", 10));
  }

  public function testStringTooLong() {
    $this->assertEquals("""",
      tokenTruncate(""toooooooooooolooooong"", 10));
  }

  public function testContainingNewline() {
    $this->assertEquals(""1 3\n5 7 9 "",
      tokenTruncate(""1 3\n5 7 9 11 14"", 10));
  }
}

EDIT :
Special UTF8 characters like 'Ã ' are not handled. Add 'u' at the end of the REGEX to handle it:
$parts = preg_split('/([\s\n\r]+)/u', $string, null, PREG_SPLIT_DELIM_CAPTURE);
"
80120,"I've used both. I guess it depends on what your organization values.
Since you are familiar with CC Net, I won't speak much to that. You already know what makes it cool.
Here's what I like about Team Foundation Build:

Build Agents. It's very simple to turn any box into a build machine and run a build on it. MSFT got this one right.
Reporting. All relevant build results (test included) are stored in a SQL database and reported on via SQL Server Reporting Services. This is an immensely powerful tool for charting build and test results over time. CC Net doesn't have this built in.
You can do similar customizations via MSBUILD. It's basically the same as using NAnt with CC Net

Here's what drives me up the wall about Team Foundation Build:

To build C++/CLI projects (or run unit tests...?) the build agent must have VSTS Dev or Team Suite installed. This, friends, is just batsh*t crazy.
It must be connected to the TFS Mothership

If you're in a big org with lots of bosses who have huge budgets and love reports (and don't get me wrong, this has huge value) OR you need to scale up to a multi-machine build farm, I'd prefer Team Foundation Build. 
If you're a leaner shop, stick with CC Net and grow your own reporting solutions. That's what we did.
Until we got acquired. And got TFS :P
"
80160,"No idea if it's still used but it was meant to change the balance used by the COM algorithms.
If you had tons of memory and wanted speed at all costs, you would set that flag.
In low-memory environments, leaving that flag off would favor reduced memory usage.

As it turns out, the marvellous Raymond Chen (of ""The Old New Thing"" fame) has now weighed in on the subject and, despite what that flag was meant to do, it apparently does nothing at all.
See What does the COINIT_SPEED_OVER_MEMORY flag to CoInitializeEx do? for more details:

When should you enable this mode? It doesn't matter, because as far as I can tell, there is no code anywhere in COM that changes its behavior based on whether the process has been placed into this mode! It looks like the flag was added when DCOM was introduced, but it never got hooked up to anything. (Or whatever code that had been hooked up to it never shipped.)

Also  http://archives.neohapsis.com/archives/microsoft/various/dcom/2001-q1/0160.html from Steve Swartz, one of the original COM+ architects:

COINIT_SPEED_OVER_MEMORY is ignored by COM.

"
80320,"You have to code it all yourself -- Poppler only handles the PDF part, you have to write the GUI. Look at the code to Evince for a good example. 
"
80370,"Your way is the best way, there's no way to embed windows into tabs without using horrible hacks like GtkPlug (which I'd guess you'd be uninterested in if you're using .NET). Look at the code to gnome-terminal for an example of how to do this.
"
80470,"I did that at my work once. Don't remember the exact numbers offhand, but I think it was 8 levels deep, 10 subdirectories in each level (user id 87654321 maps to directory 8/7/6/5/4/3/2/1/. Turned out that was not such a great idea, started running into problems with filesystem inode number limits, iirc (10^10 = 10000000000 directories, not good). Switched to more subdirectories per level and many less levels; problems went away. Your situation sounds more manageable, but still, check that your filesystem would support the kinds of file and directory counts that you're anticipating.
"
80550,"Edit:  Actually you're not alone.
http://www.eggheadcafe.com/software/aspnet/31450420/crmdeploymentservice-crm.aspx
Hope that helps.
"
80650,"I think this is covered in MSDN, please see Registering an Application to a URL Protocol.
"
80690,"Edit, since I've misunderstand the question first:
Quoted from here http://www.memorymanagement.org/glossary/p.html:

The Java specification says that the
  phantom reference is not cleared when
  the reference object is enqueued, but
  actually, there's no way in the
  language to tell whether that has been
  done or not. In some implementations,
  JNI weak global references are weaker
  than phantom references, and provide a
  way to access phantom reachable
  objects.

But I found no other references which would say the same.
"
80770,"(: file: titles.xqy :)
<table>
<tr><th>title</th><th>author</th></tr>
{
let $books-doc := doc(""books.xml"")
let $authors-doc := doc(""authors.xml"")
for $b in $books-doc//book,
    $a in $authors-doc//author
where $a/@id = $b/authorid
return 
<tr>
    <td>{$b/title/text()}</td>
    <td>{$a/text()}</td>
</tr>
}


"
80820,"There is a FolderBrowserDialog class that you can use if you want the user to select a folder.
http://msdn.microsoft.com/en-us/library/system.windows.forms.folderbrowserdialog.aspx
DialogResult result = folderBrowserDialog1.ShowDialog();
if (result.Equals(get_DialogResult().OK)) {
    textbox1.Text = folderBrowserDialog1.get_SelectedPath();
}

If all you want is to get the direcotory from a full path, you can do this:
textbox1.Text = Path.GetDirectoryName(@""c:\windows\temp\myfile.txt"");

This will set the Text-property to ""c:\windows\temp\""
"
80940,"We use XForms for creating user interfaces for SOAP-based web services. Currently we settled with Chiba XForms engine (http://chiba.sourceforge.net/), but Orbeon (http://www.orbeon.com/) actually seems more mature. Both are server-side engines, which convert XForms into HTML on the fly. The validation is performed on server side with the help of AJAX. This puts quite high demands on the server, so I wouldn't bet on those engines when creating sites with heavy traffic. Alternatives are well documented on XForms Wikipedia page: http://en.wikipedia.org/wiki/XForms.
"
80980,"Some browsers support the canvas:
http://developer.mozilla.org/En/Drawing_Graphics_with_Canvas
"
81150,"The nicest solution I've found is http://bloggablea.wordpress.com/2007/05/01/global-hotkeys-with-net/
Hotkey hk = new Hotkey();

hk.KeyCode = Keys.1;
hk.Windows = true;
hk.Pressed += delegate { Console.WriteLine(""Windows+1 pressed!""); };

hk.Register(myForm); 

Note how you can set different lambdas to different hotkeys
"
81160,"Not free. Not opensource. But I have found AgitarOne Agitator (http://www.agitar.com/solutions/products/agitarone.html) to be REALLY good for automatically generating unit tests AND looking for unwanted obscure side effects
"
81180,"
In IE7 (and probably all famous browsers, including old Firefox 2), if we submit a file like '//server1/path/to/file/filename' it works properly and gives the full path to the file and the filename.
I have no clue how to overcome this 'new feature' because it causes all upload forms in my webapp to stop working on Firefox 3.

There's a major misunderstanding here. Why do you ever need the full file path on the server side? Imagine that I am the client and I have a file at C:\path\to\passwords.txt and I give the full file path to you. How would you as being a server ever get its contents? Do you have an open TCP connection to my local disk file system? Did you test the file upload functionality when you've brought your webapp into production on a different server machine?
It will only work when both the client and server runs at physically the same machine, because you will then have the access to the same hard disk file system. This would only occur when you're locally developing your website and thus both the webbrowser (client) and webserver (server) by coincidence runs at the same machine.
That the full file path is being sent in MSIE and other ancient webbrowsers is due to a security bug. The W3 and RFC2388 specifications have never mentioned to include the full file path. Only the file name. Firefox is doing its job correctly.
To handle uploaded files, you should not need to know the full file path. You should rather be interested in the full file contents which the client has already sent to the server in the request body in case of a multipart/form-data request. Change your form to look like the following as stated in RFC2388:
<form action=""upload-script-url"" method=""post"" enctype=""multipart/form-data"">
    <input type=""file"" name=""file"">
    <input type=""submit"">
</form>

How to obtain the contents of the uploaded file in the server side depends on the server side programming language you're using.

Java/JSP: you'd like to use HttpServletRequest#getPart() or Apache Commons FileUpload API to parse it. You should end up with an InputStream with the file contents which you in turn can write to any OutputStream to your taste. You can find an example in this answer.
Java/JSF: you'd like to use <h:inputFile> component or any other file upload component provided by the component library you're using. Also here, you'd like to obtain the file contents in flavor of an InputStream. See this answer for an example.
PHP: the file contents is already implicitly stored on the temp disk. You'd like to use move_uploaded_file() function to move it to the desired location. See also PHP manual.
ASP.NET: no detailed answer from me since I don't do it, but Google has found some examples for me: ASP.NET example, ASP.NET 2.0 example

Whenever you want to obtain the file name part of the uploaded file, you should trim the full path off from the file name. This information is namely completely irrelevant to you. Also see for example this Apache Commons FileUpload FAQ entry

Why does FileItem.getName() return the whole path, and not just the file name?
Internet Explorer provides the entire path to the uploaded file and not just the base file name. Since FileUpload provides exactly what was supplied by the client (browser), you may want to remove this path information in your application. 

"
81260,"Ant's zipfileset does the job
<jar id=""files"" jarfile=""all.jar"">
    <zipfileset src=""first.jar"" includes=""**/*.java **/*.class""/>
    <zipfileset src=""second.jar"" includes=""**/*.java **/*.class""/>
</jar>

"
81280,"Actually I wiredup the event the wrong way :|
I had
EventManager.RegisterClassHandler ( typeof ( MyClass )......

Instead of
EventManager.RegisterClassHandler ( typeof ( TheClassThatOwnedTheEvent )

So .. my bad.
"
81350,"You will find the answers to this in RFC 1918. Though, I have listed them below for you.
 10.0.0.0        -   10.255.255.255  (10/8 prefix)
 172.16.0.0      -   172.31.255.255  (172.16/12 prefix)
 192.168.0.0     -   192.168.255.255 (192.168/16 prefix)

It is a common misconception that 169.254.0.0/16 is a private IP address block. This is not true. It is link local, basically it is meant to be only used within networks, but it isn't official RFC1918. Additional information about IPv4 addresses can be found in RFC 3300. 
On the other hand IPv6 doesn't have an equivalent to RFC1918, but any sort of site-local work should be done in fc00::/7. This is further touched on in  RFC 4193.
"
81360,"The way to get the return value is to use a SqlParameter on the SqlCommand object which has its Direction set to ParameterDirection.ReturnValue. You should check the SelectCommand property of the TableAdapter after calling Fill.
"
81410,"you could always petition wp to add your widget to their 'approved' list, but who knows how long that would take. you're talking about a way to circumvent the rules they have in place about posting arbitrary script. myspace javascript exploits in particular have increased awareness of the possibility of such workarounds, so you might have a tough time getting around the restrictions - however, here's a classic ones to try:
put the javascript in a weird place, like anywhere that executes a URL. for instance:
<div style=""background:url('javascript:alert(this);');"" />

sometimes the word 'javascript' gets cut out, but occasionally you can sneak it through as java\nscript, or something similar.
sometimes quotes get stripped out - try String.fromCharCode(34) to get around that. Also, in general, using eval(""codepart1"" + ""codepart2"") to get around restricted words or characters.
sneaking in javascript is a tricky business, mostly utilizing unorthodox (possibly un-documented) browser behavior in order to execute arbitrary javascript on a page. Welcome to hacking.
"
81520,"In order to silence the message, you must be redirecting stderr at the time the message is generated. Because the kill command sends a signal and doesn't wait for the target process to respond, redirecting stderr of the kill command does you no good. The bash builtin wait was made specifically for this purpose.
Here is very simple example that kills the most recent background command. (Learn more about $! here.)
kill $!
wait $! 2>/dev/null

Because both kill and wait accept multiple pids, you can also do batch kills. Here is an example that kills all background processes (of the current process/script of course).
kill $(jobs -rp)
wait $(jobs -rp) 2>/dev/null

I was led here from bash: silently kill background function process.
"
81560,"What I would do is this:

The constraint is CASCADE
The application checks if preferences exist.
If they do, show the warning.
If no preferences exist, or the warning is accepted, delete the client.

Changing database relationships on the fly is not going to be a good idea!!
Cheers,
RB.
"
81730,"The runtime keeps a reference to the thread as long as it is running. The GC wont collect it as long as anyone still keeps that reference.
"
81770,"Jozef Dransfield: 
http://www.grassr.com/wordpress/?cat=8
"
81830,"One other thing worth mentioning: the design philosophy of both framework is somewhat different when it comes to the model. Grails is more ""domain-oriented"" while Rails is more ""database-oriented"".
In Rails, you essentially start by defining your tables (with field names and their specifics). Then ActiveRecord will map them to Ruby classes or models.
In Grails, it's the reverse: you start by defining your models (Groovy classes) and when you hit run, GORM (Grails ActiveRecord equivalent) will create the related database and tables (or update them). Which may also be why you don't have the concept of 'migrations' in Grails (although I think it will come in some future release).
I don't know if one is better than the other. I guess it depends on your context.
This being said, I'm still myself wondering which one to choose. As Tom was saying, if you're dependent on Java you can still go for JRuby - so Java reuse shouldn't be your sole criterion.
"
81870,"C++11 update to a very old question: Print variable type in C++.
The accepted (and good) answer is to use typeid(a).name(), where a is a variable name.
Now in C++11 we have decltype(x), which can turn an expression into a type.  And decltype() comes with its own set of very interesting rules.  For example decltype(a) and decltype((a)) will generally be different types (and for good and understandable reasons once those reasons are exposed).
Will our trusty typeid(a).name() help us explore this brave new world?
No.
But the tool that will is not that complicated.  And it is that tool which I am using as an answer to this question.  I will compare and contrast this new tool to typeid(a).name().  And this new tool is actually built on top of typeid(a).name().
The fundamental issue:
typeid(a).name()

throws away cv-qualifiers, references, and lvalue/rvalue-ness.  For example:
const int ci = 0;
std::cout << typeid(ci).name() << '\n';

For me outputs:
i

and I'm guessing on MSVC outputs:
int

I.e. the const is gone.  This is not a QOI (Quality Of Implementation) issue.  The standard mandates this behavior.
What I'm recommending below is:
template <typename T> std::string type_name();

which would be used like this:
const int ci = 0;
std::cout << type_name<decltype(ci)>() << '\n';

and for me outputs:
int const

<disclaimer> I have not tested this on MSVC. </disclaimer>  But I welcome feedback from those who do.
The C++11 Solution
I am using __cxa_demangle for non-MSVC platforms as recommend by ipapadop in his answer to demangle types.  But on MSVC I'm trusting typeid to demangle names (untested).  And this core is wrapped around some simple testing that detects, restores and reports cv-qualifiers and references to the input type.
#include <type_traits>
#include <typeinfo>
#ifndef _MSC_VER
#   include <cxxabi.h>
#endif
#include <memory>
#include <string>
#include <cstdlib>

template <class T>
std::string
type_name()
{
    typedef typename std::remove_reference<T>::type TR;
    std::unique_ptr<char, void(*)(void*)> own
           (
#ifndef _MSC_VER
                abi::__cxa_demangle(typeid(TR).name(), nullptr,
                                           nullptr, nullptr),
#else
                nullptr,
#endif
                std::free
           );
    std::string r = own != nullptr ? own.get() : typeid(TR).name();
    if (std::is_const<TR>::value)
        r += "" const"";
    if (std::is_volatile<TR>::value)
        r += "" volatile"";
    if (std::is_lvalue_reference<T>::value)
        r += ""&"";
    else if (std::is_rvalue_reference<T>::value)
        r += ""&&"";
    return r;
}

The Results
With this solution I can do this:
int& foo_lref();
int&& foo_rref();
int foo_value();

int
main()
{
    int i = 0;
    const int ci = 0;
    std::cout << ""decltype(i) is "" << type_name<decltype(i)>() << '\n';
    std::cout << ""decltype((i)) is "" << type_name<decltype((i))>() << '\n';
    std::cout << ""decltype(ci) is "" << type_name<decltype(ci)>() << '\n';
    std::cout << ""decltype((ci)) is "" << type_name<decltype((ci))>() << '\n';
    std::cout << ""decltype(static_cast<int&>(i)) is "" << type_name<decltype(static_cast<int&>(i))>() << '\n';
    std::cout << ""decltype(static_cast<int&&>(i)) is "" << type_name<decltype(static_cast<int&&>(i))>() << '\n';
    std::cout << ""decltype(static_cast<int>(i)) is "" << type_name<decltype(static_cast<int>(i))>() << '\n';
    std::cout << ""decltype(foo_lref()) is "" << type_name<decltype(foo_lref())>() << '\n';
    std::cout << ""decltype(foo_rref()) is "" << type_name<decltype(foo_rref())>() << '\n';
    std::cout << ""decltype(foo_value()) is "" << type_name<decltype(foo_value())>() << '\n';
}

and the output is:
decltype(i) is int
decltype((i)) is int&
decltype(ci) is int const
decltype((ci)) is int const&
decltype(static_cast<int&>(i)) is int&
decltype(static_cast<int&&>(i)) is int&&
decltype(static_cast<int>(i)) is int
decltype(foo_lref()) is int&
decltype(foo_rref()) is int&&
decltype(foo_value()) is int

Note (for example) the difference between decltype(i) and decltype((i)).  The former is the type of the declaration of i.  The latter is the ""type"" of the expression i. (expressions never have reference type, but as a convention decltype represents lvalue expressions with lvalue references).
Thus this tool is an excellent vehicle just to learn about decltype, in addition to exploring and debugging your own code.
In contrast, if I were to build this just on typeid(a).name(), without adding back lost cv-qualifiers or references, the output would be:
decltype(i) is int
decltype((i)) is int
decltype(ci) is int
decltype((ci)) is int
decltype(static_cast<int&>(i)) is int
decltype(static_cast<int&&>(i)) is int
decltype(static_cast<int>(i)) is int
decltype(foo_lref()) is int
decltype(foo_rref()) is int
decltype(foo_value()) is int

I.e. Every reference and cv-qualifier is stripped off.
C++14 Update
Just when you think you've got a solution to a problem nailed, someone always comes out of nowhere and shows you a much better way. :-)
This answer from Jamboree shows how to get the type name in C++14 at compile time.  It is a brilliant solution for a couple reasons:

It's at compile time!
You get the compiler itself to do the job instead of a library (even a std::lib).  This means more accurate results for the latest language features (like lambdas).

Jamboree's answer doesn't quite lay everything out for VS, and I'm tweaking his code a little bit.  But since this answer gets a lot of views, take some time to go over there and upvote his answer, without which, this update would never have happened.
#include <cstddef>
#include <stdexcept>
#include <cstring>
#include <ostream>

#ifndef _MSC_VER
#  if __cplusplus < 201103
#    define CONSTEXPR11_TN
#    define CONSTEXPR14_TN
#    define NOEXCEPT_TN
#  elif __cplusplus < 201402
#    define CONSTEXPR11_TN constexpr
#    define CONSTEXPR14_TN
#    define NOEXCEPT_TN noexcept
#  else
#    define CONSTEXPR11_TN constexpr
#    define CONSTEXPR14_TN constexpr
#    define NOEXCEPT_TN noexcept
#  endif
#else  // _MSC_VER
#  if _MSC_VER < 1900
#    define CONSTEXPR11_TN
#    define CONSTEXPR14_TN
#    define NOEXCEPT_TN
#  elif _MSC_VER < 2000
#    define CONSTEXPR11_TN constexpr
#    define CONSTEXPR14_TN
#    define NOEXCEPT_TN noexcept
#  else
#    define CONSTEXPR11_TN constexpr
#    define CONSTEXPR14_TN constexpr
#    define NOEXCEPT_TN noexcept
#  endif
#endif  // _MSC_VER

class static_string
{
    const char* const p_;
    const std::size_t sz_;

public:
    typedef const char* const_iterator;

    template <std::size_t N>
    CONSTEXPR11_TN static_string(const char(&a)[N]) NOEXCEPT_TN
        : p_(a)
        , sz_(N-1)
        {}

    CONSTEXPR11_TN static_string(const char* p, std::size_t N) NOEXCEPT_TN
        : p_(p)
        , sz_(N)
        {}

    CONSTEXPR11_TN const char* data() const NOEXCEPT_TN {return p_;}
    CONSTEXPR11_TN std::size_t size() const NOEXCEPT_TN {return sz_;}

    CONSTEXPR11_TN const_iterator begin() const NOEXCEPT_TN {return p_;}
    CONSTEXPR11_TN const_iterator end()   const NOEXCEPT_TN {return p_ + sz_;}

    CONSTEXPR11_TN char operator[](std::size_t n) const
    {
        return n < sz_ ? p_[n] : throw std::out_of_range(""static_string"");
    }
};

inline
std::ostream&
operator<<(std::ostream& os, static_string const& s)
{
    return os.write(s.data(), s.size());
}

template <class T>
CONSTEXPR14_TN
static_string
type_name()
{
#ifdef __clang__
    static_string p = __PRETTY_FUNCTION__;
    return static_string(p.data() + 31, p.size() - 31 - 1);
#elif defined(__GNUC__)
    static_string p = __PRETTY_FUNCTION__;
#  if __cplusplus < 201402
    return static_string(p.data() + 36, p.size() - 36 - 1);
#  else
    return static_string(p.data() + 46, p.size() - 46 - 1);
#  endif
#elif defined(_MSC_VER)
    static_string p = __FUNCSIG__;
    return static_string(p.data() + 38, p.size() - 38 - 7);
#endif
}

This code will auto-backoff on the constexpr if you're still stuck in ancient C++11.  And if you're painting on the cave wall with C++98/03, the noexcept is sacrificed as well.
"
82180,"Qt's own OpenGL based surfaces (using QPainter) are known to be much faster than Cairo. Might you explain why you want specifically Cairo in Qt?
For the basics of using QPainter see this excerpt from the book ""C++ GUI Programming with Qt4"", and while it's C++ code, the PyQt implementation will be parallel.
As for joining Cairo with Qt... This article in ArsTechnica sheds some light - it seems nothing that could help you exists currently (iow., nobody tried such marriage).
"
82220,"Try this:

Create a new Calculated column
In the Forumla box, enter something like this:
    =TEXT([existing date column]+30,""yyyy-mm-dd"")
You can use any date format string you like instead of ""yyyy-mm-dd""
Make the data type ""Date and Time""
Make the date and time format ""Date Only""

"
82340,"There definitely is a way. Though I'd strongly vote for sticky sessions - saves so much load for your servers/database (unless something fails)...
http://tomcat.apache.org/tomcat-5.5-doc/config/manager.html has information about SessionManager configuration and setup for Tomcat. Depending on your exact requirements you might have to implement your own session manager, but this starting point should provide some help.
"
82350,"No.  If the VPC is in full screen mode, alt+tab works only within the context of the VPC.  If the VPC Screen is not focused, you will get the collection of applications that are in the Host (including the instance of VPC)
"
82380,"I decided to go with the new ASP.net Routing.
Why not urlRewriting? Because I don't want to change the clean URL that routing gives to you.
Here is the code:
Sub Application_Start(ByVal sender As Object, ByVal e As EventArgs)
    ' Code that runs on application startup
    RegisterRoutes(RouteTable.Routes)
End Sub


Public Sub RegisterRoutes(ByVal routes As RouteCollection)
    Dim reportRoute As Route
    Dim DefaultLang As String = ""es""

    reportRoute = New Route(""{lang}/{page}"", New LangRouteHandler)
    '* if you want, you can contrain the values
    'reportRoute.Constraints = New RouteValueDictionary(New With {.lang = ""[a-z]{2}""})
    reportRoute.Defaults = New RouteValueDictionary(New With {.lang = DefaultLang, .page = ""home""})

    routes.Add(reportRoute)
End Sub

Then LangRouteHandler.vb class:
Public Class LangRouteHandler
     Implements IRouteHandler

  Public Function GetHttpHandler(ByVal requestContext As System.Web.Routing.RequestContext) As System.Web.IHttpHandler _
      Implements System.Web.Routing.IRouteHandler.GetHttpHandler

    'Fill the context with the route data, just in case some page needs it
    For Each value In requestContext.RouteData.Values
        HttpContext.Current.Items(value.Key) = value.Value
    Next

    Dim VirtualPath As String
    VirtualPath = ""~/"" + requestContext.RouteData.Values(""page"") + "".aspx""

    Dim redirectPage As IHttpHandler
    redirectPage = BuildManager.CreateInstanceFromVirtualPath(VirtualPath, GetType(Page))
    Return redirectPage

  End Function
End Class

Finally I use the default.aspx in the root to redirect to the default lang used in the browser list.
Maybe this can be done with the route.Defaults, but don't work inside Visual Studio (maybe it works in the server)
Protected Sub Page_Load(ByVal sender As Object, ByVal e As System.EventArgs)
    Dim DefaultLang As String = ""es""
    Dim SupportedLangs As String() = {""en"", ""es""}
    Dim BrowserLang As String = Mid(Request.UserLanguages(0).ToString(), 1, 2).ToLower
    If SupportedLangs.Contains(BrowserLang) Then DefaultLang = BrowserLang

    Response.Redirect(DefaultLang + ""/"")
End Sub

Some sources:
  * Mike Ormond's blog
  * Chris Cavanaghâs Blog
  * MSDN 
"
82530,"In /etc/subversion/servers you are setting http-proxy-host, which has nothing to do with svn:// which connects to a different server usually running on port 3690 started by  svnserve command.
If you have access to the server, you can setup svn+ssh:// as explained here.
Update: You could also try using connect-tunnel, which uses your HTTPS proxy server to tunnel connections:
connect-tunnel -P proxy.company.com:8080 -T 10234:svn.example.com:3690

Then you would use
svn checkout svn://localhost:10234/path/to/trunk

"
82550,"#include <boost/serialization/version.hpp>

:-)
"
82850,"You can certainly edit the web.config file for your sites.  The one thing that you should be aware of, however, is that when you start editing files manually on the file system, you will have to remember to manually make those changes across all servers in the farm (assuming a farm exists).  In addition to this, when you edit files in the 12 hive, it's important to understand that you will be making a change to all SharePoint sites hosted on the server(s) for which the files were edited.
Personally, if I were going to create a custom error page, I would simply add a <customErrors> section to my web.config.  I avoid editing any existing files in the 12 hive, but I have added files (though it's rare).
"
82950,"It's nice for aggregating feeds, yes, but the other handy thing to do is filtering the feeds. A while back, I created a feed for Digg (before Digg fell into the Fark pit of dispair). I didn't care about the overwhelming Apple and Ubuntu news, so I filtered those keywords out of Technology, which I then combined with Science and World & Business feeds.
Anyway, you can do a lot more than just combine things. If you wanted to be smart about it,  you could set up per-subfeed and whole-feed filters to give granular or over-arching filtering abilities as the news changes and you get bored with one topic or another.
"
83040,"From PHP Manual

You will need the Oracle client libraries to use this extension.
The most convenient way to install all the required files is to use Oracle Instant Client, which is available from Oracle's site

"
83050,"Here's an Oracle methodology using an analytic function.
with data as (
SELECT 1 trip_id, to_date('20080801 13:30:00','YYYYMMDD HH24:mi:ss') dt, 'Initial'  step from dual UNION ALL
SELECT 1 trip_id, to_date('20080802 13:30:00','YYYYMMDD HH24:mi:ss') dt, 'Work'     step from dual  UNION ALL
SELECT 1 trip_id, to_date('20080803 13:30:00','YYYYMMDD HH24:mi:ss') dt, 'Review'   step from dual  UNION ALL
SELECT 1 trip_id, to_date('20080804 13:30:00','YYYYMMDD HH24:mi:ss') dt, 'Work'     step from dual UNION ALL
SELECT 1 trip_id, to_date('20080805 13:30:00','YYYYMMDD HH24:mi:ss') dt, 'Review'   step from dual  UNION ALL
SELECT 1 trip_id, to_date('20080806 13:30:00','YYYYMMDD HH24:mi:ss') dt, 'Accepted' step from dual  UNION ALL
SELECT 1 trip_id, to_date('20080807 13:30:00','YYYYMMDD HH24:mi:ss') dt, 'Done'     step from dual )
select trip_id,
       step,
       dt - lag(dt) over (partition by trip_id order by dt) trip_time
from  data
/


1   Initial	
1   Work	    1
1   Review	    1
1   Work	    1
1   Review	    1
1   Accepted    1
1   Done	    1

These are very commonly used in situations where traditionally we might use a self-join.
"
83130,"This looks to be a similar issue for .net 2.0, vista and oracle http://forums.oracle.com/forums/thread.jspa?threadID=516250
"
83190,"You can use any editor you like in MATLAB by going to 
File -> Preferences -> Editor/Debugger
and then change the radio button from 'MATLAB Editor' to 'Text editor' and the command for your editor of choice in there.  I use this to launch gedit on my Linux box.
On the Mac-Specific side - it seems that there is a MATLAB bundle for TextMate
http://kjosmoen.org/2007/6/15/bugfixes-in-the-textmate-matlab-bundle
"
83260,"A solution could be to use LINQ as in the following example:
int[] test = { 1, 2, 1, 3, 3, 4, 5 };
var res = (from t in test select t).Distinct<int>();
foreach (var i in res)
{
    Console.WriteLine(i);
}

That would print the expected:
1
2
3
4
5

"
83320,"The Postscript Type-1 specification was created by Adobe back in 1985 or so. Type-1 fonts are vector based. You can find the specification in ""Adobe Type 1. Font Format."".
TrueType fonts were defined by Apple a couple of years earlier so True Type and PostScript were competitors in the 1990s. Microsoft picked up True Type for the native Windows font format in the beginning 1990s (for using PostScript, additional tools like Adobe Type manager were necessary). 
Today, Microsoft is fading out support for PostScript fonts. Try using one as an UI font in Vista. Good luck ;-)
As a successor of TrueType, Microsoft (I think together with Adobe) created the Open Type (anytime around 2000) format and Adobe converted their whole font library into the new format (you can still get them as Type-1 fonts). 
"
83410,"This answer was pulled from http://www.databasejournal.com/features/mssql/article.php/3683181
This same example can be used for any adhoc queries. Let us execute the stored procedure âsp_helpdbâ as shown below.
$SqlConnection = New-Object System.Data.SqlClient.SqlConnection
$SqlConnection.ConnectionString = ""Server=HOME\SQLEXPRESS;Database=master;Integrated Security=True""
$SqlCmd = New-Object System.Data.SqlClient.SqlCommand
$SqlCmd.CommandText = ""sp_helpdb""
$SqlCmd.Connection = $SqlConnection
$SqlAdapter = New-Object System.Data.SqlClient.SqlDataAdapter
$SqlAdapter.SelectCommand = $SqlCmd
$DataSet = New-Object System.Data.DataSet
$SqlAdapter.Fill($DataSet)
$SqlConnection.Close()
$DataSet.Tables[0]

"
83640,"They happen in constant time.  I'm looking at page 466 of the ISO/IEC 14882:2003 standard:
Table 65 - Container Requiments
a.begin();   (constant complexity)
a.end();     (constant complexity)
Table 66 - Reversible Container Requirements
a.rbegin();  (constant complexity)
a.rend();    (constant complexity)
"
83770,"I accomplished this in a project a while back. To do it I created a CompositeControl that contains both the TextBox and the CalendarExtender.
In the CreateChildControls method of the CompositeControl I use code similar to this:
TextBox textbox = new TextBox();
textbox.ID = this.ID + ""Textbox"";
textbox.Text = this.EditableField.TextValue;
textbox.TextChanged += new EventHandler(HandleTextboxTextChanged);
textbox.Width = new Unit(100, UnitType.Pixel);
CalendarExtender calExender = new CalendarExtender();
calExender.PopupButtonID = ""Image1"";
calExender.TargetControlID = textbox.ID;
this.Controls.Add(textbox);
this.Controls.Add(calExender);

Of course make sure that the form containing this CompositeControl has a toolkit script manager.
"
